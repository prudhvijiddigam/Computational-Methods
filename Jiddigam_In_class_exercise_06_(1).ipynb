{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Jiddigam_In_class_exercise_06 (1).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prudhvijiddigam/Computational-Methods/blob/main/Jiddigam_In_class_exercise_06_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7TahL04sVvR"
      },
      "source": [
        "# **The sixth in-class-exercise (20 points in total, 3/2/2021)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejyZITr8sjnh"
      },
      "source": [
        "## **1. Rule-based information extraction (10 points)**\n",
        "\n",
        "Use any keywords related to data science, natural language processing, machine learning to search from google scholar, get the **titles** of 100 articles (either by web scraping or manually) about this topic, define a set of patterns to extract the research questions/problems, methods/algorithms/models, datasets, applications, or any other important information about this topic. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvR_O9D8sOUY",
        "outputId": "4168b049-be6a-402a-8ff3-843bb9e919a5"
      },
      "source": [
        "# Write your code here\n",
        "\n",
        "!pip install pandas\n",
        "!pip install chardet\n",
        "import pandas as pd\n",
        "import csv\n",
        "file1 = open('/titles_data1.txt', 'r',encoding = \"ISO-8859-1\")\n",
        "count = 0\n",
        " \n",
        "while True:\n",
        "    count += 1\n",
        "    line = file1.readline()\n",
        "    if not line:\n",
        "        break\n",
        "    print(\"Line{}: {}\".format(count, line.strip()))\n",
        " \n",
        "file1.close()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.7/dist-packages (3.0.4)\n",
            "Line1: Title of the article\n",
            "Line2: Data scienceÊand prediction\n",
            "Line3: Data scienceÊand its relationship to bigÊdataÊandÊdata-driven decision making\n",
            "Line4: Data ScienceÊfor Business: What you need to know aboutÊdataÊmining andÊdata-analytic thinking\n",
            "Line5: High-dimensional probability: An introduction with applications inÊdata science\n",
            "Line6: Computational optimal transport: With applications to data science\n",
            "Line7: \"Data science, predictive analytics, and big data: a revolution that will transform supply chain design and management\"\n",
            "Line8: \"Reproducible, interactive, scalable and extensible microbiomeÊdata scienceÊusing QIIME 2\"\n",
            "Line9: The quantified self: Fundamental disruption in bigÊdata scienceÊand biological discovery\n",
            "Line10: Putting the data science into journalism\n",
            "Line11: Big data: astronomical or genomical\n",
            "Line12: A comprehensive survey of clustering algorithms\n",
            "Line13: DataÊmining\n",
            "Line14: Analyzing social science data: 50 key problems in data analysis\n",
            "Line15: TheÊdataÊdeluge: An e-scienceÊperspective\n",
            "Line16: Machine learning: the art and science of algorithms that make sense of data\n",
            "Line17: Online analysis enhances use of NASA earth science data\n",
            "Line18: [BOOK]ÊAnalysis of multivariate socialÊscience data\n",
            "Line19: A survey of data provenance in e-science\n",
            "Line20: The analysis of social science data with missing values\n",
            "Line21: Discovering knowledge in data: an introduction to data mining\n",
            "Line22: \"Statistics: methods and applications: a comprehensive reference for science, industry, and data mining\"\n",
            "Line23: The fourth paradigm: data-intensive scientific discovery\n",
            "Line24: Machine learning\n",
            "Line25: Machine learning basics\n",
            "Line26: \"Machine learning: Trends, perspectives, and prospects\"\n",
            "Line27: Readings in machine learning\n",
            "Line28: Foundations of machine learning\n",
            "Line29: Encyclopedia of machine learning\n",
            "Line30: [BOOK] Optimization for machine learning\n",
            "Line31: Understanding machine learning: From theory to algorithms\n",
            "Line32: Elements of machine learning\n",
            "Line33: he impact of machine learning on economicsGenetic algorithms and machine learning\n",
            "Line34: Machine-learning research\n",
            "Line35: Machine learning: a probabilistic perspective\n",
            "Line36: Machine learning and the physical sciences\n",
            "Line37: Machine learning that matters\n",
            "Line38: Python machine learning\n",
            "Line39: Pattern recognition and machine learning\n",
            "Line40: What is machine learning?\n",
            "Line41: Machine learning: the new AI\n",
            "Line42: Dlib-ml: A machine learning toolkit\n",
            "Line43: Machine learning and law\n",
            "Line44: Machine learning in agriculture: A review\n",
            "Line45: The discipline of machine learning\n",
            "Line46: Torch7: A matlab-like environment for machine learning\n",
            "Line47: Practical machine learning\n",
            "Line48: Bioinformatics: the machine learning approach\n",
            "Line49: Machine learning for molecular and materials science\n",
            "Line50: Machine learning for sequential data: A review\n",
            "Line51: Machine learningÊin bioinformatics\n",
            "Line52: Model-based machine learning\n",
            "Line53: Mlaas: Machine learning as a service\n",
            "Line54: ModelDB: a system for machine learning model management\n",
            "Line55: MATLAB machine learning\n",
            "Line56: A course in machine learning\n",
            "Line57: On-line algorithms in machine learning\n",
            "Line58: Graphlab: A new framework for parallel machine learning\n",
            "Line59: MoleculeNet: a benchmark for molecular machine learning\n",
            "Line60: \"Machine learning, neural and statistical classification\"\n",
            "Line61: Python Machine Learning: Machine Learning and Deep Learning with Python\n",
            "Line62: \"Machine learning, a probabilistic perspective\"\n",
            "Line63: Machine learning: algorithms and applications\n",
            "Line64: Ensemble methods in machine learning\n",
            "Line65: Supervised machine learning: A review of classification techniques\n",
            "Line66: Machine learning from theory to algorithms: an overview\n",
            "Line67: Machine learning: the art and science of algorithms that make sense of data\n",
            "Line68: A review of machine learning\n",
            "Line69: Machine learning and data mining\n",
            "Line70: Mllib: Machine learning in apache spark\n",
            "Line71: An introduction to machine learning\n",
            "Line72: Machine learning and radiology\n",
            "Line73: Pylearn2: a machine learning research library\n",
            "Line74: Machine learning and the profession of medicine\n",
            "Line75: Machine learning in the air\n",
            "Line76: QoT estimation for unestablished lighpaths usingÊmachine learning\n",
            "Line77: How the machine 'thinks': Understanding opacity in machine learning algorithms\n",
            "Line78: Dadiannao: A machine-learning supercomputer\n",
            "Line79: Machine learning: a guide to current research\n",
            "Line80: A brief review of machine learning and its application\n",
            "Line81: A review of studies on machine learning techniques\n",
            "Line82: Kernel methods in machine learning\n",
            "Line83: The computational complexity of machine learning\n",
            "Line84: Gaussian processes in machine learning\n",
            "Line85: Encyclopedia of machine learning and data mining\n",
            "Line86: Real-world machine learning\n",
            "Line87: Machine learning phases of matter\n",
            "Line88: \"The immune system, adaptation, and machine learning\"\n",
            "Line89: Machine learning unifies the modeling of materials and molecules\n",
            "Line90: Machine learning: a Bayesian and optimization perspective\n",
            "Line91: Machine learningÊmethods that economists should know about\n",
            "Line92: Advances in financial machine learning\n",
            "Line93: Machine learning: a historical and methodological analysis\n",
            "Line94: Multimodal machine learning: A survey and taxonomy\n",
            "Line95: A review of supervised machine learning algorithms\n",
            "Line96: Argument based machine learning\n",
            "Line97: Adversarial machine learning\n",
            "Line98: Applications of machine learning and rule induction\n",
            "Line99: Machine learning and data mining\n",
            "Line100: Interpretable machine learning\n",
            "Line101: Machine learning for medical imaging\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIzQ-p5HJ8yG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "N7C4-w-7Jtdr",
        "outputId": "643c3257-d0d7-4893-e3d4-37f4cf359767"
      },
      "source": [
        "import pandas as pd\n",
        "articles = pd.read_csv(\"/titles.csv\", encoding = \"ISO-8859-1\")\n",
        "articles.head(47)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Data Science in Action</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Data scienceÊand prediction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Data scienceÊand its relationship to bigÊdataÊ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Data ScienceÊfor Business: What you need to kn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>High-dimensional probability: An introduction ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Computational optimal transport: With applicat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Data science, predictive analytics, and big da...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Reproducible, interactive, scalable and extens...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>The quantified self: Fundamental disruption in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Putting the data science into journalism</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Big data: astronomical or genomical?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>A comprehensive survey of clustering algorithms</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>DataÊmining</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Analyzing social science data: 50 key problems...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>TheÊdataÊdeluge: An e-scienceÊperspective</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Machine learning: the art and science of algor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Online analysis enhances use of NASA earth sci...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>[BOOK]ÊAnalysis of multivariate socialÊscience...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>A survey of data provenance in e-science</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>The analysis of social science data with missi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Discovering knowledge in data: an introduction...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Statistics: methods and applications: a compre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>The fourth paradigm: data-intensive scientific...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Machine learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Machine learning basics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Machine learning: Trends, perspectives, and pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Readings in machine learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Foundations of machine learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Encyclopedia of machine learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>[BOOK] Optimization for machine learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Understanding machine learning: From theory to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Elements of machine learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>he impact of machine learning on economicsGene...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Machine-learning research</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>Machine learning: a probabilistic perspective</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Machine learning and the physical sciences</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>Machine learning that matters</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Python machine learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Pattern recognition and machine learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>What is machine learning?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Machine learning: the new AI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Dlib-ml: A machine learning toolkit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Machine learning and law</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Machine learning in agriculture: A review</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>The discipline of machine learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Torch7: A matlab-like environment for machine ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>Practical machine learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>Bioinformatics: the machine learning approach</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               Data Science in Action\n",
              "0                         Data scienceÊand prediction\n",
              "1   Data scienceÊand its relationship to bigÊdataÊ...\n",
              "2   Data ScienceÊfor Business: What you need to kn...\n",
              "3   High-dimensional probability: An introduction ...\n",
              "4   Computational optimal transport: With applicat...\n",
              "5   Data science, predictive analytics, and big da...\n",
              "6   Reproducible, interactive, scalable and extens...\n",
              "7   The quantified self: Fundamental disruption in...\n",
              "8            Putting the data science into journalism\n",
              "9                Big data: astronomical or genomical?\n",
              "10    A comprehensive survey of clustering algorithms\n",
              "11                                        DataÊmining\n",
              "12  Analyzing social science data: 50 key problems...\n",
              "13          TheÊdataÊdeluge: An e-scienceÊperspective\n",
              "14  Machine learning: the art and science of algor...\n",
              "15  Online analysis enhances use of NASA earth sci...\n",
              "16  [BOOK]ÊAnalysis of multivariate socialÊscience...\n",
              "17           A survey of data provenance in e-science\n",
              "18  The analysis of social science data with missi...\n",
              "19  Discovering knowledge in data: an introduction...\n",
              "20  Statistics: methods and applications: a compre...\n",
              "21  The fourth paradigm: data-intensive scientific...\n",
              "22                                   Machine learning\n",
              "23                            Machine learning basics\n",
              "24  Machine learning: Trends, perspectives, and pr...\n",
              "25                       Readings in machine learning\n",
              "26                    Foundations of machine learning\n",
              "27                   Encyclopedia of machine learning\n",
              "28           [BOOK] Optimization for machine learning\n",
              "29  Understanding machine learning: From theory to...\n",
              "30                       Elements of machine learning\n",
              "31  he impact of machine learning on economicsGene...\n",
              "32                          Machine-learning research\n",
              "33      Machine learning: a probabilistic perspective\n",
              "34         Machine learning and the physical sciences\n",
              "35                      Machine learning that matters\n",
              "36                            Python machine learning\n",
              "37           Pattern recognition and machine learning\n",
              "38                          What is machine learning?\n",
              "39                       Machine learning: the new AI\n",
              "40                Dlib-ml: A machine learning toolkit\n",
              "41                           Machine learning and law\n",
              "42          Machine learning in agriculture: A review\n",
              "43                 The discipline of machine learning\n",
              "44  Torch7: A matlab-like environment for machine ...\n",
              "45                         Practical machine learning\n",
              "46      Bioinformatics: the machine learning approach"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-fh-Wc_1LL4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "e6b662fc-0c81-4dfa-b209-bff2092a2977"
      },
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "matcher = Matcher(nlp.vocab)\n",
        "set_1 = [{\"LOWER\": \"techniques\"}]\n",
        "set_2 = [{\"TEXT\": {\"REGEX\": \"^(N|n)\\w+$\"}},{\"TEXT\": {\"REGEX\": \"^(L|l)\\w+$\"}}, {\"TEXT\": {\"REGEX\": \"^(P|p)\\w+$\"}},\n",
        "           {\"TEXT\": {\"REGEX\": \"^(I|i)(N|n)$\"}},{\"TEXT\": {\"REGEX\": \"^\\w+$\"}}]\n",
        "set_3 = [{\"TEXT\": {\"REGEX\": \"^\\w+$\"}}, {\"TEXT\": {\"REGEX\": \"^[Uu](\\.?|sing)$\"}}, {\"TEXT\": {\"REGEX\": \"^\\w+$\"}}]\n",
        "set_4 = [{\"TEXT\": {\"REGEX\": \"^\\w+$\"}}, {\"TEXT\": {\"REGEX\": \"^[Bb](\\.?|ased)$\"}}, {\"TEXT\": {\"REGEX\": \"^\\w+$\"}}]\n",
        "matcher.add(\"text1\", None, set_1)\n",
        "matcher.add(\"text2\", None, set_2)\n",
        "matcher.add(\"text3\", None, set_3)\n",
        "matcher.add(\"text4\", None, set_4)\n",
        "\n",
        "for text in articles[' Data Science in Action ']:\n",
        "  doc = nlp(text)\n",
        "  matches = matcher(doc)\n",
        "  for match_id, start, end in matches:\n",
        "      span = doc[start:end]\n",
        "      print(text)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-6d303ea39846>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mmatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"based\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marticles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m' Data Science in Action '\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m   \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0mmatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'articles' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxtHkQ5brI5s"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dq_7VGmrsum4"
      },
      "source": [
        "## **2. Domain-specific information extraction (10 points)**\n",
        "\n",
        "For the legal case used in the data cleaning exercise: [01-05-1 Adams v Tanner.txt](https://raw.githubusercontent.com/unt-iialab/info5731_spring2021/main/class_exercises/01-05-1%20%20Adams%20v%20Tanner.txt), use [legalNLP](https://lexpredict-lexnlp.readthedocs.io/en/latest/modules/extract/extract.html#nlp-based-extraction-methods) to extract the following inforation from the text (if the information is not exist, just print None):\n",
        "\n",
        "(1) acts, e.g., “section 1 of the Advancing Hope Act, 1986”\n",
        "\n",
        "(2) amounts, e.g., “ten pounds” or “5.8 megawatts”\n",
        "\n",
        "(3) citations, e.g., “10 U.S. 100” or “1998 S. Ct. 1”\n",
        "\n",
        "(4) companies, e.g., “Lexpredict LLC”\n",
        "\n",
        "(5) conditions, e.g., “subject to …” or “unless and until …”\n",
        "\n",
        "(6) constraints, e.g., “no more than”\n",
        "\n",
        "(7) copyright, e.g., “(C) Copyright 2000 Acme”\n",
        "\n",
        "(8) courts, e.g., “Supreme Court of New York”\n",
        "\n",
        "(9) CUSIP, e.g., “392690QT3”\n",
        "\n",
        "(10) dates, e.g., “June 1, 2017” or “2018-01-01”\n",
        "\n",
        "(11) definitions, e.g., “Term shall mean …”\n",
        "\n",
        "(12) distances, e.g., “fifteen miles”\n",
        "\n",
        "(13) durations, e.g., “ten years” or “thirty days”\n",
        "\n",
        "(14) geographic and geopolitical entities, e.g., “New York” or “Norway”\n",
        "\n",
        "(15) money and currency usages, e.g., “$5” or “10 Euro”\n",
        "\n",
        "(16) percents and rates, e.g., “10%” or “50 bps”\n",
        "\n",
        "(17) PII, e.g., “212-212-2121” or “999-999-9999”\n",
        "\n",
        "(18) ratios, e.g.,” 3:1” or “four to three”\n",
        "\n",
        "(19) regulations, e.g., “32 CFR 170”\n",
        "\n",
        "(20) trademarks, e.g., “MyApp (TM)”\n",
        "\n",
        "(21) URLs, e.g., “http://acme.com/”\n",
        "\n",
        "(22) addresses, e.g., “1999 Mount Read Blvd, Rochester, NY, USA, 14615”\n",
        "\n",
        "(23) persons, e.g., “John Doe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82YkCiGIrHWn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qc7NtJrLx5tS",
        "outputId": "ec60944a-efb5-4e9f-be9c-65528c50cd1d"
      },
      "source": [
        "!pip install lexnlp==0.2.7\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting lexnlp==0.2.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/50/e5e769dfa27b9c657bc3fefb6edee56d186c630176746e232030aa5409ed/lexnlp-0.2.7-py3-none-any.whl (8.0MB)\n",
            "\u001b[K     |████████████████████████████████| 8.0MB 11.8MB/s \n",
            "\u001b[?25hCollecting Unidecode==0.4.21\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/01/a1/9d7f3138ee3d79a1ab865a2cb38200ca778d85121db19fe264c76c981184/Unidecode-0.04.21-py2.py3-none-any.whl (228kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 41.3MB/s \n",
            "\u001b[?25hCollecting regex==2017.9.23\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/65/91b43adad1dc45d7374521422270490128a2f289e1c3e1036b231b521507/regex-2017.09.23.tar.gz (607kB)\n",
            "\u001b[K     |████████████████████████████████| 614kB 50.2MB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.19.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/2c/5edf2488897cad4fb8c4ace86369833552615bf264460ae4ef6e1f258982/scikit-learn-0.19.1.tar.gz (9.5MB)\n",
            "\u001b[K     |████████████████████████████████| 9.5MB 25.2MB/s \n",
            "\u001b[?25hCollecting pandas==0.23.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/a7/12261a51ac2e7be4c698ca27cbe364ca5f16d64999456ee47ea8c7b44417/pandas-0.23.4-cp37-cp37m-manylinux1_x86_64.whl (8.8MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8MB 18.8MB/s \n",
            "\u001b[?25hCollecting scipy==1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/73/76fc6ea21818eed0de8dd38e1e9586725578864169a2b31acdeffb9131c8/scipy-1.0.0.tar.gz (15.2MB)\n",
            "\u001b[K     |████████████████████████████████| 15.2MB 300kB/s \n",
            "\u001b[?25hCollecting num2words==0.5.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5f/d8/1c1fb47cce56ff2cc1f5eb2740f2679045769778a746fbf9ebff1d70a63e/num2words-0.5.5-py2.py3-none-any.whl (57kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.4MB/s \n",
            "\u001b[?25hCollecting dateparser==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/9e/1aa87c0c59f9731820bfd20a8b148d97b315530c2c92d1fb300328c8c42f/dateparser-0.7.0-py2.py3-none-any.whl (357kB)\n",
            "\u001b[K     |████████████████████████████████| 358kB 47.8MB/s \n",
            "\u001b[?25hCollecting reporters-db==1.0.12.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0d/6c/16c7c3849a25d2c3af5ef6e05d768d8e86e74aa9051df4728325c5f31f46/reporters_db-1.0.12.1-py2.py3-none-any.whl (60kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.3MB/s \n",
            "\u001b[?25hCollecting pycountry==18.5.26\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c5/c0/8ce9d2b55347867900edbe4d18f790571130c16f882b4891a0f08627dcdc/pycountry-18.5.26-py2.py3-none-any.whl (10.3MB)\n",
            "\u001b[K     |████████████████████████████████| 10.3MB 29.0MB/s \n",
            "\u001b[?25hCollecting gensim==3.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/a6/82ee7b14c204b82ec00e91fc6b67331cc7b28460ad72b2214384abd0e0a3/gensim-3.4.0.tar.gz (22.2MB)\n",
            "\u001b[K     |████████████████████████████████| 22.2MB 1.4MB/s \n",
            "\u001b[?25hCollecting requests==2.22.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl (57kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.1MB/s \n",
            "\u001b[?25hCollecting nltk==3.2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/c2/858e0708b497116ae45cf5c6b1f66984ac60729c61e49df6c1c0b808d1e4/nltk-3.2.4.tar.gz (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 44.5MB/s \n",
            "\u001b[?25hCollecting datefinder-lexpredict==0.6.2\n",
            "  Downloading https://files.pythonhosted.org/packages/27/47/9a38724045b30e2e4d1c5e3e08fd3b0770dedb2e9ca92c1347b9e2182470/datefinder_lexpredict-0.6.2-py2.py3-none-any.whl\n",
            "Collecting typing==3.6.2\n",
            "  Downloading https://files.pythonhosted.org/packages/44/88/d09c6a7fe1af4a02f16d2f1766212bec752aadb04e5699a9706a10a1a37d/typing-3.6.2-py3-none-any.whl\n",
            "Collecting us==1.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/72/83/8731cbf5afcf3434c0b24cfc520c11fd27bfc8a6878114662f4e3dbdab71/us-1.0.0.tar.gz\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from pandas==0.23.4->lexnlp==0.2.7) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.7/dist-packages (from pandas==0.23.4->lexnlp==0.2.7) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from pandas==0.23.4->lexnlp==0.2.7) (1.19.5)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from dateparser==0.7.0->lexnlp==0.2.7) (1.5.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from reporters-db==1.0.12.1->lexnlp==0.2.7) (1.15.0)\n",
            "Requirement already satisfied: smart_open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.4.0->lexnlp==0.2.7) (4.2.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->lexnlp==0.2.7) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->lexnlp==0.2.7) (2020.12.5)\n",
            "Collecting idna<2.9,>=2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->lexnlp==0.2.7) (3.0.4)\n",
            "Collecting jellyfish==0.5.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/48/ddb1458d966f0a84e472d059d87a9d1527df7768a725132fc1d810728386/jellyfish-0.5.6.tar.gz (132kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 48.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: regex, scikit-learn, scipy, gensim, nltk, us, jellyfish\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for regex: filename=regex-2017.9.23-cp37-cp37m-linux_x86_64.whl size=539789 sha256=13f12415782447b054f7a122858cb5c5d45687dec64197c1df2b6c25bdf9c01e\n",
            "  Stored in directory: /root/.cache/pip/wheels/57/19/41/e7d239b4a53386fe9de49f9e4328799569bbeac8b8b3748876\n",
            "  Building wheel for scikit-learn (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for scikit-learn\u001b[0m\n",
            "\u001b[?25h  Running setup.py clean for scikit-learn\n",
            "  Building wheel for scipy (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for scipy\u001b[0m\n",
            "\u001b[?25h  Running setup.py clean for scipy\n",
            "\u001b[31m  ERROR: Failed cleaning build dir for scipy\u001b[0m\n",
            "  Building wheel for gensim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gensim: filename=gensim-3.4.0-cp37-cp37m-linux_x86_64.whl size=23316463 sha256=05c4ef2202e731cf4f93fb16ea0271fead0c4fc2c6a8527945497bd2d0f7f621\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/5f/2d/04fe5cffea90fbba14c8eab40f519096c8558cceaaa6777048\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.2.4-cp37-none-any.whl size=1367704 sha256=bbea2a1fe6451c68737ed7e6b52576b1e6866c6c1e8d41fa4e80f04bde0c1fda\n",
            "  Stored in directory: /root/.cache/pip/wheels/36/f1/5c/f667347d86a3a534ba4c0127eed4389f929916e3ec88bb461a\n",
            "  Building wheel for us (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for us: filename=us-1.0.0-cp37-none-any.whl size=11833 sha256=e8d95df9c6d98e4a14621e13cf8c3acc492251819235b813db052754eb53ec61\n",
            "  Stored in directory: /root/.cache/pip/wheels/b3/98/40/cb8be35d7779a0ae4372c84e7a585c947bfc41540fd8999e53\n",
            "  Building wheel for jellyfish (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jellyfish: filename=jellyfish-0.5.6-cp37-cp37m-linux_x86_64.whl size=71985 sha256=832a6e0489a8f99da09704b36708bcfb97b1b9950959507a2524e1f0dc173e80\n",
            "  Stored in directory: /root/.cache/pip/wheels/3b/29/06/8d686d24f742cb89e7bde7f26f18cb9e89b3c8bcd6999cb12a\n",
            "Successfully built regex gensim nltk us jellyfish\n",
            "Failed to build scikit-learn scipy\n",
            "\u001b[31mERROR: yellowbrick 0.9.1 has requirement scikit-learn>=0.20, but you'll have scikit-learn 0.19.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: xarray 0.15.1 has requirement pandas>=0.25, but you'll have pandas 0.23.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: umap-learn 0.5.1 has requirement scikit-learn>=0.22, but you'll have scikit-learn 0.19.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement pandas>=0.25.0, but you'll have pandas 0.23.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement scipy>=1.2.0, but you'll have scipy 1.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: mizani 0.6.0 has requirement pandas>=0.25.0, but you'll have pandas 0.23.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: imbalanced-learn 0.4.3 has requirement scikit-learn>=0.20, but you'll have scikit-learn 0.19.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.1.0; python_version >= \"3.0\", but you'll have pandas 0.23.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement pandas>=1.0.4, but you'll have pandas 0.23.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: cvxpy 1.0.31 has requirement scipy>=1.1.0, but you'll have scipy 1.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: Unidecode, regex, scikit-learn, pandas, scipy, num2words, dateparser, reporters-db, pycountry, gensim, idna, requests, nltk, datefinder-lexpredict, typing, jellyfish, us, lexnlp\n",
            "  Found existing installation: regex 2019.12.20\n",
            "    Uninstalling regex-2019.12.20:\n",
            "      Successfully uninstalled regex-2019.12.20\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "    Running setup.py install for scikit-learn ... \u001b[?25l\u001b[?25herror\n",
            "  Rolling back uninstall of scikit-learn\n",
            "  Moving to /usr/local/lib/python3.7/dist-packages/scikit_learn-0.22.2.post1.dist-info/\n",
            "   from /usr/local/lib/python3.7/dist-packages/~cikit_learn-0.22.2.post1.dist-info\n",
            "  Moving to /usr/local/lib/python3.7/dist-packages/sklearn/\n",
            "   from /usr/local/lib/python3.7/dist-packages/~klearn\n",
            "\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-g3s96hfj/scikit-learn/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-g3s96hfj/scikit-learn/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-gqsntazv/install-record.txt --single-version-externally-managed --compile Check the logs for full command output.\u001b[0m\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeVvEA5Z94zF",
        "outputId": "67a84752-f3ff-4f0a-ed48-1204f4d8162b"
      },
      "source": [
        "!pip install lexnlp\n",
        "import lexnlp\n",
        "import re\n",
        "import lexnlp.extract.en.acts\n",
        "\n",
        "with open('/content/01-05-1 Adams v Tanner.txt', 'r', encoding = \"ISO-8859-1\") as file:\n",
        "    doc = file.read()\n",
        "doc = re.sub(r'\\n',' ', str(doc))\n",
        "#acts\n",
        "lexnlp.extract.en.acts.get_act_list(doc)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lexnlp in /usr/local/lib/python3.7/dist-packages (1.8.0)\n",
            "Requirement already satisfied: gensim==3.8.3 in /usr/local/lib/python3.7/dist-packages (from lexnlp) (3.8.3)\n",
            "Requirement already satisfied: reporters-db==2.0.3 in /usr/local/lib/python3.7/dist-packages (from lexnlp) (2.0.3)\n",
            "Requirement already satisfied: joblib==0.14.0 in /usr/local/lib/python3.7/dist-packages (from lexnlp) (0.14.0)\n",
            "Requirement already satisfied: scipy==1.5.1 in /usr/local/lib/python3.7/dist-packages (from lexnlp) (1.5.1)\n",
            "Requirement already satisfied: nltk==3.5 in /usr/local/lib/python3.7/dist-packages (from lexnlp) (3.5)\n",
            "Requirement already satisfied: num2words==0.5.10 in /usr/local/lib/python3.7/dist-packages (from lexnlp) (0.5.10)\n",
            "Requirement already satisfied: numpy==1.19.1 in /usr/local/lib/python3.7/dist-packages (from lexnlp) (1.19.1)\n",
            "Requirement already satisfied: dateparser==0.7.2 in /usr/local/lib/python3.7/dist-packages (from lexnlp) (0.7.2)\n",
            "Requirement already satisfied: pandas==0.24.2 in /usr/local/lib/python3.7/dist-packages (from lexnlp) (0.24.2)\n",
            "Requirement already satisfied: regex==2020.7.14 in /usr/local/lib/python3.7/dist-packages (from lexnlp) (2020.7.14)\n",
            "Requirement already satisfied: requests==2.24.0 in /usr/local/lib/python3.7/dist-packages (from lexnlp) (2.24.0)\n",
            "Requirement already satisfied: datefinder-lexpredict==0.6.2.1 in /usr/local/lib/python3.7/dist-packages (from lexnlp) (0.6.2.1)\n",
            "Requirement already satisfied: pycountry==20.7.3 in /usr/local/lib/python3.7/dist-packages (from lexnlp) (20.7.3)\n",
            "Requirement already satisfied: Unidecode==1.1.1 in /usr/local/lib/python3.7/dist-packages (from lexnlp) (1.1.1)\n",
            "Requirement already satisfied: scikit-learn==0.23.1 in /usr/local/lib/python3.7/dist-packages (from lexnlp) (0.23.1)\n",
            "Requirement already satisfied: us==2.0.2 in /usr/local/lib/python3.7/dist-packages (from lexnlp) (2.0.2)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.3->lexnlp) (4.2.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.3->lexnlp) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk==3.5->lexnlp) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk==3.5->lexnlp) (4.41.1)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.7/dist-packages (from num2words==0.5.10->lexnlp) (0.6.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from dateparser==0.7.2->lexnlp) (2018.9)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from dateparser==0.7.2->lexnlp) (2.8.1)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from dateparser==0.7.2->lexnlp) (1.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests==2.24.0->lexnlp) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.24.0->lexnlp) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.24.0->lexnlp) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.24.0->lexnlp) (1.24.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.1->lexnlp) (2.1.0)\n",
            "Requirement already satisfied: jellyfish==0.6.1 in /usr/local/lib/python3.7/dist-packages (from us==2.0.2->lexnlp) (0.6.1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JInBeeL1Dt3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4906745-8e5a-4387-bb6c-d97120ecdd8e"
      },
      "source": [
        "#2 \n",
        "import lexnlp.extract.en.amounts\n",
        "for amounts in list(lexnlp.extract.en.amounts.get_amounts(doc)):\n",
        "    print(amounts, end=', ')\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5.0, 740.0, 1843.0, 2.0, 1.0, 4.0, 2.0, 1821.0, 5.0, 1.0, 1840.0, 3777.0, 80.0, 100.0, 30.0, 1839.0, 741.0, 22.0, 1840.0, 14000.0, 120.0, 1.0, 1840.0, 3.0, 4.0, 1.0, 1.0, 1840.0, 2.0, 1.0, 361.0, 1.0, 307.0, 6.0, 604.0, 1.0, 2.0, 418.0, 422.0, 7.0, 34.0, 41.0, 167.0, 742.0, 3.0, 112.0, 207.0, 3.0, 338.0, 424.0, 5.0, 26.0, 13.0, 235.0, 8.0, 693.0, 4.0, 1821.0, 167.0, 2.0, 2.0, 216.0, 3.0, 66.0, 4.0, 130.0, 29.0, 2.0, 241.0, 2.0, 332.0, 2.0, 422.0, 9.0, 112.0, 743.0, 9.0, 39.0, 14000.0, 1840.0, 744.0, 5.0, 182.0, 3.0, 368.0, 1.0, 397.0, 6.0, 604.0, 1.0, 1821.0, 167.0, 745.0, 4.0, 746.0, 4.0, 210.0, 46.0, 747.0, 5.0, 5.0, 740.0, 1843.0, 284.0, 2019.0, 9.0, 1.0, 55.0, 266.0, 271.0, 1876.0, 2.0, 47.0, 362.0, 376.0, 1872.0, 3.0, 45.0, 329.0, 334.0, 1871.0, 4.0, 31.0, 526.0, 527.0, 1858.0, 5.0, 21.0, 333.0, 335.0, 1852.0, 6.0, 8.0, 145.0, 147.0, 1857.0, 7.0, 65.0, 256.0, 258.0, 3.0, 1880.0, 8.0, 4.0, 913.0, 914.0, 1887.0, 9.0, 103.0, 464.0, 1936.0, 3.0, 1.0, 9.0, 39.0, 1828.0, 2.0, 2.0, 5.0, 182.0, 1837.0, 2.0, 3.0, 9.0, 108.0, 1812.0, 6.0, 1.0, 2.0, "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nqlGF0WFyIr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d91baf1-944d-47e7-c3b2-ff84973a4623"
      },
      "source": [
        "#3 citations\n",
        "\n",
        "import lexnlp.extract.en.citations\n",
        "citations= [print(citation) \n",
        "  for citation in list(lexnlp.extract.en.citations.get_citations(doc))]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5, 'Ala.', 'Alabama Reports', 740, None, None, None)\n",
            "(5, 'Ala.', 'Alabama Reports', 740, '1843', None, None)\n",
            "(55, 'Ala.', 'Alabama Reports', 266, '271', None, None)\n",
            "(47, 'Ala.', 'Alabama Reports', 362, '376', None, None)\n",
            "(45, 'Ala.', 'Alabama Reports', 329, '334', None, None)\n",
            "(31, 'Ala.', 'Alabama Reports', 526, '527', None, None)\n",
            "(21, 'Ala.', 'Alabama Reports', 333, '335', None, None)\n",
            "(8, 'Cal.', 'California Reports', 145, '147', None, None)\n",
            "(65, 'Ala.', 'Alabama Reports', 256, '258', None, None)\n",
            "(4, 'S.W.', 'South Western Reporter', 913, '914', None, None)\n",
            "(103, 'A.L.R.', 'American Law Reports', 464, None, None, None)\n",
            "(9, 'Cow.', \"Cowen's Reports\", 39, None, None, None)\n",
            "(5, 'Port.', 'Alabama Reports, Porter', 182, None, None, None)\n",
            "(9, 'Johns.', \"Johnson's Reports\", 108, None, None, None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2Gj5eRIGTu5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "785f9ba3-9af4-4325-bbc3-cf9ca0a21d19"
      },
      "source": [
        "import lexnlp.extract.en.entities.nltk_re\n",
        "import lexnlp.extract.en.conditions\n",
        "import lexnlp.extract.en.constraints\n",
        "companies = [print(company) for company in list(lexnlp.extract.en.entities.nltk_re.get_companies(doc))]\n",
        "conditions = [print(condition) for condition in list(lexnlp.extract.en.conditions.get_conditions(doc))]\n",
        "constraints = [print(constraint) for constraint in list(lexnlp.extract.en.constraints.get_constraints(doc))]\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lehman, Durr Co, (17984, 18002)\n",
            "('until', '4 Cases that cite this headnote  [2] CreditorsÕ Remedies Lien and Priority Under St.1821, prohibiting a levy on a crop', '')\n",
            "('until', 'on a growing crop, nor does such lien attach', '')\n",
            "('if', 'It was proved by the claimants, by the production of a written contract, that Harrison, on the twenty-second of May, 1840, in consideration that the claimants were involved, as indorsers for Burton & Harrison of Sumter county, and were then exposed to an execution, amounting to upwards of fourteen thousand dollars, bargained and sold to the claimants all his growing crop of cotton &c., consisting of one hundred and twenty acres, &c. Allen Harrison promised and obliged himself to give up his crop to the use of the claimants at any time to save them from suffering as his indorsers;', '')\n",
            "('when', 'The claimants came from Tennessee, (where they resided) about the first of September, 1840, bringing with them three or four white laborers, and took possession of the crop and slaves, and with the latter, and white laborers, gathered the cotton, prepared it for market, and', '')\n",
            "('if', 'The court charged the jury, that the plaintiff had no lien by virtue of his judgment, and execution on the growing crop; that Harrison had a right to convey it, without being in any manner restrained by them; that the writing adduced, was a sale of the crop, but', '')\n",
            "('when', 'it was not, and the lien of the fieri facias would have attached upon it,', '')\n",
            "('if', 'gathered, yet', '')\n",
            "('not subject to', 'the claimants obtained possession on the first of September, and controlled the gathering of the crop, then no lien attached, and it was', '')\n",
            "('until', 'Rep, 693;] and', '')\n",
            "('until', '167,] which declares it to be lawful to levy an execution on a planted crop,', '')\n",
            "('if', 'It is admitted that the contract between the defendant in execution, and the claimants, was in good faith,', '')\n",
            "('when', 'The defendant in execution might at any time have divested the interest which the contract vested in the claimants, by discharging their liability as his indorsers, or a judgment creditor might have satisfied the lien, and', '')\n",
            "('unless', 'We will then consider the writing under which the claimants assert a right, as a mortgage with a power to take possession any time during the year,', '')\n",
            "('if', 'Conceding the truth of the facts stated in the bill of exceptions, and we think it will not follow, that the possession of the claimants is a nullity, and that the case must be considered as', '')\n",
            "('if', 'The contract contains an express undertaking to give up the crop at any time the claimants might require it for their indemnity, and', '')\n",
            "('if', 'they took possession of it in the absence of the grantor, (though without his consent,)', '')\n",
            "('if', 'he subsequently acquiesced in it, the inference would be,', '')\n",
            "('subject to', 'Mr. Dane, in remarking upon this point, says, ÒThe American editor of BaconÕs Abridgment, says, ÔWheat growing in the ground is a chattel, and', '')\n",
            "('until', 'The first section of the act of 1821, ÒTo prevent sheriffs and other officers from levying executions in certain cases, enacts, that ÒIt shall not be lawful for any sheriff or other officer, to levy a writ of fieri facias or other execution on the planted crop of a debtor, or person against whom an execution may issue,', '')\n",
            "('until', 'Now here is an express inhibition to levy an execution on a crop while it remains on, or in the ground, and', '')\n",
            "('until', 'If so, the act cited, will only have the effect of keeping the right to levy it in abeyance', '')\n",
            "('if', 'The lien and the right to levy are intimately connected, and', '')\n",
            "('until', 'That it was competent for the legislature to have made it unlawful to levy an execution on particular property,', '')\n",
            "('until', 'If the object was merely to suspend the sale,', '')\n",
            "('as soon as', 'The idea that the lien attached upon the planted crop', '')\n",
            "('until', 'the execution was delivered to the sheriff, though the right to levy it was postponed', '')\n",
            "('if', 'They do not refer to the lien,', '')\n",
            "('until', 'they did they would postpone it', '')\n",
            "('until', 'the crop was gathered; but it is the levy they relate to and postpone', '')\n",
            "('until', '**4 The right to levy an execution on a planted crop, then, being expressly taken away by the statute, the lien which is connected with and consequent upon that right, never attaches', '')\n",
            "('if', 'The circuit judge may have mistaken the law in supposing that the contract was a sale, but', '')\n",
            "('when', 'There is no assumption of any material fact in the charge; but the possession of the claimant, the time', '')\n",
            "('if', 'acquired, the gathering of the crop, &c., are all referred to the determination of the jury; who are instructed,', '')\n",
            "('until', '**4 The statute which presents the question before the court is, that Òit shall not be lawful for any sheriff or other officer to levy a writ of fieei facias or other execution, on the planted crop of a debtor, or person against whom an execution may issue,', '')\n",
            "('subject to', 'The policy of the State, as indicated by these statutes, is undeniably that all the property of a debtor, real and personal, to which he has a legal title, shall be', '')\n",
            "('until', 'The mischief which the statute designed to remedy was, the sacrifice which would be necessarily made by the sale of an immature crop: the statute enables the debtor to retain it', '')\n",
            "('if', '**5', '')\n",
            "('until', 'The sheriff is forbidden to levy on a Òplanted cropÓ', '')\n",
            "('if', 'Now,', '')\n",
            "('until', 'This, I feel a thorough conviction, was not the intention of the legislature; but that it was to secure him from loss, by prohibiting a levy and sale of the crop,', '')\n",
            "('when', 'it was gathered,', '')\n",
            "('subject to', 'Growing crops as', '')\n",
            "('subject to', '464 Generally, at common law, growing crops raised by annual planting, while still attached to the soil, are regarded as personal chattels,', '')\n",
            "('where', 'And', '')\n",
            "('after', 'on a growing crop, nor does such lien attach until', '')\n",
            "('after', '', ' and that alias and pluries fieri faciasõ, issued regularly up to the time levy was made; that the cotton levied on was growed on the plantation of harrison, and cultivated by the hands in his service.')\n",
            "('first of', 'the claimants came from tennessee, (where they resided) about the', '')\n",
            "('first of', 'the court charged the jury, that the plaintiff had no lien by virtue of his judgment, and execution on the growing crop; that harrison had a right to convey it, without being in any manner restrained by them; that the writing adduced, was a sale of the crop, but if it was not, and the lien of the fieri facias would have attached upon it, when gathered, yet if the claimants obtained possession on the', '')\n",
            "('after', 'it merely inhibits the levy, but the lien attaches, and a levy and sale may be made', '')\n",
            "('more than', 'taking this to be clear *744 law, and it will be seen, that the defendant in execution at the time of the levy had nothing', '')\n",
            "('before', 'it has been frequently mooted whether, at common law, corn, &c.,', '')\n",
            "('before', '**4 the statute which presents the question', '')\n",
            "('after', 'now, if the view taken by the majority of the court, is correct, the right secured to the plaintiff in execution, of levying on the crop', '')\n",
            "('before', 'tried', '')\n",
            "('before', 'tried', '')\n",
            "('before', 'tried', '')\n",
            "('before', 'tried', '')\n",
            "('before', 'tried', '')\n",
            "('before', 'tried', '')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ugc8T3XuHLnq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2323354e-ff94-4011-84d4-2343f2bab942"
      },
      "source": [
        "import lexnlp.extract.en.copyright\n",
        "import lexnlp.extract.en.courts\n",
        "import lexnlp.extract.en.cusip\n",
        "import lexnlp.extract.en.dates\n",
        "import lexnlp.extract.en.definitions\n",
        "import lexnlp.extract.en.distances\n",
        "import lexnlp.extract.en.durations\n",
        "import lexnlp.extract.en.geoentities\n",
        "import lexnlp.extract.en.money\n",
        "import lexnlp.extract.en.percents\n",
        "import lexnlp.extract.en.pii\n",
        "import lexnlp.extract.en.ratios\n",
        "import lexnlp.extract.en.regulations\n",
        "import lexnlp.extract.en.trademarks\n",
        "import lexnlp.extract.en.urls\n",
        "\n",
        "copyright = [print(copyright) for copyright in list(lexnlp.extract.en.copyright.get_copyright(doc))]\n",
        "dates = [print(date) for date in list(lexnlp.extract.en.dates.get_dates(doc))]\n",
        "distances = [print(distance) for distance in list(lexnlp.extract.en.distances.get_distances(doc))]\n",
        "durations = [print(duration) for duration in list(lexnlp.extract.en.durations.get_durations(doc))]\n",
        "print(\"cusip:\",list(lexnlp.extract.en.cusip.get_cusip(doc)))\n",
        "print(\"definations\",list(lexnlp.extract.en.definitions.get_definitions(doc)))\n",
        "print(\"money\",list(lexnlp.extract.en.money.get_money(doc)))\n",
        "print(\"percents\",list(lexnlp.extract.en.percents.get_percents(doc)))\n",
        "print(\"pii\",list(lexnlp.extract.en.pii.get_pii(doc)))\n",
        "print(\"ratios\",list(lexnlp.extract.en.ratios.get_ratios(doc)))\n",
        "print(\"regualtons\",list(lexnlp.extract.en.regulations.get_regulations(doc)))\n",
        "print(\"trademarks:\",list(lexnlp.extract.en.trademarks.get_trademarks(doc)))\n",
        "print(\"urls\",list(lexnlp.extract.en.urls.get_urls(doc)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('©', '2019', 'Thomson Reuters. No')\n",
            "2021-06-01\n",
            "1840-11-01\n",
            "1839-10-01\n",
            "1840-09-01\n",
            "1840-05-01\n",
            "1840-05-01\n",
            "2021-12-01\n",
            "2021-12-01\n",
            "2021-01-01\n",
            "2021-01-01\n",
            "2021-01-01\n",
            "2021-03-21\n",
            "2021-06-01\n",
            "2021-07-01\n",
            "2021-11-01\n",
            "('second', Decimal('20.0'), Decimal('0.0002'))\n",
            "('year', Decimal('6.0'), Decimal('2190.0'))\n",
            "cusip: []\n",
            "definations []\n",
            "money [(Decimal('100.0'), 'USD'), (Decimal('14000.0'), 'USD'), (Decimal('14000.0'), 'USD')]\n",
            "percents []\n",
            "pii []\n",
            "ratios []\n",
            "regualtons []\n",
            "trademarks: []\n",
            "urls []\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MU6vebcJTrM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}