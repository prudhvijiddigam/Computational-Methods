{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "In_class_exercise_08-1.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prudhvijiddigam/Computational-Methods/blob/main/In_class_exercise_08_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCRPUNdZpgIW"
      },
      "source": [
        "# **The eighth in-class-exercise (20 points in total, 3/30/2021)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-95wcBApgIX"
      },
      "source": [
        "The data for this exercise is from the dataset you created from assignment three. Please perform answer the following questions based on your data:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pet7nI_1pgIY"
      },
      "source": [
        "## (1) (10 points) Write a python program to extract the sentiment related terms from the corpus. You may use python package such as polyglot or external lexicon resources in the question. Rank the sentiment related terms by frequency."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "X8UyJCNppgIY",
        "outputId": "33651038-46e3-47a9-ef96-b4db75ff1897"
      },
      "source": [
        "# Write your code here\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.read_csv('/content/sentimental_analysis1.csv')\n",
        "df"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Titles</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>text directly (rather than e.g. titles and abs...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ABSTRACT: Language is way of communicating you...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>We report experiments on the use of standard n...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>this paper, we will describe a simple rule-bas...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>This paper focuses on connectionist models in ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>This paper presents a workbench built by Pribe...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>Abstract—Natural Language Processing (NLP) is ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>ABSTRACT: After twenty years of disfavor, a te...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>Text statistics are frequently used in stylome...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>We summarize our experience using FrameNet in ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>89 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Titles sentiment\n",
              "0   text directly (rather than e.g. titles and abs...  positive\n",
              "1   ABSTRACT: Language is way of communicating you...  positive\n",
              "2   We report experiments on the use of standard n...  positive\n",
              "3   this paper, we will describe a simple rule-bas...  positive\n",
              "4   This paper focuses on connectionist models in ...  positive\n",
              "..                                                ...       ...\n",
              "84  This paper presents a workbench built by Pribe...  positive\n",
              "85  Abstract—Natural Language Processing (NLP) is ...  positive\n",
              "86  ABSTRACT: After twenty years of disfavor, a te...  positive\n",
              "87  Text statistics are frequently used in stylome...  positive\n",
              "88  We summarize our experience using FrameNet in ...  positive\n",
              "\n",
              "[89 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "Hc2f2a8xs3WB",
        "outputId": "5e59fcd9-c37a-4008-fcbe-b514ff27d906"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "df['sentiment'].value_counts().plot(kind='pie')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f8d84d81910>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "ltv7m9-htV2Z",
        "outputId": "33851196-37d5-4292-9387-9afdb3f0a419"
      },
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from textblob import Word\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from textblob import TextBlob\n",
        "import string\n",
        "stop = stopwords.words('english')\n",
        "\n",
        "\n",
        "df['Titles'] = df['Titles'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
        "df['Titles'] = df['Titles'].apply(lambda  x: \" \".join(x for x in x.split() if x not in string.punctuation))\n",
        "df['Titles'] = df['Titles'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
        "df['Titles'] = df['Titles'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
        "df.head()\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Titles</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>text directly (rather e.g. title abstracts), s...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>abstract: language way communicating word lang...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>report experiment use standard natural languag...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>paper, describe simple rule-based approach aut...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>paper focus connectionist model natural langua...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Titles sentiment\n",
              "0  text directly (rather e.g. title abstracts), s...  positive\n",
              "1  abstract: language way communicating word lang...  positive\n",
              "2  report experiment use standard natural languag...  positive\n",
              "3  paper, describe simple rule-based approach aut...  positive\n",
              "4  paper focus connectionist model natural langua...  positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLaGzjVtuIZc",
        "outputId": "292986d0-cb77-4cfc-c505-cbf4ad6faa33"
      },
      "source": [
        "!pip install vaderSentiment\n",
        "from nltk.util import ngrams \n",
        "import nltk, re, string, collections\n",
        "from nltk.corpus import stopwords\n",
        "import pandas as pd\n",
        "import glob\n",
        "import json\n",
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "from wordcloud import WordCloud\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from textblob import TextBlob\n",
        "from textblob.sentiments import NaiveBayesAnalyzer\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.stem import PorterStemmer\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting vaderSentiment\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/fc/310e16254683c1ed35eeb97386986d6c00bc29df17ce280aed64d55537e9/vaderSentiment-3.3.2-py2.py3-none-any.whl (125kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 20kB 19.6MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 40kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 51kB 9.9MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 61kB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 71kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 81kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 92kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 102kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 112kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 122kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 9.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from vaderSentiment) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (2020.12.5)\n",
            "Installing collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.3.2\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nLB6q3-pS30",
        "outputId": "967229d3-fb56-4f52-cbef-9287a1332655"
      },
      "source": [
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "tokens = []\n",
        "for words in df['Titles']:\n",
        "  tokens.append(word_tokenize(words))\n",
        "tokens[:2]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['text',\n",
              "  'directly',\n",
              "  '(',\n",
              "  'rather',\n",
              "  'e.g',\n",
              "  '.',\n",
              "  'title',\n",
              "  'abstracts',\n",
              "  ')',\n",
              "  ',',\n",
              "  'suggests',\n",
              "  'appropriate',\n",
              "  'approach',\n",
              "  'this',\n",
              "  ',',\n",
              "  'focus',\n",
              "  'role',\n",
              "  'natural',\n",
              "  'language',\n",
              "  'processing',\n",
              "  '.',\n",
              "  'paper',\n",
              "  'also',\n",
              "  'comment',\n",
              "  'possible',\n",
              "  'connection',\n",
              "  'data',\n",
              "  'knowledge',\n",
              "  'retrieval',\n",
              "  ',',\n",
              "  'concludes',\n",
              "  'emphasizing',\n",
              "  'importance',\n",
              "  'rigorous'],\n",
              " ['abstract',\n",
              "  ':',\n",
              "  'language',\n",
              "  'way',\n",
              "  'communicating',\n",
              "  'word',\n",
              "  'language',\n",
              "  'help',\n",
              "  'understanding',\n",
              "  'world',\n",
              "  ',',\n",
              "  'we',\n",
              "  'get',\n",
              "  'better',\n",
              "  'insight',\n",
              "  'world',\n",
              "  '.',\n",
              "  'language',\n",
              "  'help',\n",
              "  'speaker',\n",
              "  'vague',\n",
              "  'precise',\n",
              "  'like',\n",
              "  '.',\n",
              "  'nlp',\n",
              "  'stand',\n",
              "  'natural',\n",
              "  'language',\n",
              "  'processing..',\n",
              "  'natural',\n",
              "  'language',\n",
              "  'language',\n",
              "  'spoken']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VSyld0cRpR_W",
        "outputId": "3bdcaf7a-f61b-436b-a952-4a78d57ef180"
      },
      "source": [
        "def sentiment_analysis(sentence):\n",
        "    analyzer = SentimentIntensityAnalyzer()\n",
        "    vs = analyzer.polarity_scores(sentence)\n",
        "    score=vs['compound']\n",
        "    if score >= 0.5:\n",
        "        return 'Positive'\n",
        "    elif score <= -0.5:\n",
        "        return 'Negative'\n",
        "    else:\n",
        "        return 'Neutral'\n",
        "\n",
        "result=df.head(df.shape[0])\n",
        "result['sentiment']=result['Titles'].apply(lambda x: sentiment_analysis(x))\n",
        "positive = result.loc[result['sentiment'] == 'Positive']\n",
        "\n",
        "print(\"Papers which are considered as positive sentiment:\", pos['Titles'].size)\n",
        "positive"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Papers which are considered as positive sentiment: 41\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Titles</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>abstract: language way communicating word lang...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>report experiment use standard natural languag...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>paper focus connectionist model natural langua...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>paper (see [schank 86] theoretical discussion ...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>paper briefly describes current implementation...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>based literature resources. describe system ag...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>abstract-- natural language processing theoret...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>paper review process involved natural language...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>article focus derivation large lexicon natural...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>sounds, text motion. technique developed deep ...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>statistical baseline including: forgiving natu...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>work computational linguistics began soon deve...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>voice recognition natural language (tamil) com...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>abstract: testing natural language requirement...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>visual development environment support visual ...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>applied structure learning model, max-margin s...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>-mation infrastructure, digital libraries, net...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>kernelized sorting increase robustness perform...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>structured. word statistical natural language ...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>many natural language processing (nlp) techniq...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>information retrieval process finding document...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>logic programming within natural language rese...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>statistical method used natural language proce...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>report, collaborative work field machine learn...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>abstract. thesis examines use machine learning...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>chapter examines application natural language ...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>natural language processing (nlp) large divers...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>probabilistic finite-state string transducer (...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>abstract. special issue tal, look fundamental ...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>natural language processing system (nlp) extra...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>developed prototype information retrieval syst...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>abstract: natural language processing study ma...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>natural language processing (nlp), branch arti...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>evaluation lolita related natural language pro...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>previous work demonstrated web count used appr...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>chapter examines application natural language ...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>paper describes natural language system improv...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>confidence measure practical solution improvin...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>lex-sign sense-id sense-id dictionary \"ldoce\" ...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>support sophisticated natural language process...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>abstract—natural language processing (nlp) eff...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Titles sentiment\n",
              "1   abstract: language way communicating word lang...  Positive\n",
              "2   report experiment use standard natural languag...  Positive\n",
              "4   paper focus connectionist model natural langua...  Positive\n",
              "6   paper (see [schank 86] theoretical discussion ...  Positive\n",
              "8   paper briefly describes current implementation...  Positive\n",
              "9   based literature resources. describe system ag...  Positive\n",
              "12  abstract-- natural language processing theoret...  Positive\n",
              "13  paper review process involved natural language...  Positive\n",
              "14  article focus derivation large lexicon natural...  Positive\n",
              "16  sounds, text motion. technique developed deep ...  Positive\n",
              "19  statistical baseline including: forgiving natu...  Positive\n",
              "20  work computational linguistics began soon deve...  Positive\n",
              "21  voice recognition natural language (tamil) com...  Positive\n",
              "22  abstract: testing natural language requirement...  Positive\n",
              "38  visual development environment support visual ...  Positive\n",
              "40  applied structure learning model, max-margin s...  Positive\n",
              "41  -mation infrastructure, digital libraries, net...  Positive\n",
              "44  kernelized sorting increase robustness perform...  Positive\n",
              "45  structured. word statistical natural language ...  Positive\n",
              "47  many natural language processing (nlp) techniq...  Positive\n",
              "51  information retrieval process finding document...  Positive\n",
              "52  logic programming within natural language rese...  Positive\n",
              "53  statistical method used natural language proce...  Positive\n",
              "54  report, collaborative work field machine learn...  Positive\n",
              "55  abstract. thesis examines use machine learning...  Positive\n",
              "56  chapter examines application natural language ...  Positive\n",
              "58  natural language processing (nlp) large divers...  Positive\n",
              "59  probabilistic finite-state string transducer (...  Positive\n",
              "60  abstract. special issue tal, look fundamental ...  Positive\n",
              "62  natural language processing system (nlp) extra...  Positive\n",
              "65  developed prototype information retrieval syst...  Positive\n",
              "70  abstract: natural language processing study ma...  Positive\n",
              "71  natural language processing (nlp), branch arti...  Positive\n",
              "72  evaluation lolita related natural language pro...  Positive\n",
              "73  previous work demonstrated web count used appr...  Positive\n",
              "74  chapter examines application natural language ...  Positive\n",
              "75  paper describes natural language system improv...  Positive\n",
              "77  confidence measure practical solution improvin...  Positive\n",
              "78  lex-sign sense-id sense-id dictionary \"ldoce\" ...  Positive\n",
              "82  support sophisticated natural language process...  Positive\n",
              "85  abstract—natural language processing (nlp) eff...  Positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1p_-0Vtr8zC",
        "outputId": "34c2eee5-3a28-4bf2-a823-e586f174b963"
      },
      "source": [
        "import itertools\n",
        "aftercleaning = [x for x in words_sentence if x != []]\n",
        "iterations = list(itertools.chain.from_iterable(aftercleaning))\n",
        "iterations[:5]\n",
        "\n",
        "file = df.to_records(index=False)\n",
        "file = list(file)\n",
        "file[:5]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('text directly (rather e.g. title abstracts), suggests appropriate approach this, focus role natural language processing. paper also comment possible connection data knowledge retrieval, concludes emphasizing importance rigorous', 'Neutral'),\n",
              " ('abstract: language way communicating word language help understanding world,we get better insight world. language help speaker vague precise like. nlp stand natural language processing.. natural language language spoken', 'Positive'),\n",
              " ('report experiment use standard natural language processing (nlp) tool analysis music lyrics. significant amount music audio lyrics. lyric encode important part semantics song, therefore analysis complement acoustic cultural', 'Positive'),\n",
              " ('paper, describe simple rule-based approach automated learning linguistic knowledge. approach shown number task capture information clearer direct fashion without compromise performance. present detailed case study learning method applied part speech tagging', 'Neutral'),\n",
              " ('paper focus connectionist model natural language processing. briefly present discus several aspect high level task recently approached connectionism, either localist parallel distributed processing models. several interesting architecture', 'Positive')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJ_AeFpRr9DH",
        "outputId": "f323d035-216f-4d11-b4e8-36a6a5e66dc7"
      },
      "source": [
        "def document_features(document):\n",
        "    document_words = set(document)\n",
        "    features = {}\n",
        "    for word in iterations:\n",
        "        features['contains({})'.format(word)] = (word in document_words)\n",
        "    return features\n",
        "featuresets = [(document_features(d), c) for (d,c) in file]\n",
        "train_set, test_set = featuresets[:80], featuresets[80:]\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "print(nltk.classify.accuracy(classifier, test_set))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5555555555555556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXAcZhUvpgIa"
      },
      "source": [
        "## (2) (10 points) Compare the performance of the following tools in sentiment identification: TextBlob (https://textblob.readthedocs.io/en/dev/), VADER (https://github.com/cjhutto/vaderSentiment), TFIDF-based Support Vector Machine (SVM) (Split your data into training and testing data). Take your own annotation as the standard answers. \n",
        "\n",
        "Reference code: https://towardsdatascience.com/fine-grained-sentiment-analysis-in-python-part-1-2697bb111ed4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "Blyn1Gv1pgIc",
        "outputId": "c604b652-ef80-42bc-cf82-b88e9bc0472b"
      },
      "source": [
        "# Write your code here\n",
        "\n",
        "df = pd.read_csv('/content/sentimental_analysis1.csv')\n",
        "df\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Titles</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>text directly (rather than e.g. titles and abs...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ABSTRACT: Language is way of communicating you...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>We report experiments on the use of standard n...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>this paper, we will describe a simple rule-bas...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>This paper focuses on connectionist models in ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>This paper presents a workbench built by Pribe...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>Abstract—Natural Language Processing (NLP) is ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>ABSTRACT: After twenty years of disfavor, a te...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>Text statistics are frequently used in stylome...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>We summarize our experience using FrameNet in ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>89 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Titles sentiment\n",
              "0   text directly (rather than e.g. titles and abs...  positive\n",
              "1   ABSTRACT: Language is way of communicating you...  positive\n",
              "2   We report experiments on the use of standard n...  positive\n",
              "3   this paper, we will describe a simple rule-bas...  positive\n",
              "4   This paper focuses on connectionist models in ...  positive\n",
              "..                                                ...       ...\n",
              "84  This paper presents a workbench built by Pribe...  positive\n",
              "85  Abstract—Natural Language Processing (NLP) is ...  positive\n",
              "86  ABSTRACT: After twenty years of disfavor, a te...  positive\n",
              "87  Text statistics are frequently used in stylome...  positive\n",
              "88  We summarize our experience using FrameNet in ...  positive\n",
              "\n",
              "[89 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVUykFzUtBX9",
        "outputId": "78394be7-94af-427d-e4f3-cc44c96b6240"
      },
      "source": [
        "from textblob import TextBlob\n",
        "polar=[]\n",
        "for x in df['Titles']:\n",
        "  blob = TextBlob(x)\n",
        "  for sentence in blob.sentences:\n",
        "    polar.append(sentence.sentiment.polarity)\n",
        "neutral=0\n",
        "positive=0\n",
        "negative=0\n",
        "for x in polar:\n",
        "  if x==0.0:\n",
        "    neutral+=1\n",
        "  elif x>0:\n",
        "    positive+=1\n",
        "  else: negative+=1\n",
        "print(\" no of positive analysis \",pos)\n",
        "print(\"no of negative analysis\",neg)\n",
        "print(\"no of neutral analysis\",neutral)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " no of positive analysis  107\n",
            "no of negative analysis 18\n",
            "no of neutral analysis 99\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7o5MhWpwtMwh",
        "outputId": "af62a026-6c13-45af-b61e-2e62e4a613c8"
      },
      "source": [
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "analyser = SentimentIntensityAnalyzer()\n",
        "def analysis_scores(sentence):\n",
        "    result = analyser.polarity_scores(sentence)\n",
        "    print(\"{:-<40} {}\".format(sentence, str(result)))\n",
        "for x in df['Titles'][:5]:\n",
        "  analysis_scores(x)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "text directly (rather than e.g. titles and abstracts), and suggests appropriate approaches to doing this, with a focus on the role of natural language processing. The paper also comments on possible connections with data and knowledge retrieval, and concludes by emphasizing the importance of rigorous  {'neg': 0.043, 'neu': 0.855, 'pos': 0.102, 'compound': 0.4404}\n",
            "ABSTRACT: Language is way of communicating your words Language helps in understanding the world,we get a better insight of the world. Language helps speakers to be as vague or as precise as they like. NLP Stands for natural language processing.. Natural languages are those languages that are spoken  {'neg': 0.024, 'neu': 0.707, 'pos': 0.269, 'compound': 0.9217}\n",
            "We report experiments on the use of standard natural language processing (NLP) tools for the analysis of music lyrics. A significant amount of music audio has lyrics. Lyrics encode an important part of the semantics of a song, therefore their analysis complements that of acoustic and cultural  {'neg': 0.0, 'neu': 0.878, 'pos': 0.122, 'compound': 0.6249}\n",
            "this paper, we will describe a simple rule-based approach to automated learning of linguistic knowledge. This approach has been shown for a number of tasks to capture information in a clearer and more direct fashion without a compromise in performance. We present a detailed case study of this learning method applied to part of speech tagging  {'neg': 0.0, 'neu': 0.977, 'pos': 0.023, 'compound': 0.0772}\n",
            "This paper focuses on connectionist models in natural language processing. We briefly present and discuss several aspects of high level tasks which recently have been approached with connectionism, either with localist or parallel distributed processing models. Several interesting architectures  {'neg': 0.0, 'neu': 0.877, 'pos': 0.123, 'compound': 0.6369}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoU8gNhjupQl"
      },
      "source": [
        "train_set=df[:80]\n",
        "test_set=df[80:]\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(min_df = 5,max_df = 0.8,sublinear_tf = True,use_idf = True)\n",
        "train_vectors = vectorizer.fit_transform(train['Titles'])\n",
        "test_vectors = vectorizer.transform(test['Titles'])"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3appq_LcvQ2a",
        "outputId": "c57dcc45-b3b2-4e13-e9f3-688faf445532"
      },
      "source": [
        "import time\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import classification_report\n",
        "classifier_linear = svm.SVC(kernel='linear')\n",
        "t0 = time.time()\n",
        "classifier_linear.fit(train_vectors, train['sentiment'])\n",
        "t1 = time.time()\n",
        "prediction_linear = classifier_linear.predict(test_vectors)\n",
        "t2 = time.time()\n",
        "time_linear_train = t1-t0\n",
        "time_linear_predict = t2-t1\n",
        "print(\"Training time: %fs; Prediction time: %fs\" % (time_linear_train, time_linear_predict))\n",
        "report = classification_report(test['sentiment'], prediction_linear, output_dict=True)\n",
        "print('positive: ', report['positive'])\n",
        "##print('negative: ', report['negative'])\n",
        "##print(\"neutral:\", report['neutral'])"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training time: 0.005335s; Prediction time: 0.000562s\n",
            "positive:  {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 9}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFjuqb-vwGME"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}