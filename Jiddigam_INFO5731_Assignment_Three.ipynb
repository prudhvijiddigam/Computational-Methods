{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Jiddigam_INFO5731_Assignment_Three.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prudhvijiddigam/Computational-Methods/blob/main/Jiddigam_INFO5731_Assignment_Three.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USSdXHuqnwv9"
      },
      "source": [
        "# **INFO5731 Assignment Three**\n",
        "\n",
        "In this assignment, you are required to conduct information extraction, semantic analysis based on **the dataset you collected from assignment two**. You may use scipy and numpy package in this assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWxodXh5n4xF"
      },
      "source": [
        "# **Question 1: Understand N-gram**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TenBkDJ5n95k"
      },
      "source": [
        "(45 points). Write a python program to conduct N-gram analysis based on the dataset in your assignment two:\n",
        "\n",
        "(1) Count the frequency of all the N-grams (N=3).\n",
        "\n",
        "(2) Calculate the probabilities for all the bigrams in the dataset by using the fomular count(w2 w1) / count(w2). For example, count(really like) / count(really) = 1 / 3 = 0.33.\n",
        "\n",
        "(3) Extract all the **noun phrases** and calculate the relative probabilities of each review in terms of other reviews (abstracts, or tweets) by using the fomular frequency (noun phrase) / max frequency (noun phrase) on the whole dataset. Print out the result in a table with column name the all the noun phrases and row name as all the 100 reviews (abstracts, or tweets). \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuFPKhC0m1fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5347ce2e-1632-4766-b92a-2c9e761bce2b"
      },
      "source": [
        "# Write your code here\n",
        "import nltk, re, string, collections\n",
        "from nltk.corpus import stopwords\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "from pandas import DataFrame\n",
        "\n",
        "\n",
        "df = pd.read_csv('Data.csv')\n",
        "\n",
        "def clean_text(text):\n",
        "    '''Make text lowercase, remove text in square brackets, remove punctuation and remove words containing numbers.'''\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r'\\[.*?\\]', '', text)\n",
        "    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text)\n",
        "    text = re.sub(r'\\w*\\d\\w*', '', text)\n",
        "    return text\n",
        "\n",
        "df.columns = ['Paper']\n",
        "Data_main_list = []\n",
        "for name in df.Paper:\n",
        "  cleaned_text = clean_text(name)\n",
        "  Data_main_list.append(cleaned_text)\n",
        "df_clean = pd.DataFrame(Data_main_list) \n",
        "df_clean.columns = ['Paper']\n",
        "print(df_clean)\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                Paper\n",
            "0   text directly rather than eg titles and abstra...\n",
            "1   abstract language is way of communicating your...\n",
            "2   we report experiments on the use of standard n...\n",
            "3   this paper we will describe a simple rulebased...\n",
            "4   this paper focuses on connectionist models in ...\n",
            "..                                                ...\n",
            "86  abstract after twenty years of disfavor a tech...\n",
            "87  text statistics are frequently used in stylome...\n",
            "88  we summarize our experience using framenet in ...\n",
            "89  research in natural language processing nlp ha...\n",
            "90  natural language processing nlp programs are c...\n",
            "\n",
            "[91 rows x 1 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mN0IJ_6Orxnu",
        "outputId": "733f2f73-5a77-44b9-e631-470f2bb8d140"
      },
      "source": [
        "from nltk.util import ngrams \n",
        "import nltk, re, string, collections\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "df1 = df_clean.Paper.values\n",
        "df1 = ' '.join([review for review in df1])\n",
        "df1\n",
        "\n",
        "tokens = nltk.word_tokenize(df1)\n",
        "def count_freq(text, order):\n",
        "    t = ngrams(text, order)\n",
        "    t_freq = collections.Counter(t)\n",
        "    return t_freq\n",
        "\n",
        "\n",
        "Ngrams = count_freq(tokens, 3)\n",
        "Ngrams= [print(b,t) for b, t in Ngrams.items()]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "('text', 'directly', 'rather') 1\n",
            "('directly', 'rather', 'than') 1\n",
            "('rather', 'than', 'eg') 1\n",
            "('than', 'eg', 'titles') 1\n",
            "('eg', 'titles', 'and') 1\n",
            "('titles', 'and', 'abstracts') 1\n",
            "('and', 'abstracts', 'and') 1\n",
            "('abstracts', 'and', 'suggests') 1\n",
            "('and', 'suggests', 'appropriate') 1\n",
            "('suggests', 'appropriate', 'approaches') 1\n",
            "('appropriate', 'approaches', 'to') 1\n",
            "('approaches', 'to', 'doing') 1\n",
            "('to', 'doing', 'this') 1\n",
            "('doing', 'this', 'with') 1\n",
            "('this', 'with', 'a') 1\n",
            "('with', 'a', 'focus') 3\n",
            "('a', 'focus', 'on') 3\n",
            "('focus', 'on', 'the') 1\n",
            "('on', 'the', 'role') 1\n",
            "('the', 'role', 'of') 2\n",
            "('role', 'of', 'natural') 1\n",
            "('of', 'natural', 'language') 12\n",
            "('natural', 'language', 'processing') 60\n",
            "('language', 'processing', 'the') 2\n",
            "('processing', 'the', 'paper') 1\n",
            "('the', 'paper', 'also') 1\n",
            "('paper', 'also', 'comments') 1\n",
            "('also', 'comments', 'on') 1\n",
            "('comments', 'on', 'possible') 1\n",
            "('on', 'possible', 'connections') 1\n",
            "('possible', 'connections', 'with') 1\n",
            "('connections', 'with', 'data') 1\n",
            "('with', 'data', 'and') 1\n",
            "('data', 'and', 'knowledge') 1\n",
            "('and', 'knowledge', 'retrieval') 1\n",
            "('knowledge', 'retrieval', 'and') 1\n",
            "('retrieval', 'and', 'concludes') 1\n",
            "('and', 'concludes', 'by') 1\n",
            "('concludes', 'by', 'emphasizing') 1\n",
            "('by', 'emphasizing', 'the') 1\n",
            "('emphasizing', 'the', 'importance') 1\n",
            "('the', 'importance', 'of') 1\n",
            "('importance', 'of', 'rigorous') 1\n",
            "('of', 'rigorous', 'abstract') 1\n",
            "('rigorous', 'abstract', 'language') 1\n",
            "('abstract', 'language', 'is') 1\n",
            "('language', 'is', 'way') 1\n",
            "('is', 'way', 'of') 1\n",
            "('way', 'of', 'communicating') 1\n",
            "('of', 'communicating', 'your') 1\n",
            "('communicating', 'your', 'words') 1\n",
            "('your', 'words', 'language') 1\n",
            "('words', 'language', 'helps') 1\n",
            "('language', 'helps', 'in') 1\n",
            "('helps', 'in', 'understanding') 1\n",
            "('in', 'understanding', 'the') 1\n",
            "('understanding', 'the', 'worldwe') 1\n",
            "('the', 'worldwe', 'get') 1\n",
            "('worldwe', 'get', 'a') 1\n",
            "('get', 'a', 'better') 1\n",
            "('a', 'better', 'insight') 1\n",
            "('better', 'insight', 'of') 1\n",
            "('insight', 'of', 'the') 1\n",
            "('of', 'the', 'world') 1\n",
            "('the', 'world', 'language') 1\n",
            "('world', 'language', 'helps') 1\n",
            "('language', 'helps', 'speakers') 1\n",
            "('helps', 'speakers', 'to') 1\n",
            "('speakers', 'to', 'be') 1\n",
            "('to', 'be', 'as') 1\n",
            "('be', 'as', 'vague') 1\n",
            "('as', 'vague', 'or') 1\n",
            "('vague', 'or', 'as') 1\n",
            "('or', 'as', 'precise') 1\n",
            "('as', 'precise', 'as') 1\n",
            "('precise', 'as', 'they') 1\n",
            "('as', 'they', 'like') 1\n",
            "('they', 'like', 'nlp') 1\n",
            "('like', 'nlp', 'stands') 1\n",
            "('nlp', 'stands', 'for') 1\n",
            "('stands', 'for', 'natural') 1\n",
            "('for', 'natural', 'language') 4\n",
            "('language', 'processing', 'natural') 1\n",
            "('processing', 'natural', 'languages') 1\n",
            "('natural', 'languages', 'are') 1\n",
            "('languages', 'are', 'those') 1\n",
            "('are', 'those', 'languages') 1\n",
            "('those', 'languages', 'that') 1\n",
            "('languages', 'that', 'are') 1\n",
            "('that', 'are', 'spoken') 1\n",
            "('are', 'spoken', 'we') 1\n",
            "('spoken', 'we', 'report') 1\n",
            "('we', 'report', 'experiments') 1\n",
            "('report', 'experiments', 'on') 1\n",
            "('experiments', 'on', 'the') 1\n",
            "('on', 'the', 'use') 1\n",
            "('the', 'use', 'of') 4\n",
            "('use', 'of', 'standard') 1\n",
            "('of', 'standard', 'natural') 1\n",
            "('standard', 'natural', 'language') 1\n",
            "('language', 'processing', 'nlp') 19\n",
            "('processing', 'nlp', 'tools') 1\n",
            "('nlp', 'tools', 'for') 1\n",
            "('tools', 'for', 'the') 1\n",
            "('for', 'the', 'analysis') 1\n",
            "('the', 'analysis', 'of') 1\n",
            "('analysis', 'of', 'music') 1\n",
            "('of', 'music', 'lyrics') 1\n",
            "('music', 'lyrics', 'a') 1\n",
            "('lyrics', 'a', 'significant') 1\n",
            "('a', 'significant', 'amount') 1\n",
            "('significant', 'amount', 'of') 1\n",
            "('amount', 'of', 'music') 1\n",
            "('of', 'music', 'audio') 1\n",
            "('music', 'audio', 'has') 1\n",
            "('audio', 'has', 'lyrics') 1\n",
            "('has', 'lyrics', 'lyrics') 1\n",
            "('lyrics', 'lyrics', 'encode') 1\n",
            "('lyrics', 'encode', 'an') 1\n",
            "('encode', 'an', 'important') 1\n",
            "('an', 'important', 'part') 1\n",
            "('important', 'part', 'of') 1\n",
            "('part', 'of', 'the') 1\n",
            "('of', 'the', 'semantics') 1\n",
            "('the', 'semantics', 'of') 1\n",
            "('semantics', 'of', 'a') 1\n",
            "('of', 'a', 'song') 1\n",
            "('a', 'song', 'therefore') 1\n",
            "('song', 'therefore', 'their') 1\n",
            "('therefore', 'their', 'analysis') 1\n",
            "('their', 'analysis', 'complements') 1\n",
            "('analysis', 'complements', 'that') 1\n",
            "('complements', 'that', 'of') 1\n",
            "('that', 'of', 'acoustic') 1\n",
            "('of', 'acoustic', 'and') 1\n",
            "('acoustic', 'and', 'cultural') 1\n",
            "('and', 'cultural', 'this') 1\n",
            "('cultural', 'this', 'paper') 1\n",
            "('this', 'paper', 'we') 6\n",
            "('paper', 'we', 'will') 2\n",
            "('we', 'will', 'describe') 1\n",
            "('will', 'describe', 'a') 1\n",
            "('describe', 'a', 'simple') 1\n",
            "('a', 'simple', 'rulebased') 1\n",
            "('simple', 'rulebased', 'approach') 1\n",
            "('rulebased', 'approach', 'to') 1\n",
            "('approach', 'to', 'automated') 1\n",
            "('to', 'automated', 'learning') 1\n",
            "('automated', 'learning', 'of') 1\n",
            "('learning', 'of', 'linguistic') 1\n",
            "('of', 'linguistic', 'knowledge') 2\n",
            "('linguistic', 'knowledge', 'this') 1\n",
            "('knowledge', 'this', 'approach') 1\n",
            "('this', 'approach', 'has') 1\n",
            "('approach', 'has', 'been') 1\n",
            "('has', 'been', 'shown') 1\n",
            "('been', 'shown', 'for') 1\n",
            "('shown', 'for', 'a') 1\n",
            "('for', 'a', 'number') 1\n",
            "('a', 'number', 'of') 3\n",
            "('number', 'of', 'tasks') 2\n",
            "('of', 'tasks', 'to') 1\n",
            "('tasks', 'to', 'capture') 1\n",
            "('to', 'capture', 'information') 1\n",
            "('capture', 'information', 'in') 1\n",
            "('information', 'in', 'a') 1\n",
            "('in', 'a', 'clearer') 1\n",
            "('a', 'clearer', 'and') 1\n",
            "('clearer', 'and', 'more') 1\n",
            "('and', 'more', 'direct') 1\n",
            "('more', 'direct', 'fashion') 1\n",
            "('direct', 'fashion', 'without') 1\n",
            "('fashion', 'without', 'a') 1\n",
            "('without', 'a', 'compromise') 1\n",
            "('a', 'compromise', 'in') 1\n",
            "('compromise', 'in', 'performance') 1\n",
            "('in', 'performance', 'we') 1\n",
            "('performance', 'we', 'present') 1\n",
            "('we', 'present', 'a') 1\n",
            "('present', 'a', 'detailed') 1\n",
            "('a', 'detailed', 'case') 1\n",
            "('detailed', 'case', 'study') 1\n",
            "('case', 'study', 'of') 1\n",
            "('study', 'of', 'this') 1\n",
            "('of', 'this', 'learning') 1\n",
            "('this', 'learning', 'method') 1\n",
            "('learning', 'method', 'applied') 1\n",
            "('method', 'applied', 'to') 1\n",
            "('applied', 'to', 'part') 1\n",
            "('to', 'part', 'of') 1\n",
            "('part', 'of', 'speech') 1\n",
            "('of', 'speech', 'tagging') 1\n",
            "('speech', 'tagging', 'this') 1\n",
            "('tagging', 'this', 'paper') 1\n",
            "('this', 'paper', 'focuses') 1\n",
            "('paper', 'focuses', 'on') 1\n",
            "('focuses', 'on', 'connectionist') 1\n",
            "('on', 'connectionist', 'models') 1\n",
            "('connectionist', 'models', 'in') 1\n",
            "('models', 'in', 'natural') 1\n",
            "('in', 'natural', 'language') 17\n",
            "('language', 'processing', 'we') 4\n",
            "('processing', 'we', 'briefly') 1\n",
            "('we', 'briefly', 'present') 1\n",
            "('briefly', 'present', 'and') 1\n",
            "('present', 'and', 'discuss') 1\n",
            "('and', 'discuss', 'several') 1\n",
            "('discuss', 'several', 'aspects') 1\n",
            "('several', 'aspects', 'of') 1\n",
            "('aspects', 'of', 'high') 1\n",
            "('of', 'high', 'level') 1\n",
            "('high', 'level', 'tasks') 1\n",
            "('level', 'tasks', 'which') 1\n",
            "('tasks', 'which', 'recently') 1\n",
            "('which', 'recently', 'have') 1\n",
            "('recently', 'have', 'been') 1\n",
            "('have', 'been', 'approached') 1\n",
            "('been', 'approached', 'with') 1\n",
            "('approached', 'with', 'connectionism') 1\n",
            "('with', 'connectionism', 'either') 1\n",
            "('connectionism', 'either', 'with') 1\n",
            "('either', 'with', 'localist') 1\n",
            "('with', 'localist', 'or') 1\n",
            "('localist', 'or', 'parallel') 1\n",
            "('or', 'parallel', 'distributed') 1\n",
            "('parallel', 'distributed', 'processing') 1\n",
            "('distributed', 'processing', 'models') 1\n",
            "('processing', 'models', 'several') 1\n",
            "('models', 'several', 'interesting') 1\n",
            "('several', 'interesting', 'architectures') 1\n",
            "('interesting', 'architectures', 'process') 1\n",
            "('architectures', 'process', 'of') 1\n",
            "('process', 'of', 'language') 1\n",
            "('of', 'language', 'understanding') 1\n",
            "('language', 'understanding', 'this') 1\n",
            "('understanding', 'this', 'is') 1\n",
            "('this', 'is', 'a') 1\n",
            "('is', 'a', 'new') 1\n",
            "('a', 'new', 'approach') 1\n",
            "('new', 'approach', 'in') 1\n",
            "('approach', 'in', 'natural') 1\n",
            "('language', 'processing', 'based') 1\n",
            "('processing', 'based', 'on') 1\n",
            "('based', 'on', 'the') 2\n",
            "('on', 'the', 'deterministic') 1\n",
            "('the', 'deterministic', 'chaotic') 1\n",
            "('deterministic', 'chaotic', 'behavior') 1\n",
            "('chaotic', 'behavior', 'of') 1\n",
            "('behavior', 'of', 'dynamical') 1\n",
            "('of', 'dynamical', 'systems') 1\n",
            "('dynamical', 'systems', 'this') 1\n",
            "('systems', 'this', 'paper') 3\n",
            "('this', 'paper', 'see') 1\n",
            "('paper', 'see', 'for') 1\n",
            "('see', 'for', 'a') 1\n",
            "('for', 'a', 'theoretical') 1\n",
            "('a', 'theoretical', 'discussion') 1\n",
            "('theoretical', 'discussion', 'and') 1\n",
            "('discussion', 'and', 'and') 1\n",
            "('and', 'and', 'for') 1\n",
            "('and', 'for', 'brief') 1\n",
            "('for', 'brief', 'discussions') 1\n",
            "('brief', 'discussions', 'of') 1\n",
            "('discussions', 'of', 'a') 1\n",
            "('of', 'a', 'program') 1\n",
            "('a', 'program', 'built') 1\n",
            "('program', 'built', 'around') 1\n",
            "('built', 'around', 'these') 1\n",
            "('around', 'these', 'principles') 1\n",
            "('these', 'principles', 'the') 1\n",
            "('principles', 'the', 'goal') 1\n",
            "('the', 'goal', 'here') 1\n",
            "('goal', 'here', 'is') 1\n",
            "('here', 'is', 'simply') 1\n",
            "('is', 'simply', 'to') 1\n",
            "('simply', 'to', 'point') 1\n",
            "('to', 'point', 'out') 1\n",
            "('point', 'out', 'how') 1\n",
            "('out', 'how', 'our') 1\n",
            "('how', 'our', 'interest') 1\n",
            "('our', 'interest', 'in') 1\n",
            "('interest', 'in', 'natural') 1\n",
            "('language', 'processing', 'has') 2\n",
            "('processing', 'has', 'led') 1\n",
            "('has', 'led', 'us') 1\n",
            "('led', 'us', 'naturally') 1\n",
            "('us', 'naturally', 'and') 1\n",
            "('naturally', 'and', 'indeed') 1\n",
            "('and', 'indeed', 'inevitably') 1\n",
            "('indeed', 'inevitably', 'objectives') 1\n",
            "('inevitably', 'objectives', 'to') 1\n",
            "('objectives', 'to', 'provide') 1\n",
            "('to', 'provide', 'an') 1\n",
            "('provide', 'an', 'overview') 1\n",
            "('an', 'overview', 'and') 1\n",
            "('overview', 'and', 'tutorial') 1\n",
            "('and', 'tutorial', 'of') 1\n",
            "('tutorial', 'of', 'natural') 1\n",
            "('processing', 'nlp', 'and') 1\n",
            "('nlp', 'and', 'modern') 1\n",
            "('and', 'modern', 'nlpsystem') 1\n",
            "('modern', 'nlpsystem', 'design') 1\n",
            "('nlpsystem', 'design', 'target') 1\n",
            "('design', 'target', 'audience') 1\n",
            "('target', 'audience', 'this') 1\n",
            "('audience', 'this', 'tutorial') 1\n",
            "('this', 'tutorial', 'targets') 1\n",
            "('tutorial', 'targets', 'the') 1\n",
            "('targets', 'the', 'medical') 1\n",
            "('the', 'medical', 'informatics') 1\n",
            "('medical', 'informatics', 'generalist') 1\n",
            "('informatics', 'generalist', 'who') 1\n",
            "('generalist', 'who', 'has') 1\n",
            "('who', 'has', 'limited') 1\n",
            "('has', 'limited', 'acquaintance') 1\n",
            "('limited', 'acquaintance', 'with') 1\n",
            "('acquaintance', 'with', 'the') 1\n",
            "('with', 'the', 'principles') 1\n",
            "('the', 'principles', 'behind') 1\n",
            "('principles', 'behind', 'nlp') 1\n",
            "('behind', 'nlp', 'andor') 1\n",
            "('nlp', 'andor', 'limited') 1\n",
            "('andor', 'limited', 'knowledge') 1\n",
            "('limited', 'knowledge', 'of') 1\n",
            "('knowledge', 'of', 'the') 1\n",
            "('of', 'the', 'current') 2\n",
            "('the', 'current', 'state') 2\n",
            "('current', 'state', 'this') 1\n",
            "('state', 'this', 'paper') 1\n",
            "('this', 'paper', 'briefly') 1\n",
            "('paper', 'briefly', 'describes') 1\n",
            "('briefly', 'describes', 'the') 1\n",
            "('describes', 'the', 'current') 1\n",
            "('the', 'current', 'implementation') 1\n",
            "('current', 'implementation', 'status') 1\n",
            "('implementation', 'status', 'of') 1\n",
            "('status', 'of', 'an') 1\n",
            "('of', 'an', 'intelligent') 1\n",
            "('an', 'intelligent', 'information') 1\n",
            "('intelligent', 'information', 'retrieval') 1\n",
            "('information', 'retrieval', 'system') 2\n",
            "('retrieval', 'system', 'marie') 1\n",
            "('system', 'marie', 'that') 1\n",
            "('marie', 'that', 'employs') 1\n",
            "('that', 'employs', 'natural') 1\n",
            "('employs', 'natural', 'language') 1\n",
            "('language', 'processing', 'techniques') 3\n",
            "('processing', 'techniques', 'descriptive') 1\n",
            "('techniques', 'descriptive', 'captions') 1\n",
            "('descriptive', 'captions', 'are') 1\n",
            "('captions', 'are', 'used') 1\n",
            "('are', 'used', 'to') 1\n",
            "('used', 'to', 'iden') 1\n",
            "('to', 'iden', 'tify') 1\n",
            "('iden', 'tify', 'photographic') 1\n",
            "('tify', 'photographic', 'images') 1\n",
            "('photographic', 'images', 'concerning') 1\n",
            "('images', 'concerning', 'various') 1\n",
            "('concerning', 'various', 'military') 1\n",
            "('various', 'military', 'projects') 1\n",
            "('military', 'projects', 'the') 1\n",
            "('projects', 'the', 'captions') 1\n",
            "('the', 'captions', 'are') 1\n",
            "('captions', 'are', 'parsed') 1\n",
            "('are', 'parsed', 'based') 1\n",
            "('parsed', 'based', 'and') 1\n",
            "('based', 'and', 'literature') 1\n",
            "('and', 'literature', 'resources') 1\n",
            "('literature', 'resources', 'we') 1\n",
            "('resources', 'we', 'describe') 1\n",
            "('we', 'describe', 'here') 1\n",
            "('describe', 'here', 'a') 1\n",
            "('here', 'a', 'system') 1\n",
            "('a', 'system', 'for') 1\n",
            "('system', 'for', 'agent') 1\n",
            "('for', 'agent', 'directed') 1\n",
            "('agent', 'directed', 'natural') 1\n",
            "('directed', 'natural', 'language') 1\n",
            "('language', 'processing', 'to') 3\n",
            "('processing', 'to', 'extract') 1\n",
            "('to', 'extract', 'information') 1\n",
            "('extract', 'information', 'from') 1\n",
            "('information', 'from', 'journal') 1\n",
            "('from', 'journal', 'articles') 1\n",
            "('journal', 'articles', 'an') 1\n",
            "('articles', 'an', 'interface') 1\n",
            "('an', 'interface', 'was') 1\n",
            "('interface', 'was', 'developed') 1\n",
            "('was', 'developed', 'to') 1\n",
            "('developed', 'to', 'permit') 1\n",
            "('to', 'permit', 'curation') 1\n",
            "('permit', 'curation', 'of') 1\n",
            "('curation', 'of', 'the') 1\n",
            "('of', 'the', 'nlp') 1\n",
            "('the', 'nlp', 'results') 1\n",
            "('nlp', 'results', 'and') 1\n",
            "('results', 'and', 'deposition') 1\n",
            "('and', 'deposition', 'of') 1\n",
            "('deposition', 'of', 'accepted') 1\n",
            "('of', 'accepted', 'results') 1\n",
            "('accepted', 'results', 'into') 1\n",
            "('results', 'into', 'a') 1\n",
            "('into', 'a', 'knowledge') 1\n",
            "('a', 'knowledge', 'base') 1\n",
            "('knowledge', 'base', 'motivation') 1\n",
            "('base', 'motivation', 'the') 1\n",
            "('motivation', 'the', 'advent') 1\n",
            "('the', 'advent', 'of') 1\n",
            "('advent', 'of', 'high') 1\n",
            "('of', 'high', 'to') 1\n",
            "('high', 'to', 'evaluation') 1\n",
            "('to', 'evaluation', 'in') 1\n",
            "('evaluation', 'in', 'speech') 1\n",
            "('in', 'speech', 'processing') 1\n",
            "('speech', 'processing', 'part') 1\n",
            "('processing', 'part', 'surveys') 1\n",
            "('part', 'surveys', 'significant') 1\n",
            "('surveys', 'significant', 'evaluation') 1\n",
            "('significant', 'evaluation', 'work') 1\n",
            "('evaluation', 'work', 'done') 1\n",
            "('work', 'done', 'so') 1\n",
            "('done', 'so', 'far') 1\n",
            "('so', 'far', 'for') 1\n",
            "('far', 'for', 'instance') 1\n",
            "('for', 'instance', 'in') 1\n",
            "('instance', 'in', 'machine') 1\n",
            "('in', 'machine', 'translation') 1\n",
            "('machine', 'translation', 'and') 2\n",
            "('translation', 'and', 'discusses') 1\n",
            "('and', 'discusses', 'the') 1\n",
            "('discusses', 'the', 'particular') 1\n",
            "('the', 'particular', 'problems') 1\n",
            "('particular', 'problems', 'of') 1\n",
            "('problems', 'of', 'generic') 1\n",
            "('of', 'generic', 'system') 1\n",
            "('generic', 'system', 'evaluation') 1\n",
            "('system', 'evaluation', 'the') 1\n",
            "('evaluation', 'the', 'conclusion') 1\n",
            "('the', 'conclusion', 'is') 1\n",
            "('conclusion', 'is', 'that') 1\n",
            "('is', 'that', 'evaluation') 1\n",
            "('that', 'evaluation', 'strategies') 1\n",
            "('evaluation', 'strategies', 'and') 1\n",
            "('strategies', 'and', 'techniques') 1\n",
            "('and', 'techniques', 'for') 1\n",
            "('techniques', 'for', 'nlp') 1\n",
            "('for', 'nlp', 'need') 1\n",
            "('nlp', 'need', 'much') 1\n",
            "('need', 'much', 'more') 1\n",
            "('much', 'more', 'development') 1\n",
            "('more', 'development', 'in') 1\n",
            "('development', 'in', 'particular') 1\n",
            "('in', 'particular', 'similar') 1\n",
            "('particular', 'similar', 'to') 1\n",
            "('similar', 'to', 'the') 1\n",
            "('to', 'the', 'way') 1\n",
            "('the', 'way', 'humans') 1\n",
            "('way', 'humans', 'intuitively') 1\n",
            "('humans', 'intuitively', 'do') 1\n",
            "('intuitively', 'do', 'in') 1\n",
            "('do', 'in', 'order') 1\n",
            "('in', 'order', 'to') 2\n",
            "('order', 'to', 'eliminate') 1\n",
            "('to', 'eliminate', 'noisy') 1\n",
            "('eliminate', 'noisy', 'content') 1\n",
            "('noisy', 'content', 'in') 1\n",
            "('content', 'in', 'this') 1\n",
            "('in', 'this', 'paper') 5\n",
            "('paper', 'we', 'describe') 2\n",
            "('we', 'describe', 'a') 3\n",
            "('describe', 'a', 'combination') 1\n",
            "('a', 'combination', 'of') 1\n",
            "('combination', 'of', 'html') 1\n",
            "('of', 'html', 'dom') 1\n",
            "('html', 'dom', 'analysis') 1\n",
            "('dom', 'analysis', 'and') 1\n",
            "('analysis', 'and', 'natural') 1\n",
            "('and', 'natural', 'language') 2\n",
            "('processing', 'nlp', 'techniques') 2\n",
            "('nlp', 'techniques', 'for') 1\n",
            "('techniques', 'for', 'automated') 1\n",
            "('for', 'automated', 'extractions') 1\n",
            "('automated', 'extractions', 'of') 1\n",
            "('extractions', 'of', 'main') 1\n",
            "('of', 'main', 'article') 1\n",
            "('main', 'article', 'with') 1\n",
            "('article', 'with', 'associated') 1\n",
            "('with', 'associated', 'images') 1\n",
            "('associated', 'images', 'from') 1\n",
            "('images', 'from', 'web') 1\n",
            "('from', 'web', 'pages') 1\n",
            "('web', 'pages', 'abstract') 1\n",
            "('pages', 'abstract', 'natural') 1\n",
            "('abstract', 'natural', 'language') 2\n",
            "('language', 'processing', 'is') 3\n",
            "('processing', 'is', 'a') 1\n",
            "('is', 'a', 'theoretically') 1\n",
            "('a', 'theoretically', 'motivated') 1\n",
            "('theoretically', 'motivated', 'range') 1\n",
            "('motivated', 'range', 'of') 1\n",
            "('range', 'of', 'computational') 1\n",
            "('of', 'computational', 'techniques') 1\n",
            "('computational', 'techniques', 'for') 1\n",
            "('techniques', 'for', 'analysing') 1\n",
            "('for', 'analysing', 'and') 1\n",
            "('analysing', 'and', 'representing') 1\n",
            "('and', 'representing', 'naturally') 1\n",
            "('representing', 'naturally', 'occurring') 1\n",
            "('naturally', 'occurring', 'texts') 1\n",
            "('occurring', 'texts', 'at') 1\n",
            "('texts', 'at', 'one') 1\n",
            "('at', 'one', 'or') 1\n",
            "('one', 'or', 'more') 1\n",
            "('or', 'more', 'levels') 1\n",
            "('more', 'levels', 'of') 1\n",
            "('levels', 'of', 'linguistic') 1\n",
            "('of', 'linguistic', 'analysis') 1\n",
            "('linguistic', 'analysis', 'for') 1\n",
            "('analysis', 'for', 'the') 1\n",
            "('for', 'the', 'purpose') 1\n",
            "('the', 'purpose', 'of') 1\n",
            "('purpose', 'of', 'achieving') 1\n",
            "('of', 'achieving', 'humanlike') 1\n",
            "('achieving', 'humanlike', 'language') 1\n",
            "('humanlike', 'language', 'processing') 1\n",
            "('language', 'processing', 'for') 2\n",
            "('processing', 'for', 'a') 1\n",
            "('for', 'a', 'range') 1\n",
            "('a', 'range', 'of') 2\n",
            "('range', 'of', 'tasks') 1\n",
            "('of', 'tasks', 'this') 1\n",
            "('tasks', 'this', 'paper') 1\n",
            "('this', 'paper', 'reviews') 2\n",
            "('paper', 'reviews', 'the') 2\n",
            "('reviews', 'the', 'processes') 1\n",
            "('the', 'processes', 'involved') 1\n",
            "('processes', 'involved', 'in') 1\n",
            "('involved', 'in', 'natural') 1\n",
            "('processing', 'nlp', 'it') 1\n",
            "('nlp', 'it', 'then') 1\n",
            "('it', 'then', 'demonstrates') 1\n",
            "('then', 'demonstrates', 'the') 1\n",
            "('demonstrates', 'the', 'various') 1\n",
            "('the', 'various', 'kinds') 1\n",
            "('various', 'kinds', 'of') 1\n",
            "('kinds', 'of', 'choices') 1\n",
            "('of', 'choices', 'that') 1\n",
            "('choices', 'that', 'need') 1\n",
            "('that', 'need', 'be') 1\n",
            "('need', 'be', 'taken') 1\n",
            "('be', 'taken', 'during') 1\n",
            "('taken', 'during', 'the') 1\n",
            "('during', 'the', 'execution') 1\n",
            "('the', 'execution', 'of') 1\n",
            "('execution', 'of', 'the') 1\n",
            "('of', 'the', 'word') 2\n",
            "('the', 'word', 'morphology') 1\n",
            "('word', 'morphology', 'the') 1\n",
            "('morphology', 'the', 'syntactic') 1\n",
            "('the', 'syntactic', 'text') 1\n",
            "('syntactic', 'text', 'analysis') 1\n",
            "('text', 'analysis', 'or') 1\n",
            "('analysis', 'or', 'text') 1\n",
            "('or', 'text', 'generation') 1\n",
            "('text', 'generation', 'components') 1\n",
            "('generation', 'components', 'it') 1\n",
            "('components', 'it', 'compares') 1\n",
            "('it', 'compares', 'the') 1\n",
            "('compares', 'the', 'time') 1\n",
            "('the', 'time', 'complexity') 1\n",
            "('time', 'complexity', 'this') 1\n",
            "('complexity', 'this', 'article') 1\n",
            "('this', 'article', 'focusses') 1\n",
            "('article', 'focusses', 'on') 1\n",
            "('focusses', 'on', 'the') 1\n",
            "('on', 'the', 'derivation') 1\n",
            "('the', 'derivation', 'of') 1\n",
            "('derivation', 'of', 'large') 1\n",
            "('of', 'large', 'lexicons') 1\n",
            "('large', 'lexicons', 'for') 1\n",
            "('lexicons', 'for', 'natural') 1\n",
            "('processing', 'we', 'describe') 1\n",
            "('we', 'describe', 'the') 2\n",
            "('describe', 'the', 'development') 1\n",
            "('the', 'development', 'of') 3\n",
            "('development', 'of', 'a') 1\n",
            "('of', 'a', 'dictionary') 1\n",
            "('a', 'dictionary', 'support') 1\n",
            "('dictionary', 'support', 'environment') 1\n",
            "('support', 'environment', 'linking') 1\n",
            "('environment', 'linking', 'a') 1\n",
            "('linking', 'a', 'restructured') 1\n",
            "('a', 'restructured', 'version') 1\n",
            "('restructured', 'version', 'of') 1\n",
            "('version', 'of', 'the') 1\n",
            "('of', 'the', 'longman') 1\n",
            "('the', 'longman', 'dictionary') 1\n",
            "('longman', 'dictionary', 'of') 1\n",
            "('dictionary', 'of', 'contemporary') 1\n",
            "('of', 'contemporary', 'english') 1\n",
            "('contemporary', 'english', 'to') 1\n",
            "('english', 'to', 'natural') 1\n",
            "('to', 'natural', 'language') 2\n",
            "('language', 'processing', 'systems') 5\n",
            "('processing', 'systems', 'the') 2\n",
            "('systems', 'the', 'process') 1\n",
            "('the', 'process', 'we') 1\n",
            "('process', 'we', 'introduce') 1\n",
            "('we', 'introduce', 'a') 1\n",
            "('introduce', 'a', 'method') 1\n",
            "('a', 'method', 'for') 1\n",
            "('method', 'for', 'analyzing') 1\n",
            "('for', 'analyzing', 'the') 1\n",
            "('analyzing', 'the', 'complexity') 1\n",
            "('the', 'complexity', 'of') 1\n",
            "('complexity', 'of', 'natural') 1\n",
            "('language', 'processing', 'tasks') 1\n",
            "('processing', 'tasks', 'and') 1\n",
            "('tasks', 'and', 'for') 1\n",
            "('and', 'for', 'predicting') 1\n",
            "('for', 'predicting', 'the') 1\n",
            "('predicting', 'the', 'difficulty') 1\n",
            "('the', 'difficulty', 'new') 1\n",
            "('difficulty', 'new', 'nlp') 1\n",
            "('new', 'nlp', 'tasks') 1\n",
            "('nlp', 'tasks', 'our') 1\n",
            "('tasks', 'our', 'complexity') 1\n",
            "('our', 'complexity', 'measures') 1\n",
            "('complexity', 'measures', 'are') 1\n",
            "('measures', 'are', 'derived') 1\n",
            "('are', 'derived', 'from') 1\n",
            "('derived', 'from', 'the') 1\n",
            "('from', 'the', 'kolmogorov') 1\n",
            "('the', 'kolmogorov', 'complexity') 1\n",
            "('kolmogorov', 'complexity', 'of') 1\n",
            "('complexity', 'of', 'a') 1\n",
            "('of', 'a', 'class') 1\n",
            "('a', 'class', 'of') 1\n",
            "('class', 'of', 'automata') 1\n",
            "('of', 'automata', '—') 1\n",
            "('automata', '—', 'meaning') 1\n",
            "('—', 'meaning', 'automata') 1\n",
            "('meaning', 'automata', 'whose') 1\n",
            "('automata', 'whose', 'purpose') 1\n",
            "('whose', 'purpose', 'is') 1\n",
            "('purpose', 'is', 'to') 1\n",
            "('is', 'to', 'extract') 1\n",
            "('to', 'extract', 'relevant') 1\n",
            "('extract', 'relevant', 'pieces') 1\n",
            "('relevant', 'pieces', 'sounds') 1\n",
            "('pieces', 'sounds', 'text') 1\n",
            "('sounds', 'text', 'and') 1\n",
            "('text', 'and', 'motion') 1\n",
            "('and', 'motion', 'the') 1\n",
            "('motion', 'the', 'techniques') 1\n",
            "('the', 'techniques', 'developed') 1\n",
            "('techniques', 'developed', 'from') 1\n",
            "('developed', 'from', 'deep') 1\n",
            "('from', 'deep', 'learning') 1\n",
            "('deep', 'learning', 'research') 1\n",
            "('learning', 'research', 'have') 1\n",
            "('research', 'have', 'already') 1\n",
            "('have', 'already', 'been') 1\n",
            "('already', 'been', 'impacting') 1\n",
            "('been', 'impacting', 'the') 1\n",
            "('impacting', 'the', 'research') 1\n",
            "('the', 'research', 'of') 1\n",
            "('research', 'of', 'natural') 1\n",
            "('natural', 'language', 'process') 1\n",
            "('language', 'process', 'this') 1\n",
            "('process', 'this', 'paper') 1\n",
            "('reviews', 'the', 'recent') 1\n",
            "('the', 'recent', 'research') 1\n",
            "('recent', 'research', 'on') 1\n",
            "('research', 'on', 'deep') 1\n",
            "('on', 'deep', 'learning') 1\n",
            "('deep', 'learning', 'its') 1\n",
            "('learning', 'its', 'applications') 1\n",
            "('its', 'applications', 'and') 1\n",
            "('applications', 'and', 'recent') 1\n",
            "('and', 'recent', 'development') 1\n",
            "('recent', 'development', 'in') 2\n",
            "('development', 'in', 'natural') 2\n",
            "('language', 'processing', 'this') 1\n",
            "('processing', 'this', 'is') 1\n",
            "('this', 'is', 'an') 1\n",
            "('is', 'an', 'authorproduced') 1\n",
            "('an', 'authorproduced', 'version') 1\n",
            "('authorproduced', 'version', 'of') 1\n",
            "('version', 'of', 'a') 1\n",
            "('of', 'a', 'paper') 1\n",
            "('a', 'paper', 'published') 1\n",
            "('paper', 'published', 'in') 1\n",
            "('published', 'in', 'the') 1\n",
            "('in', 'the', 'abstract—natural') 1\n",
            "('the', 'abstract—natural', 'language') 1\n",
            "('abstract—natural', 'language', 'processing') 2\n",
            "('processing', 'nlp', 'is') 4\n",
            "('nlp', 'is', 'the') 1\n",
            "('is', 'the', 'application') 1\n",
            "('the', 'application', 'of') 4\n",
            "('application', 'of', 'automated') 1\n",
            "('of', 'automated', 'parsing') 1\n",
            "('automated', 'parsing', 'and') 1\n",
            "('parsing', 'and', 'machine') 1\n",
            "('and', 'machine', 'learning') 2\n",
            "('machine', 'learning', 'techniques') 2\n",
            "('learning', 'techniques', 'to') 1\n",
            "('techniques', 'to', 'analyze') 1\n",
            "('to', 'analyze', 'standard') 1\n",
            "('analyze', 'standard', 'text') 1\n",
            "('standard', 'text', 'applications') 1\n",
            "('text', 'applications', 'of') 1\n",
            "('applications', 'of', 'nlp') 1\n",
            "('of', 'nlp', 'to') 2\n",
            "('nlp', 'to', 'requirements') 1\n",
            "('to', 'requirements', 'engineering') 1\n",
            "('requirements', 'engineering', 'include') 1\n",
            "('engineering', 'include', 'extraction') 1\n",
            "('include', 'extraction', 'of') 1\n",
            "('extraction', 'of', 'ontologies') 1\n",
            "('of', 'ontologies', 'from') 1\n",
            "('ontologies', 'from', 'a') 1\n",
            "('from', 'a', 'requirements') 1\n",
            "('a', 'requirements', 'specification') 1\n",
            "('requirements', 'specification', 'and') 1\n",
            "('specification', 'and', 'use') 1\n",
            "('and', 'use', 'of') 2\n",
            "('use', 'of', 'nlp') 1\n",
            "('nlp', 'to', 'verify') 1\n",
            "('to', 'verify', 'the') 1\n",
            "('verify', 'the', 'consistency') 1\n",
            "('the', 'consistency', 'statistical') 1\n",
            "('consistency', 'statistical', 'baseline') 1\n",
            "('statistical', 'baseline', 'including') 1\n",
            "('baseline', 'including', 'the') 1\n",
            "('including', 'the', 'forgiving') 1\n",
            "('the', 'forgiving', 'nature') 1\n",
            "('forgiving', 'nature', 'but') 1\n",
            "('nature', 'but', 'broad') 1\n",
            "('but', 'broad', 'coverage') 1\n",
            "('broad', 'coverage', 'of') 1\n",
            "('coverage', 'of', 'the') 1\n",
            "('of', 'the', 'typical') 1\n",
            "('the', 'typical', 'retrieval') 1\n",
            "('typical', 'retrieval', 'task') 1\n",
            "('retrieval', 'task', 'the') 1\n",
            "('task', 'the', 'lack') 1\n",
            "('the', 'lack', 'of') 1\n",
            "('lack', 'of', 'good') 1\n",
            "('of', 'good', 'weighting') 1\n",
            "('good', 'weighting', 'schemes') 1\n",
            "('weighting', 'schemes', 'for') 1\n",
            "('schemes', 'for', 'compound') 1\n",
            "('for', 'compound', 'index') 1\n",
            "('compound', 'index', 'terms') 1\n",
            "('index', 'terms', 'and') 1\n",
            "('terms', 'and', 'the') 1\n",
            "('and', 'the', 'implicit') 1\n",
            "('the', 'implicit', 'linguistic') 1\n",
            "('implicit', 'linguistic', 'processing') 1\n",
            "('linguistic', 'processing', 'inherent') 1\n",
            "('processing', 'inherent', 'in') 1\n",
            "('inherent', 'in', 'the') 1\n",
            "('in', 'the', 'statistical') 1\n",
            "('the', 'statistical', 'methods') 1\n",
            "('statistical', 'methods', 'natural') 1\n",
            "('methods', 'natural', 'language') 1\n",
            "('processing', 'techniques', 'may') 1\n",
            "('techniques', 'may', 'be') 1\n",
            "('may', 'be', 'more') 1\n",
            "('be', 'more', 'important') 1\n",
            "('more', 'important', 'work') 1\n",
            "('important', 'work', 'in') 1\n",
            "('work', 'in', 'computational') 1\n",
            "('in', 'computational', 'linguistics') 2\n",
            "('computational', 'linguistics', 'began') 1\n",
            "('linguistics', 'began', 'very') 1\n",
            "('began', 'very', 'soon') 1\n",
            "('very', 'soon', 'after') 1\n",
            "('soon', 'after', 'the') 1\n",
            "('after', 'the', 'development') 1\n",
            "('development', 'of', 'the') 2\n",
            "('of', 'the', 'first') 1\n",
            "('the', 'first', 'computers') 1\n",
            "('first', 'computers', 'booth') 1\n",
            "('computers', 'booth', 'brandwood') 1\n",
            "('booth', 'brandwood', 'and') 1\n",
            "('brandwood', 'and', 'cleave') 1\n",
            "('and', 'cleave', 'yet') 1\n",
            "('cleave', 'yet', 'in') 1\n",
            "('yet', 'in', 'the') 1\n",
            "('in', 'the', 'intervening') 1\n",
            "('the', 'intervening', 'four') 1\n",
            "('intervening', 'four', 'decades') 1\n",
            "('four', 'decades', 'there') 1\n",
            "('decades', 'there', 'has') 1\n",
            "('there', 'has', 'been') 1\n",
            "('has', 'been', 'a') 1\n",
            "('been', 'a', 'pervasive') 1\n",
            "('a', 'pervasive', 'feeling') 1\n",
            "('pervasive', 'feeling', 'that') 1\n",
            "('feeling', 'that', 'progress') 1\n",
            "('that', 'progress', 'in') 1\n",
            "('progress', 'in', 'computer') 1\n",
            "('in', 'computer', 'understanding') 1\n",
            "('computer', 'understanding', 'of') 1\n",
            "('understanding', 'of', 'natural') 1\n",
            "('natural', 'language', 'has') 1\n",
            "('language', 'has', 'not') 1\n",
            "('has', 'not', 'been') 1\n",
            "('not', 'been', 'commensurate') 1\n",
            "('been', 'commensurate', 'the') 1\n",
            "('commensurate', 'the', 'voice') 1\n",
            "('the', 'voice', 'recognition') 1\n",
            "('voice', 'recognition', 'for') 1\n",
            "('recognition', 'for', 'a') 1\n",
            "('for', 'a', 'natural') 1\n",
            "('a', 'natural', 'language') 2\n",
            "('natural', 'language', 'tamil') 1\n",
            "('language', 'tamil', 'by') 1\n",
            "('tamil', 'by', 'combining') 1\n",
            "('by', 'combining', 'the') 1\n",
            "('combining', 'the', 'digital') 1\n",
            "('the', 'digital', 'and') 1\n",
            "('digital', 'and', 'mathematical') 1\n",
            "('and', 'mathematical', 'knowledge') 1\n",
            "('mathematical', 'knowledge', 'using') 1\n",
            "('knowledge', 'using', 'mfcc') 1\n",
            "('using', 'mfcc', 'and') 1\n",
            "('mfcc', 'and', 'dtw') 1\n",
            "('and', 'dtw', 'to') 1\n",
            "('dtw', 'to', 'extract') 1\n",
            "('to', 'extract', 'and') 1\n",
            "('extract', 'and', 'match') 1\n",
            "('and', 'match', 'the') 1\n",
            "('match', 'the', 'features') 1\n",
            "('the', 'features', 'to') 1\n",
            "('features', 'to', 'improve') 1\n",
            "('to', 'improve', 'the') 1\n",
            "('improve', 'the', 'accuracy') 1\n",
            "('the', 'accuracy', 'for') 1\n",
            "('accuracy', 'for', 'better') 1\n",
            "('for', 'better', 'performance') 1\n",
            "('better', 'performance', 'abstract') 1\n",
            "('performance', 'abstract', 'testing') 1\n",
            "('abstract', 'testing', 'against') 1\n",
            "('testing', 'against', 'natural') 1\n",
            "('against', 'natural', 'language') 1\n",
            "('natural', 'language', 'requirements') 1\n",
            "('language', 'requirements', 'is') 1\n",
            "('requirements', 'is', 'the') 1\n",
            "('is', 'the', 'standard') 1\n",
            "('the', 'standard', 'approach') 1\n",
            "('standard', 'approach', 'for') 1\n",
            "('approach', 'for', 'system') 1\n",
            "('for', 'system', 'and') 1\n",
            "('system', 'and', 'acceptance') 1\n",
            "('and', 'acceptance', 'testing') 1\n",
            "('acceptance', 'testing', 'this') 1\n",
            "('testing', 'this', 'test') 1\n",
            "('this', 'test', 'is') 1\n",
            "('test', 'is', 'often') 1\n",
            "('is', 'often', 'performed') 1\n",
            "('often', 'performed', 'by') 1\n",
            "('performed', 'by', 'an') 1\n",
            "('by', 'an', 'independent') 1\n",
            "('an', 'independent', 'test') 1\n",
            "('independent', 'test', 'organization') 1\n",
            "('test', 'organization', 'unfamiliar') 1\n",
            "('organization', 'unfamiliar', 'with') 1\n",
            "('unfamiliar', 'with', 'the') 1\n",
            "('with', 'the', 'application') 1\n",
            "('the', 'application', 'area') 1\n",
            "('application', 'area', 'the') 1\n",
            "('area', 'the', 'only') 1\n",
            "('the', 'only', 'things') 1\n",
            "('only', 'things', 'the') 1\n",
            "('things', 'the', 'testers') 1\n",
            "('the', 'testers', 'have') 1\n",
            "('testers', 'have', 'to') 1\n",
            "('have', 'to', 'go') 1\n",
            "('to', 'go', 'by') 1\n",
            "('go', 'by', 'are') 1\n",
            "('by', 'are', 'the') 1\n",
            "('are', 'the', 'written') 1\n",
            "('the', 'written', 'requirements') 1\n",
            "('written', 'requirements', 'so') 1\n",
            "('requirements', 'so', 'abstract') 1\n",
            "('so', 'abstract', 'not') 1\n",
            "('abstract', 'not', 'found') 7\n",
            "('not', 'found', 'conversational') 1\n",
            "('found', 'conversational', 'partners') 1\n",
            "('conversational', 'partners', 'but') 1\n",
            "('partners', 'but', 'it') 1\n",
            "('but', 'it', 'also') 1\n",
            "('it', 'also', 'provides') 1\n",
            "('also', 'provides', 'us') 1\n",
            "('provides', 'us', 'with') 1\n",
            "('us', 'with', 'information') 1\n",
            "('with', 'information', 'about') 1\n",
            "('information', 'about', 'being') 1\n",
            "('about', 'being', 'creative') 1\n",
            "('being', 'creative', 'making') 1\n",
            "('creative', 'making', 'associations') 1\n",
            "('making', 'associations', 'storytelling') 1\n",
            "('associations', 'storytelling', 'and') 1\n",
            "('storytelling', 'and', 'language') 1\n",
            "('and', 'language', 'use') 1\n",
            "('language', 'use', 'many') 1\n",
            "('use', 'many', 'more') 1\n",
            "('many', 'more', 'subtleties') 1\n",
            "('more', 'subtleties', 'in') 1\n",
            "('subtleties', 'in', 'facetoface') 1\n",
            "('in', 'facetoface', 'and') 1\n",
            "('facetoface', 'and', 'multiparty') 1\n",
            "('and', 'multiparty', 'interaction') 1\n",
            "('multiparty', 'interaction', 'can') 1\n",
            "('interaction', 'can', 'be') 1\n",
            "('can', 'be', 'added') 1\n",
            "('be', 'added', 'such') 1\n",
            "('added', 'such', 'as') 1\n",
            "('such', 'as', 'using') 1\n",
            "('as', 'using', 'humor') 1\n",
            "('using', 'humor', 'to') 1\n",
            "('humor', 'to', 'persuade') 1\n",
            "('to', 'persuade', 'and') 1\n",
            "('persuade', 'and', 'dominate') 1\n",
            "('and', 'dominate', 'to') 1\n",
            "('dominate', 'to', 'soften') 1\n",
            "('to', 'soften', 'or') 1\n",
            "('soften', 'or', 'avoid') 1\n",
            "('or', 'avoid', 'a') 1\n",
            "('avoid', 'a', 'face') 1\n",
            "('a', 'face', 'threatening') 1\n",
            "('face', 'threatening', 'act') 1\n",
            "('threatening', 'act', 'abstract') 1\n",
            "('act', 'abstract', 'not') 1\n",
            "('not', 'found', 'in') 2\n",
            "('found', 'in', 'recent') 1\n",
            "('in', 'recent', 'years') 2\n",
            "('recent', 'years', 'machine') 1\n",
            "('years', 'machine', 'learning') 1\n",
            "('machine', 'learning', 'ml') 2\n",
            "('learning', 'ml', 'has') 1\n",
            "('ml', 'has', 'been') 1\n",
            "('has', 'been', 'used') 1\n",
            "('been', 'used', 'more') 1\n",
            "('used', 'more', 'and') 1\n",
            "('more', 'and', 'more') 1\n",
            "('and', 'more', 'to') 1\n",
            "('more', 'to', 'solve') 1\n",
            "('to', 'solve', 'complex') 1\n",
            "('solve', 'complex', 'tasks') 1\n",
            "('complex', 'tasks', 'in') 1\n",
            "('tasks', 'in', 'different') 1\n",
            "('in', 'different', 'disciplines') 1\n",
            "('different', 'disciplines', 'ranging') 1\n",
            "('disciplines', 'ranging', 'from') 1\n",
            "('ranging', 'from', 'data') 1\n",
            "('from', 'data', 'mining') 1\n",
            "('data', 'mining', 'to') 1\n",
            "('mining', 'to', 'information') 1\n",
            "('to', 'information', 'we') 1\n",
            "('information', 'we', 'argue') 1\n",
            "('we', 'argue', 'that') 2\n",
            "('argue', 'that', 'manual') 1\n",
            "('that', 'manual', 'and') 1\n",
            "('manual', 'and', 'automatic') 1\n",
            "('and', 'automatic', 'thesauruses') 1\n",
            "('automatic', 'thesauruses', 'are') 1\n",
            "('thesauruses', 'are', 'alternative') 1\n",
            "('are', 'alternative', 'resources') 1\n",
            "('alternative', 'resources', 'for') 1\n",
            "('resources', 'for', 'the') 1\n",
            "('for', 'the', 'same') 1\n",
            "('the', 'same', 'nlp') 1\n",
            "('same', 'nlp', 'tasks') 1\n",
            "('nlp', 'tasks', 'this') 1\n",
            "('tasks', 'this', 'involves') 1\n",
            "('this', 'involves', 'the') 1\n",
            "('involves', 'the', 'radical') 1\n",
            "('the', 'radical', 'step') 1\n",
            "('radical', 'step', 'of') 1\n",
            "('step', 'of', 'interpreting') 1\n",
            "('of', 'interpreting', 'manual') 1\n",
            "('interpreting', 'manual', 'thesauruses') 1\n",
            "('manual', 'thesauruses', 'as') 1\n",
            "('thesauruses', 'as', 'classifications') 1\n",
            "('as', 'classifications', 'of') 1\n",
            "('classifications', 'of', 'words') 1\n",
            "('of', 'words', 'rather') 1\n",
            "('words', 'rather', 'than') 1\n",
            "('rather', 'than', 'word') 1\n",
            "('than', 'word', 'senses') 1\n",
            "('word', 'senses', 'the') 1\n",
            "('senses', 'the', 'case') 1\n",
            "('the', 'case', 'for') 1\n",
            "('case', 'for', 'this') 1\n",
            "('for', 'this', 'is') 1\n",
            "('this', 'is', 'made') 1\n",
            "('is', 'made', 'the') 1\n",
            "('made', 'the', 'range') 1\n",
            "('the', 'range', 'of') 1\n",
            "('range', 'of', 'roles') 1\n",
            "('of', 'roles', 'for') 1\n",
            "('roles', 'for', 'thesauruses') 1\n",
            "('for', 'thesauruses', 'within') 1\n",
            "('thesauruses', 'within', 'nlp') 1\n",
            "('within', 'nlp', 'is') 1\n",
            "('nlp', 'is', 'briefly') 1\n",
            "('is', 'briefly', 'presented') 1\n",
            "('briefly', 'presented', 'and') 1\n",
            "('presented', 'and', 'the') 1\n",
            "('and', 'the', 'wasps') 1\n",
            "('the', 'wasps', 'thesaurus') 1\n",
            "('wasps', 'thesaurus', 'is') 1\n",
            "('thesaurus', 'is', 'introduced') 1\n",
            "('is', 'introduced', 'thesaurus') 1\n",
            "('introduced', 'thesaurus', 'evaluation') 1\n",
            "('thesaurus', 'evaluation', 'is') 1\n",
            "('evaluation', 'is', 'now') 1\n",
            "('is', 'now', 'becoming') 1\n",
            "('now', 'becoming', 'urgent') 1\n",
            "('becoming', 'urgent', 'a') 1\n",
            "('urgent', 'a', 'range') 1\n",
            "('range', 'of', 'evaluation') 1\n",
            "('of', 'evaluation', 'strategies') 1\n",
            "('evaluation', 'strategies', 'all') 1\n",
            "('strategies', 'all', 'embedded') 1\n",
            "('all', 'embedded', 'within') 1\n",
            "('embedded', 'within', 'nlp') 1\n",
            "('within', 'nlp', 'tasks') 1\n",
            "('nlp', 'tasks', 'is') 1\n",
            "('tasks', 'is', 'proposed') 1\n",
            "('is', 'proposed', 'introduction') 1\n",
            "('proposed', 'introduction', 'patterns') 1\n",
            "('introduction', 'patterns', 'in') 1\n",
            "('patterns', 'in', 'music') 1\n",
            "('in', 'music', 'have') 1\n",
            "('music', 'have', 'been') 1\n",
            "('have', 'been', 'the') 1\n",
            "('been', 'the', 'object') 1\n",
            "('the', 'object', 'of') 1\n",
            "('object', 'of', 'intensive') 1\n",
            "('of', 'intensive', 'studies') 1\n",
            "('intensive', 'studies', 'in') 1\n",
            "('studies', 'in', 'the') 1\n",
            "('in', 'the', 'past') 1\n",
            "('the', 'past', 'years') 2\n",
            "('past', 'years', 'one') 1\n",
            "('years', 'one', 'of') 1\n",
            "('one', 'of', 'the') 1\n",
            "('of', 'the', 'purposes') 1\n",
            "('the', 'purposes', 'of') 1\n",
            "('purposes', 'of', 'analyzing') 1\n",
            "('of', 'analyzing', 'musical') 1\n",
            "('analyzing', 'musical', 'structure') 1\n",
            "('musical', 'structure', 'and') 1\n",
            "('structure', 'and', 'form') 1\n",
            "('and', 'form', 'is') 1\n",
            "('form', 'is', 'to') 1\n",
            "('is', 'to', 'discover') 1\n",
            "('to', 'discover', 'the') 1\n",
            "('discover', 'the', 'patterns') 1\n",
            "('the', 'patterns', 'that') 1\n",
            "('patterns', 'that', 'are') 1\n",
            "('that', 'are', 'explicit') 1\n",
            "('are', 'explicit', 'or') 1\n",
            "('explicit', 'or', 'implicit') 1\n",
            "('or', 'implicit', 'in') 1\n",
            "('implicit', 'in', 'musical') 1\n",
            "('in', 'musical', 'works') 1\n",
            "('musical', 'works', 'simon') 1\n",
            "('works', 'simon', 'patterns') 1\n",
            "('simon', 'patterns', 'comprise') 1\n",
            "('patterns', 'comprise', 'periodicity') 1\n",
            "('comprise', 'periodicity', 'make') 1\n",
            "('periodicity', 'make', 'use') 1\n",
            "('make', 'use', 'of') 1\n",
            "('use', 'of', 'alphabets') 1\n",
            "('of', 'alphabets', 'can') 1\n",
            "('alphabets', 'can', 'be') 1\n",
            "('can', 'be', 'compound') 1\n",
            "('be', 'compound', 'made') 1\n",
            "('compound', 'made', 'up') 1\n",
            "('made', 'up', 'of') 1\n",
            "('up', 'of', 'subpatterns') 1\n",
            "('of', 'subpatterns', 'and') 1\n",
            "('subpatterns', 'and', 'possess') 1\n",
            "('and', 'possess', 'phrase') 1\n",
            "('possess', 'phrase', 'structure') 1\n",
            "('phrase', 'structure', 'with') 1\n",
            "('structure', 'with', 'various') 1\n",
            "('with', 'various', 'forms') 1\n",
            "('various', 'forms', 'of') 1\n",
            "('forms', 'of', 'punctuation') 1\n",
            "('of', 'punctuation', 'traditionally') 1\n",
            "('punctuation', 'traditionally', 'composers') 1\n",
            "('traditionally', 'composers', 'have') 1\n",
            "('composers', 'have', 'employed') 1\n",
            "('have', 'employed', 'pattern') 1\n",
            "('employed', 'pattern', 'propagation') 1\n",
            "('pattern', 'propagation', 'intuitively') 1\n",
            "('propagation', 'intuitively', 'but') 1\n",
            "('intuitively', 'but', 'algorithmic') 1\n",
            "('but', 'algorithmic', 'composition') 1\n",
            "('algorithmic', 'composition', 'techniques') 1\n",
            "('composition', 'techniques', 'allow') 1\n",
            "('techniques', 'allow', 'the') 1\n",
            "('allow', 'the', 'pattern') 1\n",
            "('the', 'pattern', 'propagation') 1\n",
            "('pattern', 'propagation', 'to') 1\n",
            "('propagation', 'to', 'be') 1\n",
            "('to', 'be', 'formalized') 1\n",
            "('be', 'formalized', 'albeit') 1\n",
            "('formalized', 'albeit', 'a') 1\n",
            "('albeit', 'a', 'high') 1\n",
            "('a', 'high', 'level') 1\n",
            "('high', 'level', 'during') 1\n",
            "('level', 'during', 'composition') 1\n",
            "('during', 'composition', 'all') 1\n",
            "('composition', 'all', 'the') 1\n",
            "('all', 'the', 'musical') 1\n",
            "('the', 'musical', 'patterns') 1\n",
            "('musical', 'patterns', 'evolve') 1\n",
            "('patterns', 'evolve', 'according') 1\n",
            "('evolve', 'according', 'to') 1\n",
            "('according', 'to', 'the') 1\n",
            "('to', 'the', 'rules') 1\n",
            "('the', 'rules', 'and') 1\n",
            "('rules', 'and', 'constraints') 1\n",
            "('and', 'constraints', 'specied') 1\n",
            "('constraints', 'specied', 'at') 1\n",
            "('specied', 'at', 'the') 1\n",
            "('at', 'the', 'design') 1\n",
            "('the', 'design', 'stage') 1\n",
            "('design', 'stage', 'in') 1\n",
            "('stage', 'in', 'jazz') 1\n",
            "('in', 'jazz', 'improvisation') 1\n",
            "('jazz', 'improvisation', 'the') 1\n",
            "('improvisation', 'the', 'musician') 1\n",
            "('the', 'musician', 'invents') 1\n",
            "('musician', 'invents', 'a') 1\n",
            "('invents', 'a', 'solo') 1\n",
            "('a', 'solo', 'guided') 1\n",
            "('solo', 'guided', 'by') 1\n",
            "('guided', 'by', 'a') 1\n",
            "('by', 'a', 'progression') 1\n",
            "('a', 'progression', 'of') 1\n",
            "('progression', 'of', 'chords') 1\n",
            "('of', 'chords', 'the') 1\n",
            "('chords', 'the', 'changes') 1\n",
            "('the', 'changes', 'one') 1\n",
            "('changes', 'one', 'approach') 1\n",
            "('one', 'approach', 'to') 1\n",
            "('approach', 'to', 'learn') 1\n",
            "('to', 'learn', 'improvising') 1\n",
            "('learn', 'improvising', 'is') 1\n",
            "('improvising', 'is', 'to') 1\n",
            "('is', 'to', 'memorize') 1\n",
            "('to', 'memorize', 'patterns') 1\n",
            "('memorize', 'patterns', 'short') 1\n",
            "('patterns', 'short', 'chunks') 1\n",
            "('short', 'chunks', 'of') 1\n",
            "('chunks', 'of', 'music') 1\n",
            "('of', 'music', 'that') 1\n",
            "('music', 'that', 't') 1\n",
            "('that', 't', 'subprogressions') 1\n",
            "('t', 'subprogressions', 'and') 1\n",
            "('subprogressions', 'and', 'to') 1\n",
            "('and', 'to', 'concatenate') 1\n",
            "('to', 'concatenate', 'them') 1\n",
            "('concatenate', 'them', 'to') 1\n",
            "('them', 'to', 'form') 1\n",
            "('to', 'form', 'a') 1\n",
            "('form', 'a', 'whole') 1\n",
            "('a', 'whole', 'solo') 1\n",
            "('whole', 'solo', 'that') 1\n",
            "('solo', 'that', 'ts') 1\n",
            "('that', 'ts', 'a') 1\n",
            "('ts', 'a', 'whole') 1\n",
            "('a', 'whole', 'progression') 1\n",
            "('whole', 'progression', 'one') 1\n",
            "('progression', 'one', 'abstract') 1\n",
            "('one', 'abstract', 'many') 1\n",
            "('abstract', 'many', 'information') 1\n",
            "('many', 'information', 'retrievalir') 1\n",
            "('information', 'retrievalir', 'systems') 1\n",
            "('retrievalir', 'systems', 'retrieve') 1\n",
            "('systems', 'retrieve', 'relevant') 1\n",
            "('retrieve', 'relevant', 'documents') 1\n",
            "('relevant', 'documents', 'based') 1\n",
            "('documents', 'based', 'on') 1\n",
            "('based', 'on', 'exact') 1\n",
            "('on', 'exact', 'matching') 1\n",
            "('exact', 'matching', 'of') 1\n",
            "('matching', 'of', 'keywords') 1\n",
            "('of', 'keywords', 'between') 1\n",
            "('keywords', 'between', 'a') 1\n",
            "('between', 'a', 'query') 1\n",
            "('a', 'query', 'and') 1\n",
            "('query', 'and', 'documents') 1\n",
            "('and', 'documents', 'this') 1\n",
            "('documents', 'this', 'method') 1\n",
            "('this', 'method', 'degrades') 1\n",
            "('method', 'degrades', 'precision') 1\n",
            "('degrades', 'precision', 'rate') 1\n",
            "('precision', 'rate', 'in') 1\n",
            "('rate', 'in', 'order') 1\n",
            "('order', 'to', 'solve') 1\n",
            "('to', 'solve', 'the') 1\n",
            "('solve', 'the', 'problem') 1\n",
            "('the', 'problem', 'we') 1\n",
            "('problem', 'we', 'collected') 1\n",
            "('we', 'collected', 'semantically') 1\n",
            "('collected', 'semantically', 'related') 1\n",
            "('semantically', 'related', 'words') 1\n",
            "('related', 'words', 'and') 1\n",
            "('words', 'and', 'assigned') 1\n",
            "('and', 'assigned', 'semantic') 1\n",
            "('assigned', 'semantic', 'relationships') 1\n",
            "('semantic', 'relationships', 'used') 1\n",
            "('relationships', 'used', 'in') 1\n",
            "('used', 'in', 'general') 1\n",
            "('in', 'general', 'thesaurus') 1\n",
            "('general', 'thesaurus', 'and') 1\n",
            "('thesaurus', 'and', 'a') 1\n",
            "('and', 'a', 'special') 1\n",
            "('a', 'special', 'relationship') 1\n",
            "('special', 'relationship', 'called') 1\n",
            "('relationship', 'called', 'keyfact') 1\n",
            "('called', 'keyfact', 'termft') 1\n",
            "('keyfact', 'termft', 'manually') 1\n",
            "('termft', 'manually', 'in') 1\n",
            "('manually', 'in', 'addition') 1\n",
            "('in', 'addition', 'to') 1\n",
            "('addition', 'to', 'the') 1\n",
            "('to', 'the', 'semantic') 1\n",
            "('the', 'semantic', 'knowledge') 1\n",
            "('semantic', 'knowledge', 'we') 1\n",
            "('knowledge', 'we', 'automatically') 1\n",
            "('we', 'automatically', 'constructed') 1\n",
            "('automatically', 'constructed', 'statistic') 1\n",
            "('constructed', 'statistic', 'knowledge') 1\n",
            "('statistic', 'knowledge', 'based') 1\n",
            "('knowledge', 'based', 'on') 1\n",
            "('on', 'the', 'concept') 1\n",
            "('the', 'concept', 'of') 1\n",
            "('concept', 'of', 'mutual') 1\n",
            "('of', 'mutual', 'information') 1\n",
            "('mutual', 'information', 'keyfact') 1\n",
            "('information', 'keyfact', 'is') 1\n",
            "('keyfact', 'is', 'an') 1\n",
            "('is', 'an', 'extended') 1\n",
            "('an', 'extended', 'concept') 1\n",
            "('extended', 'concept', 'of') 1\n",
            "('concept', 'of', 'keyword') 1\n",
            "('of', 'keyword', 'represented') 1\n",
            "('keyword', 'represented', 'by') 1\n",
            "('represented', 'by', 'noun') 1\n",
            "('by', 'noun', 'and') 1\n",
            "('noun', 'and', 'compound') 1\n",
            "('and', 'compound', 'noun') 1\n",
            "('compound', 'noun', 'keyfact') 1\n",
            "('noun', 'keyfact', 'can') 1\n",
            "('keyfact', 'can', 'be') 1\n",
            "('can', 'be', 'a') 1\n",
            "('be', 'a', 'verb') 1\n",
            "('a', 'verb', 'and') 1\n",
            "('verb', 'and', 'an') 1\n",
            "('and', 'an', 'adjective') 1\n",
            "('an', 'adjective', 'including') 1\n",
            "('adjective', 'including', 'subject') 1\n",
            "('including', 'subject', 'or') 1\n",
            "('subject', 'or', 'object') 1\n",
            "('or', 'object', 'term') 1\n",
            "('object', 'term', 'we') 1\n",
            "('term', 'we', 'first') 1\n",
            "('we', 'first', 'retrieved') 1\n",
            "('first', 'retrieved', 'relevant') 1\n",
            "('retrieved', 'relevant', 'documents') 1\n",
            "('relevant', 'documents', 'with') 1\n",
            "('documents', 'with', 'original') 1\n",
            "('with', 'original', 'query') 1\n",
            "('original', 'query', 'using') 1\n",
            "('query', 'using', 'tf') 1\n",
            "('using', 'tf', 'idf') 1\n",
            "('tf', 'idf', 'weighting') 1\n",
            "('idf', 'weighting', 'formula') 1\n",
            "('weighting', 'formula', 'and') 1\n",
            "('formula', 'and', 'then') 1\n",
            "('and', 'then', 'an') 1\n",
            "('then', 'an', 'expanded') 1\n",
            "('an', 'expanded', 'query') 1\n",
            "('expanded', 'query', 'including') 1\n",
            "('query', 'including', 'keyfacts') 1\n",
            "('including', 'keyfacts', 'is') 1\n",
            "('keyfacts', 'is', 'used') 1\n",
            "('is', 'used', 'in') 1\n",
            "('used', 'in', 'both') 1\n",
            "('in', 'both', 'second') 1\n",
            "('both', 'second', 'document') 1\n",
            "('second', 'document', 'ranking') 1\n",
            "('document', 'ranking', 'and') 1\n",
            "('ranking', 'and', 'word') 1\n",
            "('and', 'word', 'sense') 1\n",
            "('word', 'sense', 'disambiguating') 1\n",
            "('sense', 'disambiguating', 'so') 1\n",
            "('disambiguating', 'so', 'we') 1\n",
            "('so', 'we', 'made') 1\n",
            "('we', 'made', 'an') 1\n",
            "('made', 'an', 'improvement') 1\n",
            "('an', 'improvement', 'in') 1\n",
            "('improvement', 'in', 'precision') 1\n",
            "('in', 'precision', 'rate') 1\n",
            "('precision', 'rate', 'using') 1\n",
            "('rate', 'using', 'keyfact') 1\n",
            "('using', 'keyfact', 'network') 1\n",
            "('keyfact', 'network', 'this') 1\n",
            "('network', 'this', 'paper') 1\n",
            "('paper', 'we', 'argue') 1\n",
            "('argue', 'that', 'questionanswering') 1\n",
            "('that', 'questionanswering', 'qa') 1\n",
            "('questionanswering', 'qa', 'over') 1\n",
            "('qa', 'over', 'technical') 1\n",
            "('over', 'technical', 'domains') 1\n",
            "('technical', 'domains', 'is') 1\n",
            "('domains', 'is', 'distinctly') 1\n",
            "('is', 'distinctly', 'different') 1\n",
            "('distinctly', 'different', 'from') 1\n",
            "('different', 'from', 'trecbased') 1\n",
            "('from', 'trecbased', 'qa') 1\n",
            "('trecbased', 'qa', 'or') 1\n",
            "('qa', 'or', 'webbased') 1\n",
            "('or', 'webbased', 'qa') 1\n",
            "('webbased', 'qa', 'and') 1\n",
            "('qa', 'and', 'it') 1\n",
            "('and', 'it', 'can') 1\n",
            "('it', 'can', 'not') 1\n",
            "('can', 'not', 'benefit') 1\n",
            "('not', 'benefit', 'lom') 1\n",
            "('benefit', 'lom', 'dataintensive') 1\n",
            "('lom', 'dataintensive', 'approaches') 1\n",
            "('dataintensive', 'approaches', 'universitquotat') 1\n",
            "('approaches', 'universitquotat', 'des') 1\n",
            "('universitquotat', 'des', 'saarlandes') 1\n",
            "('des', 'saarlandes', 'proceedings') 1\n",
            "('saarlandes', 'proceedings', 'of') 1\n",
            "('proceedings', 'of', 'the') 1\n",
            "('of', 'the', 'workshop') 1\n",
            "('the', 'workshop', 'on') 1\n",
            "('workshop', 'on', 'unihamburgde') 1\n",
            "('on', 'unihamburgde', 'abstract') 1\n",
            "('unihamburgde', 'abstract', 'not') 1\n",
            "('not', 'found', 'abstract') 2\n",
            "('found', 'abstract', 'not') 1\n",
            "('not', 'found', 'sri') 1\n",
            "('found', 'sri', 'has') 1\n",
            "('sri', 'has', 'developed') 1\n",
            "('has', 'developed', 'a') 1\n",
            "('developed', 'a', 'new') 1\n",
            "('a', 'new', 'architecture') 1\n",
            "('new', 'architecture', 'for') 1\n",
            "('architecture', 'for', 'integrating') 1\n",
            "('for', 'integrating', 'speech') 1\n",
            "('integrating', 'speech', 'and') 1\n",
            "('speech', 'and', 'naturallanguage') 1\n",
            "('and', 'naturallanguage', 'processing') 1\n",
            "('naturallanguage', 'processing', 'that') 1\n",
            "('processing', 'that', 'applies') 1\n",
            "('that', 'applies', 'linguistic') 1\n",
            "('applies', 'linguistic', 'constraints') 1\n",
            "('linguistic', 'constraints', 'during') 1\n",
            "('constraints', 'during', 'recognition') 1\n",
            "('during', 'recognition', 'by') 1\n",
            "('recognition', 'by', 'incrementally') 1\n",
            "('by', 'incrementally', 'expanding') 1\n",
            "('incrementally', 'expanding', 'the') 1\n",
            "('expanding', 'the', 'statetransition') 1\n",
            "('the', 'statetransition', 'network') 1\n",
            "('statetransition', 'network', 'embodied') 1\n",
            "('network', 'embodied', 'in') 1\n",
            "('embodied', 'in', 'a') 1\n",
            "('in', 'a', 'unification') 1\n",
            "('a', 'unification', 'grammar') 1\n",
            "('unification', 'grammar', 'we') 1\n",
            "('grammar', 'we', 'compare') 1\n",
            "('we', 'compare', 'this') 1\n",
            "('compare', 'this', 'dynamicgralnlnarnetwork') 1\n",
            "('this', 'dynamicgralnlnarnetwork', 'dgn') 1\n",
            "('dynamicgralnlnarnetwork', 'dgn', 'approach') 1\n",
            "('dgn', 'approach', 'this') 1\n",
            "('approach', 'this', 'chapter') 1\n",
            "('this', 'chapter', 'considers') 1\n",
            "('chapter', 'considers', 'the') 1\n",
            "('considers', 'the', 'revolution') 1\n",
            "('the', 'revolution', 'that') 1\n",
            "('revolution', 'that', 'has') 1\n",
            "('that', 'has', 'taken') 1\n",
            "('has', 'taken', 'place') 1\n",
            "('taken', 'place', 'in') 1\n",
            "('place', 'in', 'natural') 1\n",
            "('language', 'processing', 'research') 1\n",
            "('processing', 'research', 'over') 1\n",
            "('research', 'over', 'the') 1\n",
            "('over', 'the', 'last') 4\n",
            "('the', 'last', 'five') 1\n",
            "('last', 'five', 'years') 1\n",
            "('five', 'years', 'it') 1\n",
            "('years', 'it', 'begins') 1\n",
            "('it', 'begins', 'by') 1\n",
            "('begins', 'by', 'providing') 1\n",
            "('by', 'providing', 'a') 1\n",
            "('providing', 'a', 'brief') 1\n",
            "('a', 'brief', 'guide') 1\n",
            "('brief', 'guide', 'to') 1\n",
            "('guide', 'to', 'the') 1\n",
            "('to', 'the', 'structure') 1\n",
            "('the', 'structure', 'of') 1\n",
            "('structure', 'of', 'the') 1\n",
            "('of', 'the', 'field') 1\n",
            "('the', 'field', 'and') 1\n",
            "('field', 'and', 'then') 1\n",
            "('and', 'then', 'presents') 1\n",
            "('then', 'presents', 'a') 1\n",
            "('presents', 'a', 'caricature') 1\n",
            "('a', 'caricature', 'of') 1\n",
            "('caricature', 'of', 'two') 1\n",
            "('of', 'two', 'competing') 1\n",
            "('two', 'competing', 'paradigms') 1\n",
            "('competing', 'paradigms', 'of') 1\n",
            "('paradigms', 'of', 'nlp') 1\n",
            "('of', 'nlp', 'research') 1\n",
            "('nlp', 'research', 'and') 1\n",
            "('research', 'and', 'indicates') 1\n",
            "('and', 'indicates', 'the') 1\n",
            "('indicates', 'the', 'reasons') 1\n",
            "('the', 'reasons', 'visual') 1\n",
            "('reasons', 'visual', 'development') 1\n",
            "('visual', 'development', 'environment') 1\n",
            "('development', 'environment', 'to') 1\n",
            "('environment', 'to', 'support') 1\n",
            "('to', 'support', 'the') 1\n",
            "('support', 'the', 'visual') 1\n",
            "('the', 'visual', 'assembly') 1\n",
            "('visual', 'assembly', 'execution') 1\n",
            "('assembly', 'execution', 'and') 1\n",
            "('execution', 'and', 'analysis') 1\n",
            "('and', 'analysis', 'of') 1\n",
            "('analysis', 'of', 'modular') 1\n",
            "('of', 'modular', 'natural') 1\n",
            "('modular', 'natural', 'language') 1\n",
            "('systems', 'the', 'visual') 1\n",
            "('the', 'visual', 'model') 1\n",
            "('visual', 'model', 'is') 1\n",
            "('model', 'is', 'an') 1\n",
            "('is', 'an', 'executable') 1\n",
            "('an', 'executable', 'data') 1\n",
            "('executable', 'data', 'flow') 1\n",
            "('data', 'flow', 'program') 1\n",
            "('flow', 'program', 'graph') 1\n",
            "('program', 'graph', 'automatically') 1\n",
            "('graph', 'automatically', 'synthesised') 1\n",
            "('automatically', 'synthesised', 'from') 1\n",
            "('synthesised', 'from', 'data') 1\n",
            "('from', 'data', 'dependency') 1\n",
            "('data', 'dependency', 'declarations') 1\n",
            "('dependency', 'declarations', 'of') 1\n",
            "('declarations', 'of', 'language') 1\n",
            "('of', 'language', 'processing') 2\n",
            "('language', 'processing', 'modules') 1\n",
            "('processing', 'modules', 'the') 1\n",
            "('modules', 'the', 'graph') 1\n",
            "('the', 'graph', 'in') 1\n",
            "('graph', 'in', 'this') 1\n",
            "('in', 'this', 'chapter') 1\n",
            "('this', 'chapter', 'the') 1\n",
            "('chapter', 'the', 'basic') 1\n",
            "('the', 'basic', 'uses') 1\n",
            "('basic', 'uses', 'of') 1\n",
            "('uses', 'of', 'description') 1\n",
            "('of', 'description', 'logics') 2\n",
            "('description', 'logics', 'for') 1\n",
            "('logics', 'for', 'natural') 1\n",
            "('language', 'processing', 'will') 1\n",
            "('processing', 'will', 'be') 1\n",
            "('will', 'be', 'analysed') 1\n",
            "('be', 'analysed', 'together') 1\n",
            "('analysed', 'together', 'with') 1\n",
            "('together', 'with', 'a') 1\n",
            "('with', 'a', 'little') 1\n",
            "('a', 'little', 'bit') 1\n",
            "('little', 'bit', 'of') 1\n",
            "('bit', 'of', 'history') 1\n",
            "('of', 'history', 'and') 2\n",
            "('history', 'and', 'the') 1\n",
            "('and', 'the', 'role') 1\n",
            "('role', 'of', 'description') 1\n",
            "('description', 'logics', 'in') 1\n",
            "('logics', 'in', 'the') 1\n",
            "('in', 'the', 'current') 1\n",
            "('current', 'state', 'of') 1\n",
            "('state', 'of', 'the') 3\n",
            "('of', 'the', 'art') 3\n",
            "('the', 'art', 'in') 1\n",
            "('art', 'in', 'computational') 1\n",
            "('computational', 'linguistics', 'will') 1\n",
            "('linguistics', 'will', 'be') 1\n",
            "('will', 'be', 'pointed') 1\n",
            "('be', 'pointed', 'out') 1\n",
            "('pointed', 'out', 'introduction') 1\n",
            "('out', 'introduction', 'since') 1\n",
            "('introduction', 'since', 'the') 1\n",
            "('since', 'the', 'early') 1\n",
            "('the', 'early', 'days') 1\n",
            "('early', 'days', 'we') 1\n",
            "('days', 'we', 'applied') 1\n",
            "('we', 'applied', 'a') 1\n",
            "('applied', 'a', 'structure') 1\n",
            "('a', 'structure', 'learning') 1\n",
            "('structure', 'learning', 'model') 1\n",
            "('learning', 'model', 'maxmargin') 1\n",
            "('model', 'maxmargin', 'structure') 1\n",
            "('maxmargin', 'structure', 'mms') 1\n",
            "('structure', 'mms', 'to') 1\n",
            "('mms', 'to', 'natural') 1\n",
            "('processing', 'nlp', 'tasks') 3\n",
            "('nlp', 'tasks', 'where') 1\n",
            "('tasks', 'where', 'the') 1\n",
            "('where', 'the', 'aim') 1\n",
            "('the', 'aim', 'is') 1\n",
            "('aim', 'is', 'to') 1\n",
            "('is', 'to', 'capture') 1\n",
            "('to', 'capture', 'the') 1\n",
            "('capture', 'the', 'latent') 1\n",
            "('the', 'latent', 'relationships') 1\n",
            "('latent', 'relationships', 'within') 1\n",
            "('relationships', 'within', 'the') 1\n",
            "('within', 'the', 'output') 1\n",
            "('the', 'output', 'language') 1\n",
            "('output', 'language', 'domain') 1\n",
            "('language', 'domain', 'we') 1\n",
            "('domain', 'we', 'formulate') 1\n",
            "('we', 'formulate', 'this') 1\n",
            "('formulate', 'this', 'model') 1\n",
            "('this', 'model', 'as') 1\n",
            "('model', 'as', 'an') 1\n",
            "('as', 'an', 'extension') 1\n",
            "('an', 'extension', 'of') 1\n",
            "('extension', 'of', 'multi–class') 1\n",
            "('of', 'multi–class', 'support') 1\n",
            "('multi–class', 'support', 'vector') 1\n",
            "('support', 'vector', 'machine') 1\n",
            "('vector', 'machine', 'svm') 1\n",
            "('machine', 'svm', 'and') 1\n",
            "('svm', 'and', 'present') 1\n",
            "('and', 'present', 'a') 1\n",
            "('present', 'a', 'mation') 1\n",
            "('a', 'mation', 'infrastructure') 1\n",
            "('mation', 'infrastructure', 'digital') 1\n",
            "('infrastructure', 'digital', 'libraries') 1\n",
            "('digital', 'libraries', 'networked') 1\n",
            "('libraries', 'networked', 'services') 1\n",
            "('networked', 'services', 'digital') 1\n",
            "('services', 'digital', 'convergence') 1\n",
            "('digital', 'convergence', 'or') 1\n",
            "('convergence', 'or', 'intelligent') 1\n",
            "('or', 'intelligent', 'agents') 1\n",
            "('intelligent', 'agents', 'this') 1\n",
            "('agents', 'this', 'attention') 1\n",
            "('this', 'attention', 'is') 1\n",
            "('attention', 'is', 'moving') 1\n",
            "('is', 'moving', 'natural') 1\n",
            "('moving', 'natural', 'language') 1\n",
            "('language', 'processing', 'along') 1\n",
            "('processing', 'along', 'the') 1\n",
            "('along', 'the', 'critical') 1\n",
            "('the', 'critical', 'path') 1\n",
            "('critical', 'path', 'for') 1\n",
            "('path', 'for', 'all') 1\n",
            "('for', 'all', 'kinds') 1\n",
            "('all', 'kinds', 'of') 1\n",
            "('kinds', 'of', 'novel') 1\n",
            "('of', 'novel', 'applications') 1\n",
            "('novel', 'applications', 'this') 1\n",
            "('applications', 'this', 'article') 1\n",
            "('this', 'article', 'will') 1\n",
            "('article', 'will', 'mention') 1\n",
            "('will', 'mention', 'a') 1\n",
            "('mention', 'a', 'number') 1\n",
            "('number', 'of', 'successful') 1\n",
            "('of', 'successful', 'applications') 1\n",
            "('successful', 'applications', 'of') 1\n",
            "('applications', 'of', 'natural') 1\n",
            "('processing', 'nlp', 'over') 1\n",
            "('nlp', 'over', 'the') 1\n",
            "('the', 'last', 'few') 1\n",
            "('last', 'few', 'years') 1\n",
            "('few', 'years', 'a') 1\n",
            "('years', 'a', 'number') 1\n",
            "('number', 'of', 'areas') 1\n",
            "('of', 'areas', 'of') 1\n",
            "('areas', 'of', 'natural') 1\n",
            "('language', 'processing', 'have') 1\n",
            "('processing', 'have', 'begun') 1\n",
            "('have', 'begun', 'applying') 1\n",
            "('begun', 'applying', 'graphbased') 1\n",
            "('applying', 'graphbased', 'techniques') 1\n",
            "('graphbased', 'techniques', 'these') 1\n",
            "('techniques', 'these', 'include') 1\n",
            "('these', 'include', 'among') 1\n",
            "('include', 'among', 'others') 1\n",
            "('among', 'others', 'text') 1\n",
            "('others', 'text', 'summarization') 1\n",
            "('text', 'summarization', 'syntactic') 1\n",
            "('summarization', 'syntactic', 'parsing') 1\n",
            "('syntactic', 'parsing', 'word') 1\n",
            "('parsing', 'word', 'sense') 2\n",
            "('word', 'sense', 'disambiguation') 2\n",
            "('sense', 'disambiguation', 'ontology') 1\n",
            "('disambiguation', 'ontology', 'construction') 1\n",
            "('ontology', 'construction', 'sentiment') 1\n",
            "('construction', 'sentiment', 'and') 1\n",
            "('sentiment', 'and', 'subjectivity') 1\n",
            "('and', 'subjectivity', 'analysis') 1\n",
            "('subjectivity', 'analysis', 'text') 1\n",
            "('analysis', 'text', 'clustering') 1\n",
            "('text', 'clustering', 'in') 1\n",
            "('clustering', 'in', 'natural') 1\n",
            "('processing', 'nlp', 'research') 1\n",
            "('nlp', 'research', 'results') 1\n",
            "('research', 'results', 'from') 1\n",
            "('results', 'from', 'software') 1\n",
            "('from', 'software', 'engineering') 1\n",
            "('software', 'engineering', 'and') 1\n",
            "('engineering', 'and', 'software') 1\n",
            "('and', 'software', 'technology') 1\n",
            "('software', 'technology', 'have') 1\n",
            "('technology', 'have', 'often') 1\n",
            "('have', 'often', 'been') 1\n",
            "('often', 'been', 'neglected') 1\n",
            "('been', 'neglected', 'of') 1\n",
            "('neglected', 'of', 'kernelized') 1\n",
            "('of', 'kernelized', 'sorting') 1\n",
            "('kernelized', 'sorting', 'to') 1\n",
            "('sorting', 'to', 'increase') 1\n",
            "('to', 'increase', 'its') 1\n",
            "('increase', 'its', 'robustness') 1\n",
            "('its', 'robustness', 'and') 1\n",
            "('robustness', 'and', 'performance') 1\n",
            "('and', 'performance', 'on') 1\n",
            "('performance', 'on', 'several') 1\n",
            "('on', 'several', 'natural') 1\n",
            "('several', 'natural', 'language') 1\n",
            "('nlp', 'tasks', 'document') 1\n",
            "('tasks', 'document', 'matching') 1\n",
            "('document', 'matching', 'from') 1\n",
            "('matching', 'from', 'parallel') 1\n",
            "('from', 'parallel', 'and') 1\n",
            "('parallel', 'and', 'comparable') 1\n",
            "('and', 'comparable', 'corpora') 1\n",
            "('comparable', 'corpora', 'machine') 1\n",
            "('corpora', 'machine', 'transliteration') 1\n",
            "('machine', 'transliteration', 'and') 1\n",
            "('transliteration', 'and', 'even') 1\n",
            "('and', 'even', 'image') 1\n",
            "('even', 'image', 'processing') 1\n",
            "('image', 'processing', 'empirically') 1\n",
            "('processing', 'empirically', 'we') 1\n",
            "('empirically', 'we', 'show') 1\n",
            "('we', 'show', 'that') 1\n",
            "('show', 'that', 'on') 1\n",
            "('that', 'on', 'these') 1\n",
            "('on', 'these', 'tasks') 1\n",
            "('these', 'tasks', 'a') 1\n",
            "('tasks', 'a', 'semisupervised') 1\n",
            "('a', 'semisupervised', 'variant') 1\n",
            "('semisupervised', 'variant', 'of') 1\n",
            "('variant', 'of', 'kernelized') 1\n",
            "('of', 'kernelized', 'will') 1\n",
            "('kernelized', 'will', 'be') 1\n",
            "('will', 'be', 'structured') 1\n",
            "('be', 'structured', 'in') 1\n",
            "('structured', 'in', 'the') 1\n",
            "('in', 'the', 'words') 1\n",
            "('the', 'words', 'of') 1\n",
            "('words', 'of', 'statistical') 1\n",
            "('of', 'statistical', 'natural') 1\n",
            "('statistical', 'natural', 'language') 1\n",
            "('processing', 'we', 'need') 1\n",
            "('we', 'need', 'a') 1\n",
            "('need', 'a', 'sophisticated') 1\n",
            "('a', 'sophisticated', 'statistical') 1\n",
            "('sophisticated', 'statistical', 'model') 1\n",
            "('statistical', 'model', 'of') 1\n",
            "('model', 'of', 'the') 2\n",
            "('of', 'the', 'basic') 1\n",
            "('the', 'basic', 'elements') 1\n",
            "('basic', 'elements', 'such') 1\n",
            "('elements', 'such', 'as') 1\n",
            "('such', 'as', 'words') 1\n",
            "('as', 'words', 'or') 1\n",
            "('words', 'or', 'phrases') 1\n",
            "('or', 'phrases', 'to') 1\n",
            "('phrases', 'to', 'be') 1\n",
            "('to', 'be', 'combined') 1\n",
            "('be', 'combined', 'with') 1\n",
            "('combined', 'with', 'the') 1\n",
            "('with', 'the', 'structural') 1\n",
            "('the', 'structural', 'modeling') 1\n",
            "('structural', 'modeling', 'such') 1\n",
            "('modeling', 'such', 'as') 1\n",
            "('such', 'as', 'syntactic') 1\n",
            "('as', 'syntactic', 'parsing') 1\n",
            "('syntactic', 'parsing', 'or') 1\n",
            "('parsing', 'or', 'dependency') 1\n",
            "('or', 'dependency', 'analysis') 1\n",
            "('dependency', 'analysis', 'since') 1\n",
            "('analysis', 'since', 'the') 1\n",
            "('since', 'the', 'basic') 1\n",
            "('the', 'basic', 'property') 1\n",
            "('basic', 'property', 'of') 1\n",
            "('property', 'of', 'these') 1\n",
            "('of', 'these', 'elements') 1\n",
            "('these', 'elements', 'in') 1\n",
            "('elements', 'in', 'this') 1\n",
            "('describe', 'a', 'framework') 1\n",
            "('a', 'framework', 'for') 1\n",
            "('framework', 'for', 'developing') 1\n",
            "('for', 'developing', 'probabilistic') 1\n",
            "('developing', 'probabilistic', 'classifiers') 1\n",
            "('probabilistic', 'classifiers', 'in') 1\n",
            "('classifiers', 'in', 'natural') 1\n",
            "('language', 'processing', 'our') 1\n",
            "('processing', 'our', 'focus') 1\n",
            "('our', 'focus', 'is') 1\n",
            "('focus', 'is', 'on') 1\n",
            "('is', 'on', 'formulating') 1\n",
            "('on', 'formulating', 'models') 1\n",
            "('formulating', 'models', 'that') 1\n",
            "('models', 'that', 'capture') 1\n",
            "('that', 'capture', 'the') 1\n",
            "('capture', 'the', 'most') 1\n",
            "('the', 'most', 'important') 1\n",
            "('most', 'important', 'interdependencies') 1\n",
            "('important', 'interdependencies', 'among') 1\n",
            "('interdependencies', 'among', 'features') 1\n",
            "('among', 'features', 'to') 1\n",
            "('features', 'to', 'avoid') 1\n",
            "('to', 'avoid', 'overfitting') 1\n",
            "('avoid', 'overfitting', 'the') 1\n",
            "('overfitting', 'the', 'data') 1\n",
            "('the', 'data', 'while') 1\n",
            "('data', 'while', 'also') 1\n",
            "('while', 'also', 'characterizing') 1\n",
            "('also', 'characterizing', 'the') 1\n",
            "('characterizing', 'the', 'data') 1\n",
            "('the', 'data', 'well') 1\n",
            "('data', 'well', 'the') 1\n",
            "('well', 'the', 'class') 1\n",
            "('the', 'class', 'many') 1\n",
            "('class', 'many', 'natural') 1\n",
            "('many', 'natural', 'language') 1\n",
            "('nlp', 'techniques', 'have') 1\n",
            "('techniques', 'have', 'been') 1\n",
            "('have', 'been', 'used') 1\n",
            "('been', 'used', 'in') 1\n",
            "('used', 'in', 'information') 1\n",
            "('in', 'information', 'retrieval') 1\n",
            "('information', 'retrieval', 'the') 1\n",
            "('retrieval', 'the', 'results') 1\n",
            "('the', 'results', 'are') 1\n",
            "('results', 'are', 'not') 1\n",
            "('are', 'not', 'encouraging') 1\n",
            "('not', 'encouraging', 'simple') 1\n",
            "('encouraging', 'simple', 'methods') 1\n",
            "('simple', 'methods', 'stopwording') 1\n",
            "('methods', 'stopwording', 'porterstyle') 1\n",
            "('stopwording', 'porterstyle', 'stemming') 1\n",
            "('porterstyle', 'stemming', 'etc') 1\n",
            "('stemming', 'etc', 'usually') 1\n",
            "('etc', 'usually', 'yield') 1\n",
            "('usually', 'yield', 'significant') 1\n",
            "('yield', 'significant', 'improvements') 1\n",
            "('significant', 'improvements', 'while') 1\n",
            "('improvements', 'while', 'higherlevel') 1\n",
            "('while', 'higherlevel', 'processing') 1\n",
            "('higherlevel', 'processing', 'chunking') 1\n",
            "('processing', 'chunking', 'parsing') 1\n",
            "('chunking', 'parsing', 'word') 1\n",
            "('sense', 'disambiguation', 'abstract') 1\n",
            "('disambiguation', 'abstract', 'this') 1\n",
            "('abstract', 'this', 'paper') 1\n",
            "('this', 'paper', 'explains') 1\n",
            "('paper', 'explains', 'the') 1\n",
            "('explains', 'the', 'information') 1\n",
            "('the', 'information', 'retrieval') 1\n",
            "('information', 'retrieval', 'using') 1\n",
            "('retrieval', 'using', 'natural') 1\n",
            "('using', 'natural', 'language') 1\n",
            "('processing', 'for', 'malayalam') 1\n",
            "('for', 'malayalam', 'language') 1\n",
            "('malayalam', 'language', 'in') 1\n",
            "('language', 'in', 'these') 1\n",
            "('in', 'these', 'basic') 1\n",
            "('these', 'basic', 'in') 1\n",
            "('basic', 'in', 'the') 1\n",
            "('in', 'the', 'state') 2\n",
            "('the', 'state', 'of') 2\n",
            "('the', 'art', 'plan') 2\n",
            "('art', 'plan', 'recognition') 2\n",
            "('plan', 'recognition', 'systems') 2\n",
            "('recognition', 'systems', 'this') 2\n",
            "('this', 'paper', 'will') 2\n",
            "('paper', 'will', 'outline') 2\n",
            "('will', 'outline', 'the') 2\n",
            "('outline', 'the', 'relations') 2\n",
            "('the', 'relations', 'between') 2\n",
            "('relations', 'between', 'natural') 2\n",
            "('between', 'natural', 'language') 2\n",
            "('natural', 'language', 'processingnlp') 2\n",
            "('language', 'processingnlp', 'and') 2\n",
            "('processingnlp', 'and', 'plan') 2\n",
            "('and', 'plan', 'recognitionpr') 2\n",
            "('plan', 'recognitionpr', 'argue') 2\n",
            "('recognitionpr', 'argue', 'that') 2\n",
            "('argue', 'that', 'each') 2\n",
            "('that', 'each', 'of') 2\n",
            "('each', 'of', 'them') 2\n",
            "('of', 'them', 'can') 2\n",
            "('them', 'can', 'effectively') 2\n",
            "('can', 'effectively', 'inform') 2\n",
            "('effectively', 'inform', 'the') 2\n",
            "('inform', 'the', 'other') 2\n",
            "('the', 'other', 'and') 2\n",
            "('other', 'and', 'then') 2\n",
            "('and', 'then', 'focus') 2\n",
            "('then', 'focus', 'on') 2\n",
            "('focus', 'on', 'key') 2\n",
            "('on', 'key', 'recent') 2\n",
            "('key', 'recent', 'research') 2\n",
            "('recent', 'research', 'results') 2\n",
            "('research', 'results', 'in') 2\n",
            "('results', 'in', 'nlp') 2\n",
            "('in', 'nlp', 'and') 2\n",
            "('nlp', 'and', 'argue') 2\n",
            "('and', 'argue', 'for') 2\n",
            "('argue', 'for', 'their') 2\n",
            "('for', 'their', 'applicability') 2\n",
            "('their', 'applicability', 'to') 2\n",
            "('applicability', 'to', 'pr') 2\n",
            "('to', 'pr', 'in') 1\n",
            "('pr', 'in', 'the') 1\n",
            "('to', 'pr', 'information') 1\n",
            "('pr', 'information', 'retrieval') 1\n",
            "('information', 'retrieval', 'is') 1\n",
            "('retrieval', 'is', 'the') 1\n",
            "('is', 'the', 'process') 1\n",
            "('the', 'process', 'of') 2\n",
            "('process', 'of', 'finding') 1\n",
            "('of', 'finding', 'the') 1\n",
            "('finding', 'the', 'documents') 1\n",
            "('the', 'documents', 'in') 1\n",
            "('documents', 'in', 'a') 1\n",
            "('in', 'a', 'document') 1\n",
            "('a', 'document', 'collection') 1\n",
            "('document', 'collection', 'that') 1\n",
            "('collection', 'that', 'satisfies') 1\n",
            "('that', 'satisfies', 'the') 1\n",
            "('satisfies', 'the', 'information') 1\n",
            "('the', 'information', 'need') 1\n",
            "('information', 'need', 'of') 1\n",
            "('need', 'of', 'the') 1\n",
            "('of', 'the', 'user') 1\n",
            "('the', 'user', 'the') 1\n",
            "('user', 'the', 'documents') 1\n",
            "('the', 'documents', 'are') 1\n",
            "('documents', 'are', 'natural') 1\n",
            "('are', 'natural', 'language') 1\n",
            "('natural', 'language', 'constructs') 1\n",
            "('language', 'constructs', 'and') 1\n",
            "('constructs', 'and', 'the') 1\n",
            "('and', 'the', 'motivation') 1\n",
            "('the', 'motivation', 'of') 1\n",
            "('motivation', 'of', 'this') 1\n",
            "('of', 'this', 'work') 1\n",
            "('this', 'work', 'is') 1\n",
            "('work', 'is', 'to') 1\n",
            "('is', 'to', 'investigate') 1\n",
            "('to', 'investigate', 'how') 1\n",
            "('investigate', 'how', 'natural') 1\n",
            "('how', 'natural', 'language') 1\n",
            "('language', 'processing', 'can') 1\n",
            "('processing', 'can', 'be') 1\n",
            "('can', 'be', 'used') 2\n",
            "('be', 'used', 'to') 2\n",
            "('used', 'to', 'improve') 1\n",
            "('to', 'improve', 'of') 1\n",
            "('improve', 'of', 'logic') 1\n",
            "('of', 'logic', 'programming') 1\n",
            "('logic', 'programming', 'within') 1\n",
            "('programming', 'within', 'both') 1\n",
            "('within', 'both', 'natural') 1\n",
            "('both', 'natural', 'language') 1\n",
            "('natural', 'language', 'research') 1\n",
            "('language', 'research', 'and') 1\n",
            "('research', 'and', 'machine') 1\n",
            "('machine', 'learning', 'we') 1\n",
            "('learning', 'we', 'point') 1\n",
            "('we', 'point', 'out') 1\n",
            "('point', 'out', 'opportunities') 1\n",
            "('out', 'opportunities', 'for') 1\n",
            "('opportunities', 'for', 'induction') 1\n",
            "('for', 'induction', 'of') 1\n",
            "('induction', 'of', 'linguistic') 1\n",
            "('linguistic', 'knowledge', 'within') 1\n",
            "('knowledge', 'within', 'logic') 1\n",
            "('within', 'logic', 'programming') 1\n",
            "('logic', 'programming', 'keywords') 1\n",
            "('programming', 'keywords', 'inductive') 1\n",
            "('keywords', 'inductive', 'logic') 1\n",
            "('inductive', 'logic', 'programming') 1\n",
            "('logic', 'programming', 'natural') 1\n",
            "('programming', 'natural', 'language') 1\n",
            "('language', 'processing', 'logic') 1\n",
            "('processing', 'logic', 'programming') 1\n",
            "('logic', 'programming', 'machine') 1\n",
            "('programming', 'machine', 'learning') 1\n",
            "('machine', 'learning', 'introduction') 1\n",
            "('learning', 'introduction', 'there') 1\n",
            "('introduction', 'there', 'is') 1\n",
            "('there', 'is', 'a') 1\n",
            "('is', 'a', 'what') 1\n",
            "('a', 'what', 'is') 1\n",
            "('what', 'is', 'a') 1\n",
            "('is', 'a', 'statistical') 2\n",
            "('a', 'statistical', 'method') 1\n",
            "('statistical', 'method', 'and') 1\n",
            "('method', 'and', 'how') 1\n",
            "('and', 'how', 'can') 1\n",
            "('how', 'can', 'it') 1\n",
            "('can', 'it', 'be') 1\n",
            "('it', 'be', 'used') 1\n",
            "('be', 'used', 'in') 1\n",
            "('used', 'in', 'natural') 1\n",
            "('processing', 'nlp', 'in') 1\n",
            "('nlp', 'in', 'this') 1\n",
            "('paper', 'we', 'start') 1\n",
            "('we', 'start', 'from') 1\n",
            "('start', 'from', 'a') 1\n",
            "('from', 'a', 'definition') 1\n",
            "('a', 'definition', 'of') 1\n",
            "('definition', 'of', 'nlp') 1\n",
            "('of', 'nlp', 'as') 1\n",
            "('nlp', 'as', 'concerned') 1\n",
            "('as', 'concerned', 'with') 1\n",
            "('concerned', 'with', 'the') 1\n",
            "('with', 'the', 'design') 1\n",
            "('the', 'design', 'and') 2\n",
            "('design', 'and', 'implementation') 1\n",
            "('and', 'implementation', 'of') 1\n",
            "('implementation', 'of', 'effective') 1\n",
            "('of', 'effective', 'natural') 1\n",
            "('effective', 'natural', 'language') 1\n",
            "('natural', 'language', 'input') 1\n",
            "('language', 'input', 'and') 1\n",
            "('input', 'and', 'output') 1\n",
            "('and', 'output', 'components') 1\n",
            "('output', 'components', 'for') 1\n",
            "('components', 'for', 'computational') 1\n",
            "('for', 'computational', 'systems') 1\n",
            "('computational', 'systems', 'we') 1\n",
            "('systems', 'we', 'distinguish') 1\n",
            "('we', 'distinguish', 'three') 1\n",
            "('distinguish', 'three', 'in') 1\n",
            "('three', 'in', 'this') 1\n",
            "('in', 'this', 'report') 1\n",
            "('this', 'report', 'some') 1\n",
            "('report', 'some', 'collaborative') 1\n",
            "('some', 'collaborative', 'work') 1\n",
            "('collaborative', 'work', 'between') 1\n",
            "('work', 'between', 'the') 1\n",
            "('between', 'the', 'fields') 1\n",
            "('the', 'fields', 'of') 1\n",
            "('fields', 'of', 'machine') 1\n",
            "('of', 'machine', 'learning') 3\n",
            "('learning', 'ml', 'and') 1\n",
            "('ml', 'and', 'natural') 1\n",
            "('nlp', 'is', 'presented') 1\n",
            "('is', 'presented', 'the') 1\n",
            "('presented', 'the', 'document') 1\n",
            "('the', 'document', 'is') 1\n",
            "('document', 'is', 'structured') 1\n",
            "('is', 'structured', 'in') 1\n",
            "('structured', 'in', 'two') 1\n",
            "('in', 'two', 'parts') 1\n",
            "('two', 'parts', 'the') 1\n",
            "('parts', 'the', 'first') 1\n",
            "('the', 'first', 'part') 1\n",
            "('first', 'part', 'includes') 1\n",
            "('part', 'includes', 'a') 1\n",
            "('includes', 'a', 'superficial') 1\n",
            "('a', 'superficial', 'but') 1\n",
            "('superficial', 'but', 'comprehensive') 1\n",
            "('but', 'comprehensive', 'survey') 1\n",
            "('comprehensive', 'survey', 'covering') 1\n",
            "('survey', 'covering', 'the') 1\n",
            "('covering', 'the', 'stateoftheart') 1\n",
            "('the', 'stateoftheart', 'of') 1\n",
            "('stateoftheart', 'of', 'machine') 1\n",
            "('machine', 'learning', 'abstract') 1\n",
            "('learning', 'abstract', 'this') 1\n",
            "('abstract', 'this', 'thesis') 1\n",
            "('this', 'thesis', 'examines') 1\n",
            "('thesis', 'examines', 'the') 1\n",
            "('examines', 'the', 'use') 1\n",
            "('use', 'of', 'machine') 1\n",
            "('learning', 'techniques', 'in') 1\n",
            "('techniques', 'in', 'various') 1\n",
            "('in', 'various', 'tasks') 1\n",
            "('various', 'tasks', 'of') 1\n",
            "('tasks', 'of', 'natural') 1\n",
            "('language', 'processing', 'mainly') 1\n",
            "('processing', 'mainly', 'for') 1\n",
            "('mainly', 'for', 'the') 1\n",
            "('for', 'the', 'task') 1\n",
            "('the', 'task', 'of') 1\n",
            "('task', 'of', 'information') 1\n",
            "('of', 'information', 'extraction') 2\n",
            "('information', 'extraction', 'from') 1\n",
            "('extraction', 'from', 'texts') 1\n",
            "('from', 'texts', 'the') 1\n",
            "('texts', 'the', 'objectives') 1\n",
            "('the', 'objectives', 'are') 1\n",
            "('objectives', 'are', 'the') 1\n",
            "('are', 'the', 'improvement') 1\n",
            "('the', 'improvement', 'of') 2\n",
            "('improvement', 'of', 'adaptability') 1\n",
            "('of', 'adaptability', 'of') 1\n",
            "('adaptability', 'of', 'information') 1\n",
            "('information', 'extraction', 'systems') 1\n",
            "('extraction', 'systems', 'to') 1\n",
            "('systems', 'to', 'new') 1\n",
            "('to', 'new', 'thematic') 1\n",
            "('new', 'thematic', 'domains') 1\n",
            "('thematic', 'domains', 'or') 1\n",
            "('domains', 'or', 'even') 1\n",
            "('or', 'even', 'this') 1\n",
            "('even', 'this', 'chapter') 1\n",
            "('this', 'chapter', 'examines') 2\n",
            "('chapter', 'examines', 'the') 2\n",
            "('examines', 'the', 'application') 2\n",
            "('application', 'of', 'natural') 2\n",
            "('processing', 'to', 'computerassisted') 2\n",
            "('to', 'computerassisted', 'language') 2\n",
            "('computerassisted', 'language', 'learning') 2\n",
            "('language', 'learning', 'including') 2\n",
            "('learning', 'including', 'the') 2\n",
            "('including', 'the', 'history') 2\n",
            "('the', 'history', 'of') 2\n",
            "('history', 'of', 'work') 2\n",
            "('of', 'work', 'in') 2\n",
            "('work', 'in', 'this') 2\n",
            "('in', 'this', 'field') 2\n",
            "('this', 'field', 'over') 2\n",
            "('field', 'over', 'the') 2\n",
            "('the', 'last', 'thirtyfive') 2\n",
            "('last', 'thirtyfive', 'years') 2\n",
            "('thirtyfive', 'years', 'but') 2\n",
            "('years', 'but', 'with') 2\n",
            "('but', 'with', 'a') 2\n",
            "('focus', 'on', 'current') 2\n",
            "('on', 'current', 'developments') 2\n",
            "('current', 'developments', 'and') 2\n",
            "('developments', 'and', 'opportunities') 2\n",
            "('and', 'opportunities', 'traditional') 1\n",
            "('opportunities', 'traditional', 'approaches') 1\n",
            "('traditional', 'approaches', 'tointerpretation') 1\n",
            "('approaches', 'tointerpretation', 'in') 1\n",
            "('tointerpretation', 'in', 'natural') 1\n",
            "('language', 'processing', 'typically') 1\n",
            "('processing', 'typically', 'fall') 1\n",
            "('typically', 'fall', 'into') 1\n",
            "('fall', 'into', 'one') 1\n",
            "('into', 'one', 'of') 1\n",
            "('one', 'of', 'three') 1\n",
            "('of', 'three', 'classes') 1\n",
            "('three', 'classes', 'syntaxdriven') 1\n",
            "('classes', 'syntaxdriven', 'semanticsdriven') 1\n",
            "('syntaxdriven', 'semanticsdriven', 'or') 1\n",
            "('semanticsdriven', 'or', 'frametask') 1\n",
            "('or', 'frametask', 'based') 1\n",
            "('frametask', 'based', 'syntaxdriven') 1\n",
            "('based', 'syntaxdriven', 'approaches') 1\n",
            "('syntaxdriven', 'approaches', 'use') 1\n",
            "('approaches', 'use', 'a') 1\n",
            "('use', 'a', 'domainindependent') 1\n",
            "('a', 'domainindependent', 'grammar') 1\n",
            "('domainindependent', 'grammar', 'to') 1\n",
            "('grammar', 'to', 'drive') 1\n",
            "('to', 'drive', 'the') 1\n",
            "('drive', 'the', 'interpretation') 1\n",
            "('the', 'interpretation', 'process') 1\n",
            "('interpretation', 'process', 'and') 1\n",
            "('process', 'and', 'produce') 1\n",
            "('and', 'produce', 'a') 1\n",
            "('produce', 'a', 'global') 1\n",
            "('a', 'global', 'parse') 1\n",
            "('global', 'parse', 'natural') 1\n",
            "('parse', 'natural', 'language') 1\n",
            "('nlp', 'is', 'a') 1\n",
            "('is', 'a', 'very') 1\n",
            "('a', 'very', 'large') 1\n",
            "('very', 'large', 'and') 1\n",
            "('large', 'and', 'diverse') 1\n",
            "('and', 'diverse', 'subtopic') 1\n",
            "('diverse', 'subtopic', 'of') 1\n",
            "('subtopic', 'of', 'artificial') 1\n",
            "('of', 'artificial', 'intelligence') 2\n",
            "('artificial', 'intelligence', 'as') 1\n",
            "('intelligence', 'as', 'a') 1\n",
            "('as', 'a', 'result') 1\n",
            "('a', 'result', 'nlp') 1\n",
            "('result', 'nlp', 'itself') 1\n",
            "('nlp', 'itself', 'has') 1\n",
            "('itself', 'has', 'many') 1\n",
            "('has', 'many', 'subtopics') 1\n",
            "('many', 'subtopics', 'including') 1\n",
            "('subtopics', 'including', 'optical') 1\n",
            "('including', 'optical', 'character') 1\n",
            "('optical', 'character', 'recognition') 1\n",
            "('character', 'recognition', 'text') 1\n",
            "('recognition', 'text', 'to') 1\n",
            "('text', 'to', 'speech') 1\n",
            "('to', 'speech', 'translators') 1\n",
            "('speech', 'translators', 'foreign') 1\n",
            "('translators', 'foreign', 'language') 1\n",
            "('foreign', 'language', 'reading') 1\n",
            "('language', 'reading', 'and') 1\n",
            "('reading', 'and', 'writing') 1\n",
            "('and', 'writing', 'aids') 1\n",
            "('writing', 'aids', 'machine') 1\n",
            "('aids', 'machine', 'translation') 1\n",
            "('translation', 'and', 'speech') 1\n",
            "('and', 'speech', 'recognition') 1\n",
            "('speech', 'recognition', 'probabilistic') 1\n",
            "('recognition', 'probabilistic', 'finitestate') 1\n",
            "('probabilistic', 'finitestate', 'string') 1\n",
            "('finitestate', 'string', 'transducers') 1\n",
            "('string', 'transducers', 'fsts') 1\n",
            "('transducers', 'fsts', 'are') 1\n",
            "('fsts', 'are', 'extremely') 1\n",
            "('are', 'extremely', 'popular') 1\n",
            "('extremely', 'popular', 'in') 1\n",
            "('popular', 'in', 'natural') 1\n",
            "('language', 'processing', 'due') 1\n",
            "('processing', 'due', 'to') 1\n",
            "('due', 'to', 'powerful') 1\n",
            "('to', 'powerful', 'generic') 1\n",
            "('powerful', 'generic', 'methods') 1\n",
            "('generic', 'methods', 'for') 1\n",
            "('methods', 'for', 'applying') 1\n",
            "('for', 'applying', 'composing') 1\n",
            "('applying', 'composing', 'and') 1\n",
            "('composing', 'and', 'learning') 1\n",
            "('and', 'learning', 'them') 1\n",
            "('learning', 'them', 'unfortunately') 1\n",
            "('them', 'unfortunately', 'fsts') 1\n",
            "('unfortunately', 'fsts', 'are') 1\n",
            "('fsts', 'are', 'not') 1\n",
            "('are', 'not', 'a') 1\n",
            "('not', 'a', 'good') 1\n",
            "('a', 'good', 'fit') 1\n",
            "('good', 'fit', 'for') 1\n",
            "('fit', 'for', 'much') 1\n",
            "('for', 'much', 'of') 1\n",
            "('much', 'of', 'the') 1\n",
            "('the', 'current', 'work') 1\n",
            "('current', 'work', 'on') 1\n",
            "('work', 'on', 'probabilistic') 1\n",
            "('on', 'probabilistic', 'modeling') 1\n",
            "('probabilistic', 'modeling', 'for') 1\n",
            "('modeling', 'for', 'machine') 1\n",
            "('for', 'machine', 'abstract') 1\n",
            "('machine', 'abstract', 'in') 1\n",
            "('abstract', 'in', 'this') 1\n",
            "('in', 'this', 'special') 1\n",
            "('this', 'special', 'issue') 1\n",
            "('special', 'issue', 'of') 1\n",
            "('issue', 'of', 'tal') 1\n",
            "('of', 'tal', 'we') 1\n",
            "('tal', 'we', 'look') 1\n",
            "('we', 'look', 'at') 1\n",
            "('look', 'at', 'the') 1\n",
            "('at', 'the', 'fundamental') 1\n",
            "('the', 'fundamental', 'principles') 1\n",
            "('fundamental', 'principles', 'underlying') 1\n",
            "('principles', 'underlying', 'evaluation') 1\n",
            "('underlying', 'evaluation', 'in') 1\n",
            "('evaluation', 'in', 'natural') 1\n",
            "('processing', 'we', 'adopt') 1\n",
            "('we', 'adopt', 'a') 1\n",
            "('adopt', 'a', 'global') 1\n",
            "('a', 'global', 'point') 1\n",
            "('global', 'point', 'of') 1\n",
            "('point', 'of', 'view') 1\n",
            "('of', 'view', 'that') 1\n",
            "('view', 'that', 'goes') 1\n",
            "('that', 'goes', 'beyond') 1\n",
            "('goes', 'beyond', 'the') 1\n",
            "('beyond', 'the', 'horizon') 1\n",
            "('the', 'horizon', 'of') 1\n",
            "('horizon', 'of', 'a') 1\n",
            "('of', 'a', 'single') 1\n",
            "('a', 'single', 'evaluation') 1\n",
            "('single', 'evaluation', 'campaign') 1\n",
            "('evaluation', 'campaign', 'or') 1\n",
            "('campaign', 'or', 'a') 1\n",
            "('or', 'a', 'particular') 1\n",
            "('a', 'particular', 'protocol') 1\n",
            "('particular', 'protocol', 'after') 1\n",
            "('protocol', 'after', 'a') 1\n",
            "('after', 'a', 'brief') 1\n",
            "('a', 'brief', 'review') 1\n",
            "('brief', 'review', 'of') 1\n",
            "('review', 'of', 'history') 1\n",
            "('history', 'and', 'terminology') 1\n",
            "('and', 'terminology', 'abstract') 1\n",
            "('terminology', 'abstract', 'not') 1\n",
            "('not', 'found', 'natural') 1\n",
            "('found', 'natural', 'language') 1\n",
            "('processing', 'systems', 'nlp') 1\n",
            "('systems', 'nlp', 'that') 1\n",
            "('nlp', 'that', 'extract') 1\n",
            "('that', 'extract', 'clinical') 1\n",
            "('extract', 'clinical', 'information') 1\n",
            "('clinical', 'information', 'from') 1\n",
            "('information', 'from', 'textual') 1\n",
            "('from', 'textual', 'reports') 1\n",
            "('textual', 'reports', 'were') 1\n",
            "('reports', 'were', 'shown') 1\n",
            "('were', 'shown', 'to') 1\n",
            "('shown', 'to', 'be') 1\n",
            "('to', 'be', 'effective') 1\n",
            "('be', 'effective', 'for') 1\n",
            "('effective', 'for', 'limited') 1\n",
            "('for', 'limited', 'domains') 1\n",
            "('limited', 'domains', 'and') 1\n",
            "('domains', 'and', 'for') 1\n",
            "('and', 'for', 'particular') 1\n",
            "('for', 'particular', 'applications') 1\n",
            "('particular', 'applications', 'because') 1\n",
            "('applications', 'because', 'an') 1\n",
            "('because', 'an', 'nlp') 1\n",
            "('an', 'nlp', 'system') 1\n",
            "('nlp', 'system', 'typically') 1\n",
            "('system', 'typically', 'requires') 1\n",
            "('typically', 'requires', 'substantial') 1\n",
            "('requires', 'substantial', 'resources') 1\n",
            "('substantial', 'resources', 'to') 1\n",
            "('resources', 'to', 'develop') 1\n",
            "('to', 'develop', 'it') 1\n",
            "('develop', 'it', 'is') 1\n",
            "('it', 'is', 'beneficial') 1\n",
            "('is', 'beneficial', 'if') 1\n",
            "('beneficial', 'if', 'it') 1\n",
            "('if', 'it', 'is') 1\n",
            "('it', 'is', 'designed') 1\n",
            "('is', 'designed', 'to') 1\n",
            "('designed', 'to', 'be') 1\n",
            "('to', 'be', 'easily') 1\n",
            "('be', 'easily', 'facts') 1\n",
            "('easily', 'facts', 'forms') 1\n",
            "('facts', 'forms', 'a') 1\n",
            "('forms', 'a', 'link') 1\n",
            "('a', 'link', 'between') 1\n",
            "('link', 'between', 'ie') 1\n",
            "('between', 'ie', 'a') 1\n",
            "('ie', 'a', 'recent') 1\n",
            "('a', 'recent', 'development') 1\n",
            "('language', 'processing', 'and') 1\n",
            "('processing', 'and', 'logic') 1\n",
            "('and', 'logic', 'programming') 1\n",
            "('logic', 'programming', 'with') 1\n",
            "('programming', 'with', 'prolog') 1\n",
            "('with', 'prolog', 'we') 1\n",
            "('prolog', 'we', 'describe') 1\n",
            "('describe', 'a', 'single') 1\n",
            "('a', 'single', 'convolutional') 1\n",
            "('single', 'convolutional', 'neural') 1\n",
            "('convolutional', 'neural', 'network') 1\n",
            "('neural', 'network', 'architecture') 1\n",
            "('network', 'architecture', 'that') 1\n",
            "('architecture', 'that', 'given') 1\n",
            "('that', 'given', 'a') 1\n",
            "('given', 'a', 'sentence') 1\n",
            "('a', 'sentence', 'outputs') 1\n",
            "('sentence', 'outputs', 'a') 1\n",
            "('outputs', 'a', 'host') 1\n",
            "('a', 'host', 'of') 1\n",
            "('host', 'of', 'language') 1\n",
            "('language', 'processing', 'predictions') 1\n",
            "('processing', 'predictions', 'partofspeech') 1\n",
            "('predictions', 'partofspeech', 'tags') 1\n",
            "('partofspeech', 'tags', 'chunks') 1\n",
            "('tags', 'chunks', 'named') 1\n",
            "('chunks', 'named', 'entity') 1\n",
            "('named', 'entity', 'tags') 1\n",
            "('entity', 'tags', 'semantic') 1\n",
            "('tags', 'semantic', 'roles') 1\n",
            "('semantic', 'roles', 'semantically') 1\n",
            "('roles', 'semantically', 'similar') 1\n",
            "('semantically', 'similar', 'words') 1\n",
            "('similar', 'words', 'and') 1\n",
            "('words', 'and', 'the') 1\n",
            "('and', 'the', 'likelihood') 1\n",
            "('the', 'likelihood', 'that') 1\n",
            "('likelihood', 'that', 'the') 1\n",
            "('that', 'the', 'sentence') 1\n",
            "('the', 'sentence', 'makes') 1\n",
            "('sentence', 'makes', 'sense') 1\n",
            "('makes', 'sense', 'grammatically') 1\n",
            "('sense', 'grammatically', 'we') 1\n",
            "('grammatically', 'we', 'developed') 1\n",
            "('we', 'developed', 'a') 1\n",
            "('developed', 'a', 'prototype') 1\n",
            "('a', 'prototype', 'information') 1\n",
            "('prototype', 'information', 'retrieval') 1\n",
            "('retrieval', 'system', 'which') 1\n",
            "('system', 'which', 'uses') 1\n",
            "('which', 'uses', 'advanced') 1\n",
            "('uses', 'advanced', 'natural') 1\n",
            "('advanced', 'natural', 'language') 1\n",
            "('processing', 'techniques', 'to') 1\n",
            "('techniques', 'to', 'enhance') 1\n",
            "('to', 'enhance', 'the') 1\n",
            "('enhance', 'the', 'effectiveness') 1\n",
            "('the', 'effectiveness', 'of') 1\n",
            "('effectiveness', 'of', 'traditional') 1\n",
            "('of', 'traditional', 'keyword') 1\n",
            "('traditional', 'keyword', 'based') 1\n",
            "('keyword', 'based', 'document') 1\n",
            "('based', 'document', 'retrieval') 1\n",
            "('document', 'retrieval', 'the') 1\n",
            "('retrieval', 'the', 'backbone') 1\n",
            "('the', 'backbone', 'of') 1\n",
            "('backbone', 'of', 'our') 1\n",
            "('of', 'our', 'system') 1\n",
            "('our', 'system', 'is') 1\n",
            "('system', 'is', 'a') 1\n",
            "('a', 'statistical', 'retrieval') 1\n",
            "('statistical', 'retrieval', 'engine') 1\n",
            "('retrieval', 'engine', 'which') 1\n",
            "('engine', 'which', 'performs') 1\n",
            "('which', 'performs', 'automated') 1\n",
            "('performs', 'automated', 'indexing') 1\n",
            "('automated', 'indexing', 'abstract') 1\n",
            "('indexing', 'abstract', 'not') 1\n",
            "('found', 'in', 'this') 1\n",
            "('we', 'will', 'discuss') 1\n",
            "('will', 'discuss', 'several') 1\n",
            "('discuss', 'several', 'issues') 1\n",
            "('several', 'issues', 'and') 1\n",
            "('issues', 'and', 'requirements') 1\n",
            "('and', 'requirements', 'for') 1\n",
            "('requirements', 'for', 'enabling') 1\n",
            "('for', 'enabling', 'natural') 1\n",
            "('enabling', 'natural', 'language') 1\n",
            "('processing', 'systems', 'to') 1\n",
            "('systems', 'to', 'become') 1\n",
            "('to', 'become', 'contextadaptive') 1\n",
            "('become', 'contextadaptive', 'given') 1\n",
            "('contextadaptive', 'given', 'the') 1\n",
            "('given', 'the', 'fact') 1\n",
            "('the', 'fact', 'that') 1\n",
            "('fact', 'that', 'emerging') 1\n",
            "('that', 'emerging', 'systems') 1\n",
            "('emerging', 'systems', 'feature') 1\n",
            "('systems', 'feature', 'speaker') 1\n",
            "('feature', 'speaker', 'independent') 1\n",
            "('speaker', 'independent', 'continuous') 1\n",
            "('independent', 'continuous', 'speech') 1\n",
            "('continuous', 'speech', 'recognition') 1\n",
            "('speech', 'recognition', 'restricted') 1\n",
            "('recognition', 'restricted', 'to') 1\n",
            "('restricted', 'to', 'individual') 1\n",
            "('to', 'individual', 'domains') 1\n",
            "('individual', 'domains', 'and') 1\n",
            "('domains', 'and', 'are') 1\n",
            "('and', 'are', 'equipped') 1\n",
            "('are', 'equipped', 'with') 1\n",
            "('equipped', 'with', 'syntactic') 1\n",
            "('with', 'syntactic', 'in') 1\n",
            "('syntactic', 'in', 'fall') 1\n",
            "('in', 'fall', 'i') 1\n",
            "('fall', 'i', 'introduced') 1\n",
            "('i', 'introduced', 'a') 1\n",
            "('introduced', 'a', 'new') 1\n",
            "('a', 'new', 'course') 1\n",
            "('new', 'course', 'called') 1\n",
            "('course', 'called', 'applied') 1\n",
            "('called', 'applied', 'natural') 1\n",
            "('applied', 'natural', 'language') 1\n",
            "('language', 'processing', 'in') 1\n",
            "('processing', 'in', 'which') 1\n",
            "('in', 'which', 'students') 1\n",
            "('which', 'students', 'acquire') 1\n",
            "('students', 'acquire', 'an') 1\n",
            "('acquire', 'an', 'understanding') 1\n",
            "('an', 'understanding', 'of') 1\n",
            "('understanding', 'of', 'which') 1\n",
            "('of', 'which', 'text') 1\n",
            "('which', 'text', 'analysis') 1\n",
            "('text', 'analysis', 'techniques') 1\n",
            "('analysis', 'techniques', 'are') 1\n",
            "('techniques', 'are', 'currently') 1\n",
            "('are', 'currently', 'feasible') 1\n",
            "('currently', 'feasible', 'for') 1\n",
            "('feasible', 'for', 'practical') 1\n",
            "('for', 'practical', 'applications') 1\n",
            "('practical', 'applications', 'abstract') 1\n",
            "('applications', 'abstract', 'not') 1\n",
            "('found', 'abstract', 'natural') 1\n",
            "('processing', 'is', 'the') 2\n",
            "('is', 'the', 'study') 1\n",
            "('the', 'study', 'of') 1\n",
            "('study', 'of', 'mathematical') 1\n",
            "('of', 'mathematical', 'and') 1\n",
            "('mathematical', 'and', 'computational') 1\n",
            "('and', 'computational', 'modelling') 1\n",
            "('computational', 'modelling', 'of') 1\n",
            "('modelling', 'of', 'various') 1\n",
            "('of', 'various', 'aspects') 1\n",
            "('various', 'aspects', 'of') 1\n",
            "('aspects', 'of', 'language') 1\n",
            "('of', 'language', 'and') 1\n",
            "('language', 'and', 'the') 2\n",
            "('and', 'the', 'improvement') 1\n",
            "('improvement', 'of', 'a') 1\n",
            "('of', 'a', 'wide') 1\n",
            "('a', 'wide', 'range') 2\n",
            "('wide', 'range', 'of') 2\n",
            "('range', 'of', 'systems') 1\n",
            "('of', 'systems', 'natural') 1\n",
            "('systems', 'natural', 'language') 1\n",
            "('natural', 'language', 'is') 1\n",
            "('language', 'is', 'any') 1\n",
            "('is', 'any', 'language') 1\n",
            "('any', 'language', 'that') 1\n",
            "('language', 'that', 'arises') 1\n",
            "('that', 'arises', 'as') 1\n",
            "('arises', 'as', 'an') 1\n",
            "('as', 'an', 'innate') 1\n",
            "('an', 'innate', 'facility') 1\n",
            "('innate', 'facility', 'for') 1\n",
            "('facility', 'for', 'language') 1\n",
            "('for', 'language', 'possessed') 1\n",
            "('language', 'possessed', 'by') 1\n",
            "('possessed', 'by', 'the') 1\n",
            "('by', 'the', 'human') 1\n",
            "('the', 'human', 'intellect') 1\n",
            "('human', 'intellect', 'it') 1\n",
            "('intellect', 'it', 'may') 1\n",
            "('it', 'may', 'natural') 1\n",
            "('may', 'natural', 'language') 1\n",
            "('processing', 'nlp', 'which') 1\n",
            "('nlp', 'which', 'is') 1\n",
            "('which', 'is', 'a') 1\n",
            "('is', 'a', 'branch') 1\n",
            "('a', 'branch', 'of') 1\n",
            "('branch', 'of', 'artificial') 1\n",
            "('artificial', 'intelligence', 'includes') 1\n",
            "('intelligence', 'includes', 'speech') 1\n",
            "('includes', 'speech', 'synthesis') 1\n",
            "('speech', 'synthesis', 'speech') 1\n",
            "('synthesis', 'speech', 'recognition') 1\n",
            "('speech', 'recognition', 'and') 1\n",
            "('recognition', 'and', 'machine') 1\n",
            "('and', 'machine', 'translation') 1\n",
            "('machine', 'translation', 'natural') 1\n",
            "('translation', 'natural', 'language') 1\n",
            "('processing', 'has', 'a') 1\n",
            "('has', 'a', 'wide') 1\n",
            "('range', 'of', 'applications') 1\n",
            "('of', 'applications', 'in') 1\n",
            "('applications', 'in', 'the') 1\n",
            "('in', 'the', 'indian') 1\n",
            "('the', 'indian', 'context') 1\n",
            "('indian', 'context', 'most') 1\n",
            "('context', 'most', 'of') 1\n",
            "('most', 'of', 'the') 1\n",
            "('of', 'the', 'rural') 1\n",
            "('the', 'rural', 'indian') 1\n",
            "('rural', 'indian', 'community') 1\n",
            "('indian', 'community', 'is') 1\n",
            "('community', 'is', 'unable') 1\n",
            "('is', 'unable', 'to') 1\n",
            "('unable', 'to', 'make') 1\n",
            "('to', 'make', 'use') 1\n",
            "('make', 'use', 'an') 1\n",
            "('use', 'an', 'evaluation') 1\n",
            "('an', 'evaluation', 'of') 1\n",
            "('evaluation', 'of', 'lolita') 1\n",
            "('of', 'lolita', 'and') 1\n",
            "('lolita', 'and', 'related') 1\n",
            "('and', 'related', 'natural') 1\n",
            "('related', 'natural', 'language') 1\n",
            "('processing', 'systems', 'paul') 1\n",
            "('systems', 'paul', 'callaghan') 1\n",
            "('paul', 'callaghan', 'submitted') 1\n",
            "('callaghan', 'submitted', 'to') 1\n",
            "('submitted', 'to', 'the') 1\n",
            "('to', 'the', 'university') 1\n",
            "('the', 'university', 'of') 1\n",
            "('university', 'of', 'durham') 1\n",
            "('of', 'durham', 'for') 1\n",
            "('durham', 'for', 'the') 1\n",
            "('for', 'the', 'degree') 1\n",
            "('the', 'degree', 'of') 1\n",
            "('degree', 'of', 'phd') 1\n",
            "('of', 'phd', 'august') 1\n",
            "('phd', 'august', 'this') 1\n",
            "('august', 'this', 'research') 1\n",
            "('this', 'research', 'addresses') 1\n",
            "('research', 'addresses', 'the') 1\n",
            "('addresses', 'the', 'question') 1\n",
            "('the', 'question', 'how') 1\n",
            "('question', 'how', 'do') 1\n",
            "('how', 'do', 'we') 1\n",
            "('do', 'we', 'evaluate') 1\n",
            "('we', 'evaluate', 'systems') 1\n",
            "('evaluate', 'systems', 'like') 1\n",
            "('systems', 'like', 'lolita') 1\n",
            "('like', 'lolita', 'lolita') 1\n",
            "('lolita', 'lolita', 'is') 1\n",
            "('lolita', 'is', 'the') 1\n",
            "('is', 'the', 'natural') 1\n",
            "('the', 'natural', 'previous') 1\n",
            "('natural', 'previous', 'work') 1\n",
            "('previous', 'work', 'demonstrated') 1\n",
            "('work', 'demonstrated', 'that') 1\n",
            "('demonstrated', 'that', 'web') 1\n",
            "('that', 'web', 'counts') 1\n",
            "('web', 'counts', 'can') 1\n",
            "('counts', 'can', 'be') 1\n",
            "('used', 'to', 'approximate') 1\n",
            "('to', 'approximate', 'bigram') 1\n",
            "('approximate', 'bigram', 'counts') 1\n",
            "('bigram', 'counts', 'suggesting') 1\n",
            "('counts', 'suggesting', 'that') 1\n",
            "('suggesting', 'that', 'webbased') 1\n",
            "('that', 'webbased', 'frequencies') 1\n",
            "('webbased', 'frequencies', 'should') 1\n",
            "('frequencies', 'should', 'be') 1\n",
            "('should', 'be', 'useful') 1\n",
            "('be', 'useful', 'for') 1\n",
            "('useful', 'for', 'a') 1\n",
            "('for', 'a', 'wide') 1\n",
            "('a', 'wide', 'variety') 1\n",
            "('wide', 'variety', 'of') 1\n",
            "('variety', 'of', 'natural') 1\n",
            "('nlp', 'tasks', 'however') 1\n",
            "('tasks', 'however', 'only') 1\n",
            "('however', 'only', 'a') 1\n",
            "('only', 'a', 'limited') 1\n",
            "('a', 'limited', 'number') 1\n",
            "('limited', 'number', 'of') 1\n",
            "('of', 'tasks', 'have') 1\n",
            "('tasks', 'have', 'so') 1\n",
            "('have', 'so', 'far') 1\n",
            "('so', 'far', 'been') 1\n",
            "('far', 'been', 'tested') 1\n",
            "('been', 'tested', 'using') 1\n",
            "('tested', 'using', 'webscale') 1\n",
            "('using', 'webscale', 'data') 1\n",
            "('webscale', 'data', 'sets') 1\n",
            "('data', 'sets', 'this') 1\n",
            "('sets', 'this', 'chapter') 1\n",
            "('and', 'opportunities', 'introduction') 1\n",
            "('opportunities', 'introduction', 'this') 1\n",
            "('introduction', 'this', 'chapter') 1\n",
            "('this', 'chapter', 'focuses') 1\n",
            "('chapter', 'focuses', 'on') 1\n",
            "('focuses', 'on', 'applications') 1\n",
            "('on', 'applications', 'this') 1\n",
            "('applications', 'this', 'paper') 1\n",
            "('this', 'paper', 'describes') 1\n",
            "('paper', 'describes', 'a') 1\n",
            "('describes', 'a', 'natural') 1\n",
            "('natural', 'language', 'system') 1\n",
            "('language', 'system', 'which') 1\n",
            "('system', 'which', 'improves') 1\n",
            "('which', 'improves', 'its') 1\n",
            "('improves', 'its', 'own') 1\n",
            "('its', 'own', 'performance') 1\n",
            "('own', 'performance', 'through') 1\n",
            "('performance', 'through', 'learning') 1\n",
            "('through', 'learning', 'the') 1\n",
            "('learning', 'the', 'system') 1\n",
            "('the', 'system', 'processes') 1\n",
            "('system', 'processes', 'short') 1\n",
            "('processes', 'short', 'english') 1\n",
            "('short', 'english', 'narratives') 1\n",
            "('english', 'narratives', 'and') 1\n",
            "('narratives', 'and', 'is') 1\n",
            "('and', 'is', 'able') 1\n",
            "('is', 'able', 'to') 1\n",
            "('able', 'to', 'acquire') 1\n",
            "('to', 'acquire', 'from') 1\n",
            "('acquire', 'from', 'a') 1\n",
            "('from', 'a', 'single') 1\n",
            "('a', 'single', 'narrative') 1\n",
            "('single', 'narrative', 'a') 1\n",
            "('narrative', 'a', 'new') 1\n",
            "('a', 'new', 'schema') 1\n",
            "('new', 'schema', 'for') 1\n",
            "('schema', 'for', 'a') 1\n",
            "('for', 'a', 'stereotypical') 1\n",
            "('a', 'stereotypical', 'set') 1\n",
            "('stereotypical', 'set', 'of') 1\n",
            "('set', 'of', 'actions') 1\n",
            "('of', 'actions', 'during') 1\n",
            "('actions', 'during', 'the') 1\n",
            "('during', 'the', 'understanding') 1\n",
            "('the', 'understanding', 'process') 1\n",
            "('understanding', 'process', 'the') 1\n",
            "('process', 'the', 'system') 1\n",
            "('the', 'system', 'attempts') 1\n",
            "('system', 'attempts', 'we') 1\n",
            "('attempts', 'we', 'classify') 1\n",
            "('we', 'classify', 'and') 1\n",
            "('classify', 'and', 'review') 1\n",
            "('and', 'review', 'current') 1\n",
            "('review', 'current', 'approaches') 1\n",
            "('current', 'approaches', 'to') 1\n",
            "('approaches', 'to', 'software') 1\n",
            "('to', 'software', 'infrastructure') 1\n",
            "('software', 'infrastructure', 'for') 1\n",
            "('infrastructure', 'for', 'research') 1\n",
            "('for', 'research', 'development') 1\n",
            "('research', 'development', 'and') 1\n",
            "('development', 'and', 'delivery') 1\n",
            "('and', 'delivery', 'of') 1\n",
            "('delivery', 'of', 'nlp') 1\n",
            "('of', 'nlp', 'systems') 1\n",
            "('nlp', 'systems', 'the') 1\n",
            "('systems', 'the', 'task') 1\n",
            "('the', 'task', 'confidence') 1\n",
            "('task', 'confidence', 'measures') 1\n",
            "('confidence', 'measures', 'are') 1\n",
            "('measures', 'are', 'a') 1\n",
            "('are', 'a', 'practical') 1\n",
            "('a', 'practical', 'solution') 1\n",
            "('practical', 'solution', 'for') 1\n",
            "('solution', 'for', 'improving') 1\n",
            "('for', 'improving', 'the') 1\n",
            "('improving', 'the', 'usefulness') 1\n",
            "('the', 'usefulness', 'of') 1\n",
            "('usefulness', 'of', 'natural') 1\n",
            "('language', 'processing', 'applications') 1\n",
            "('processing', 'applications', 'confidence') 1\n",
            "('applications', 'confidence', 'estimation') 1\n",
            "('confidence', 'estimation', 'is') 1\n",
            "('estimation', 'is', 'a') 1\n",
            "('is', 'a', 'generic') 1\n",
            "('a', 'generic', 'machine') 1\n",
            "('generic', 'machine', 'learning') 1\n",
            "('machine', 'learning', 'approach') 1\n",
            "('learning', 'approach', 'for') 1\n",
            "('approach', 'for', 'deriving') 1\n",
            "('for', 'deriving', 'confidence') 1\n",
            "('deriving', 'confidence', 'measures') 1\n",
            "('confidence', 'measures', 'we') 1\n",
            "('measures', 'we', 'give') 1\n",
            "('we', 'give', 'an') 1\n",
            "('give', 'an', 'overview') 1\n",
            "('an', 'overview', 'of') 1\n",
            "('overview', 'of', 'the') 1\n",
            "('of', 'the', 'application') 1\n",
            "('application', 'of', 'confidence') 1\n",
            "('of', 'confidence', 'estimation') 1\n",
            "('confidence', 'estimation', 'in') 1\n",
            "('estimation', 'in', 'various') 1\n",
            "('in', 'various', 'fields') 1\n",
            "('various', 'fields', 'lexsign') 1\n",
            "('fields', 'lexsign', 'senseid') 1\n",
            "('lexsign', 'senseid', 'senseid') 3\n",
            "('senseid', 'senseid', 'dictionary') 1\n",
            "('senseid', 'dictionary', 'ldoce') 1\n",
            "('dictionary', 'ldoce', 'lexsign') 1\n",
            "('ldoce', 'lexsign', 'senseid') 1\n",
            "('senseid', 'senseid', 'ldbentryno') 1\n",
            "('senseid', 'ldbentryno', 'lexsign') 1\n",
            "('ldbentryno', 'lexsign', 'senseid') 1\n",
            "('senseid', 'senseid', 'senseno') 1\n",
            "('senseid', 'senseno', 'when') 1\n",
            "('senseno', 'when', 'loaded') 1\n",
            "('when', 'loaded', 'into') 1\n",
            "('loaded', 'into', 'the') 1\n",
            "('into', 'the', 'lkb') 1\n",
            "('the', 'lkb', 'will') 1\n",
            "('lkb', 'will', 'be') 1\n",
            "('will', 'be', 'expanded') 1\n",
            "('be', 'expanded', 'into') 1\n",
            "('expanded', 'into', 'a') 1\n",
            "('into', 'a', 'fullyfledged') 1\n",
            "('a', 'fullyfledged', 'representation') 1\n",
            "('fullyfledged', 'representation', 'for') 1\n",
            "('representation', 'for', 'the') 1\n",
            "('for', 'the', 'transitive') 1\n",
            "('the', 'transitive', 'use') 1\n",
            "('transitive', 'use', 'of') 1\n",
            "('use', 'of', 'experience') 1\n",
            "('of', 'experience', 'by') 1\n",
            "('experience', 'by', 'integrating') 1\n",
            "('by', 'integrating', 'wordspecific') 1\n",
            "('integrating', 'wordspecific', 'information') 1\n",
            "('wordspecific', 'information', 'provided') 1\n",
            "('information', 'provided', 'by') 1\n",
            "('provided', 'by', 'with') 1\n",
            "('by', 'with', 'the') 1\n",
            "('with', 'the', 'information') 1\n",
            "('the', 'information', 'encoded') 1\n",
            "('information', 'encoded', 'by') 1\n",
            "('encoded', 'by', 'the') 1\n",
            "('by', 'the', 'lkb') 1\n",
            "('the', 'lkb', 'type') 1\n",
            "('lkb', 'type', 'stricttranssign') 1\n",
            "('type', 'stricttranssign', 'thus') 1\n",
            "('stricttranssign', 'thus', 'although') 1\n",
            "('thus', 'although', 'neither') 1\n",
            "('although', 'neither', 'ldoce') 1\n",
            "('neither', 'ldoce', 'llce') 1\n",
            "('ldoce', 'llce', 'or') 1\n",
            "('llce', 'or', 'the') 1\n",
            "('or', 'the', 'earlier') 1\n",
            "('the', 'earlier', 'subcategorised') 1\n",
            "('earlier', 'subcategorised', 'lexicon') 1\n",
            "('subcategorised', 'lexicon', 'contain') 1\n",
            "('lexicon', 'contain', 'all') 1\n",
            "('contain', 'all', 'the') 1\n",
            "('all', 'the', 'information') 1\n",
            "('the', 'information', 'about') 1\n",
            "('information', 'about', 'psychological') 1\n",
            "('about', 'psychological', 'verbs') 1\n",
            "('psychological', 'verbs', 'defined') 1\n",
            "('verbs', 'defined', 'in') 1\n",
            "('defined', 'in', 'sanfilippoaposs') 1\n",
            "('in', 'sanfilippoaposs', 'type') 1\n",
            "('sanfilippoaposs', 'type', 'system') 1\n",
            "('type', 'system', 'by') 1\n",
            "('system', 'by', 'using') 1\n",
            "('by', 'using', 'the') 1\n",
            "('using', 'the', 'conjunction') 1\n",
            "('the', 'conjunction', 'of') 1\n",
            "('conjunction', 'of', 'information') 1\n",
            "('of', 'information', 'available') 1\n",
            "('information', 'available', 'from') 1\n",
            "('available', 'from', 'all') 1\n",
            "('from', 'all', 'three') 1\n",
            "('all', 'three', 'it') 1\n",
            "('three', 'it', 'proved') 1\n",
            "('it', 'proved', 'possible') 1\n",
            "('proved', 'possible', 'to') 1\n",
            "('possible', 'to', 'effectively') 1\n",
            "('to', 'effectively', 'enrich') 1\n",
            "('effectively', 'enrich', 'this') 1\n",
            "('enrich', 'this', 'information') 1\n",
            "('this', 'information', 'at') 1\n",
            "('information', 'at', 'the') 1\n",
            "('at', 'the', 'same') 1\n",
            "('the', 'same', 'time') 1\n",
            "('same', 'time', 'as') 1\n",
            "('time', 'as', 'mapping') 1\n",
            "('as', 'mapping', 'it') 1\n",
            "('mapping', 'it', 'into') 1\n",
            "('it', 'into', 'a') 1\n",
            "('into', 'a', 'formal') 1\n",
            "('a', 'formal', 'representation') 1\n",
            "('formal', 'representation', 'towards') 1\n",
            "('representation', 'towards', 'a') 1\n",
            "('towards', 'a', 'multilingual') 1\n",
            "('a', 'multilingual', 'lkb') 1\n",
            "('multilingual', 'lkb', 'a') 1\n",
            "('lkb', 'a', 'goal') 1\n",
            "('a', 'goal', 'of') 1\n",
            "('goal', 'of', 'acquilex') 1\n",
            "('of', 'acquilex', 'is') 1\n",
            "('acquilex', 'is', 'to') 1\n",
            "('is', 'to', 'demonstrate') 1\n",
            "('to', 'demonstrate', 'that') 1\n",
            "('demonstrate', 'that', 'an') 1\n",
            "('that', 'an', 'lkb') 1\n",
            "('an', 'lkb', 'can') 1\n",
            "('lkb', 'can', 'be') 1\n",
            "('can', 'be', 'produced') 1\n",
            "('be', 'produced', 'that') 1\n",
            "('produced', 'that', 'usefully') 1\n",
            "('that', 'usefully', 'exploits') 1\n",
            "('usefully', 'exploits', 'various') 1\n",
            "('exploits', 'various', 'mrd') 1\n",
            "('various', 'mrd', 'sources') 1\n",
            "('mrd', 'sources', 'and') 1\n",
            "('sources', 'and', 'integrates') 1\n",
            "('and', 'integrates', 'multilingual') 1\n",
            "('integrates', 'multilingual', 'information') 1\n",
            "('multilingual', 'information', 'the') 1\n",
            "('information', 'the', 'use') 1\n",
            "('use', 'of', 'a') 1\n",
            "('of', 'a', 'common') 1\n",
            "('a', 'common', 'lrl') 1\n",
            "('common', 'lrl', 'with') 1\n",
            "('lrl', 'with', 'a') 1\n",
            "('with', 'a', 'common') 1\n",
            "('a', 'common', 'type') 1\n",
            "('common', 'type', 'system') 1\n",
            "('type', 'system', 'makes') 1\n",
            "('system', 'makes', 'it') 1\n",
            "('makes', 'it', 'possi') 1\n",
            "('it', 'possi', 'we') 1\n",
            "('possi', 'we', 'describe') 1\n",
            "('describe', 'the', 'design') 1\n",
            "('design', 'and', 'use') 1\n",
            "('use', 'of', 'the') 2\n",
            "('of', 'the', 'stanford') 1\n",
            "('the', 'stanford', 'corenlp') 1\n",
            "('stanford', 'corenlp', 'toolkit') 1\n",
            "('corenlp', 'toolkit', 'an') 1\n",
            "('toolkit', 'an', 'extensible') 1\n",
            "('an', 'extensible', 'pipeline') 1\n",
            "('extensible', 'pipeline', 'that') 1\n",
            "('pipeline', 'that', 'provides') 1\n",
            "('that', 'provides', 'core') 1\n",
            "('provides', 'core', 'natural') 1\n",
            "('core', 'natural', 'language') 1\n",
            "('natural', 'language', 'analysis') 1\n",
            "('language', 'analysis', 'this') 1\n",
            "('analysis', 'this', 'toolkit') 1\n",
            "('this', 'toolkit', 'is') 1\n",
            "('toolkit', 'is', 'quite') 1\n",
            "('is', 'quite', 'widely') 1\n",
            "('quite', 'widely', 'used') 1\n",
            "('widely', 'used', 'both') 1\n",
            "('used', 'both', 'in') 1\n",
            "('both', 'in', 'the') 1\n",
            "('in', 'the', 'research') 1\n",
            "('the', 'research', 'nlp') 1\n",
            "('research', 'nlp', 'community') 1\n",
            "('nlp', 'community', 'and') 1\n",
            "('community', 'and', 'also') 1\n",
            "('and', 'also', 'among') 1\n",
            "('also', 'among', 'commercial') 1\n",
            "('among', 'commercial', 'and') 1\n",
            "('commercial', 'and', 'government') 1\n",
            "('and', 'government', 'users') 1\n",
            "('government', 'users', 'of') 1\n",
            "('users', 'of', 'open') 1\n",
            "('of', 'open', 'source') 1\n",
            "('open', 'source', 'nlp') 1\n",
            "('source', 'nlp', 'technology') 1\n",
            "('nlp', 'technology', 'we') 1\n",
            "('technology', 'we', 'suggest') 1\n",
            "('we', 'suggest', 'gaussian') 1\n",
            "('suggest', 'gaussian', 'processes') 1\n",
            "('gaussian', 'processes', 'gps') 1\n",
            "('processes', 'gps', 'are') 1\n",
            "('gps', 'are', 'a') 1\n",
            "('are', 'a', 'powerful') 1\n",
            "('a', 'powerful', 'modelling') 1\n",
            "('powerful', 'modelling', 'framework') 1\n",
            "('modelling', 'framework', 'incorporating') 1\n",
            "('framework', 'incorporating', 'kernels') 1\n",
            "('incorporating', 'kernels', 'and') 1\n",
            "('kernels', 'and', 'bayesian') 1\n",
            "('and', 'bayesian', 'inference') 1\n",
            "('bayesian', 'inference', 'and') 1\n",
            "('inference', 'and', 'are') 1\n",
            "('and', 'are', 'recognised') 1\n",
            "('are', 'recognised', 'as') 1\n",
            "('recognised', 'as', 'stateoftheart') 1\n",
            "('as', 'stateoftheart', 'for') 1\n",
            "('stateoftheart', 'for', 'many') 1\n",
            "('for', 'many', 'machine') 1\n",
            "('many', 'machine', 'learning') 1\n",
            "('machine', 'learning', 'tasks') 1\n",
            "('learning', 'tasks', 'a') 1\n",
            "('tasks', 'a', 'fundamental') 1\n",
            "('a', 'fundamental', 'issue') 1\n",
            "('fundamental', 'issue', 'in') 1\n",
            "('issue', 'in', 'natural') 1\n",
            "('is', 'the', 'prerequisite') 1\n",
            "('the', 'prerequisite', 'of') 1\n",
            "('prerequisite', 'of', 'an') 1\n",
            "('of', 'an', 'enormous') 1\n",
            "('an', 'enormous', 'quantity') 1\n",
            "('enormous', 'quantity', 'of') 1\n",
            "('quantity', 'of', 'preprogrammed') 1\n",
            "('of', 'preprogrammed', 'knowledge') 1\n",
            "('preprogrammed', 'knowledge', 'concerning') 1\n",
            "('knowledge', 'concerning', 'both') 1\n",
            "('concerning', 'both', 'the') 1\n",
            "('both', 'the', 'language') 1\n",
            "('the', 'language', 'and') 1\n",
            "('and', 'the', 'domain') 1\n",
            "('the', 'domain', 'under') 1\n",
            "('domain', 'under', 'examination') 1\n",
            "('under', 'examination', 'manual') 1\n",
            "('examination', 'manual', 'acquisition') 1\n",
            "('manual', 'acquisition', 'of') 1\n",
            "('acquisition', 'of', 'this') 1\n",
            "('of', 'this', 'knowledge') 1\n",
            "('this', 'knowledge', 'is') 1\n",
            "('knowledge', 'is', 'tedious') 1\n",
            "('is', 'tedious', 'and') 1\n",
            "('tedious', 'and', 'error') 1\n",
            "('and', 'error', 'prone') 1\n",
            "('error', 'prone', 'development') 1\n",
            "('prone', 'development', 'of') 1\n",
            "('development', 'of', 'an') 1\n",
            "('of', 'an', 'automated') 1\n",
            "('an', 'automated', 'acquisition') 1\n",
            "('automated', 'acquisition', 'that') 1\n",
            "('acquisition', 'that', 'supports') 1\n",
            "('that', 'supports', 'sophisticated') 1\n",
            "('supports', 'sophisticated', 'natural') 1\n",
            "('sophisticated', 'natural', 'language') 1\n",
            "('language', 'processing', 'while') 1\n",
            "('processing', 'while', 'significantly') 1\n",
            "('while', 'significantly', 'simplifying') 1\n",
            "('significantly', 'simplifying', 'the') 1\n",
            "('simplifying', 'the', 'interface') 1\n",
            "('the', 'interface', 'between') 1\n",
            "('interface', 'between', 'domainspecific') 1\n",
            "('between', 'domainspecific', 'knowledge') 1\n",
            "('domainspecific', 'knowledge', 'and') 1\n",
            "('knowledge', 'and', 'general') 1\n",
            "('and', 'general', 'linguis') 1\n",
            "('general', 'linguis', 'tic') 1\n",
            "('linguis', 'tic', 'resources') 1\n",
            "('tic', 'resources', 'this') 1\n",
            "('resources', 'this', 'paper') 1\n",
            "('this', 'paper', 'presents') 2\n",
            "('paper', 'presents', 'the') 1\n",
            "('presents', 'the', 'results') 1\n",
            "('the', 'results', 'of') 1\n",
            "('results', 'of', 'our') 1\n",
            "('of', 'our', 'experiences') 1\n",
            "('our', 'experiences', 'in') 1\n",
            "('experiences', 'in', 'designing') 1\n",
            "('in', 'designing', 'and') 1\n",
            "('designing', 'and', 'using') 1\n",
            "('and', 'using', 'the') 1\n",
            "('using', 'the', 'upper') 1\n",
            "('the', 'upper', 'model') 1\n",
            "('upper', 'model', 'in') 1\n",
            "('model', 'in', 'a') 1\n",
            "('in', 'a', 'variety') 1\n",
            "('a', 'variety', 'of') 1\n",
            "('variety', 'of', 'applications') 1\n",
            "('of', 'applications', 'over') 1\n",
            "('applications', 'over', 'the') 1\n",
            "('over', 'the', 'past') 1\n",
            "('past', 'years', 'into') 1\n",
            "('years', 'into', 'the') 1\n",
            "('into', 'the', 'same') 1\n",
            "('the', 'same', 'or') 1\n",
            "('same', 'or', 'neighboring') 1\n",
            "('or', 'neighboring', 'map') 1\n",
            "('neighboring', 'map', 'nodes') 1\n",
            "('map', 'nodes', 'nodes') 1\n",
            "('nodes', 'nodes', 'may') 1\n",
            "('nodes', 'may', 'thus') 1\n",
            "('may', 'thus', 'be') 1\n",
            "('thus', 'be', 'viewed') 1\n",
            "('be', 'viewed', 'as') 1\n",
            "('viewed', 'as', 'word') 1\n",
            "('as', 'word', 'categories') 1\n",
            "('word', 'categories', 'although') 1\n",
            "('categories', 'although', 'no') 1\n",
            "('although', 'no', 'a') 1\n",
            "('no', 'a', 'priori') 1\n",
            "('a', 'priori', 'information') 1\n",
            "('priori', 'information', 'about') 1\n",
            "('information', 'about', 'classes') 1\n",
            "('about', 'classes', 'is') 1\n",
            "('classes', 'is', 'given') 1\n",
            "('is', 'given', 'during') 1\n",
            "('given', 'during', 'the') 1\n",
            "('during', 'the', 'selforganizing') 1\n",
            "('the', 'selforganizing', 'process') 1\n",
            "('selforganizing', 'process', 'a') 1\n",
            "('process', 'a', 'model') 1\n",
            "('a', 'model', 'of') 1\n",
            "('the', 'word', 'classes') 1\n",
            "('word', 'classes', 'emerges') 1\n",
            "('classes', 'emerges', 'the') 1\n",
            "('emerges', 'the', 'central') 1\n",
            "('the', 'central', 'topic') 1\n",
            "('central', 'topic', 'of') 1\n",
            "('topic', 'of', 'the') 1\n",
            "('of', 'the', 'thesis') 1\n",
            "('the', 'thesis', 'is') 1\n",
            "('thesis', 'is', 'the') 1\n",
            "('is', 'the', 'use') 1\n",
            "('of', 'the', 'som') 1\n",
            "('the', 'som', 'in') 1\n",
            "('som', 'in', 'natural') 1\n",
            "('processing', 'the', 'approach') 1\n",
            "('the', 'approach', 'this') 1\n",
            "('approach', 'this', 'paper') 1\n",
            "('paper', 'presents', 'a') 1\n",
            "('presents', 'a', 'workbench') 1\n",
            "('a', 'workbench', 'built') 1\n",
            "('workbench', 'built', 'by') 1\n",
            "('built', 'by', 'priberam') 1\n",
            "('by', 'priberam', 'informática') 1\n",
            "('priberam', 'informática', 'for') 1\n",
            "('informática', 'for', 'the') 1\n",
            "('for', 'the', 'development') 1\n",
            "('of', 'the', 'company') 1\n",
            "('the', 'company', '’') 1\n",
            "('company', '’', 's') 1\n",
            "('’', 's', 'natural') 1\n",
            "('s', 'natural', 'language') 1\n",
            "('language', 'processing', 'technology') 1\n",
            "('processing', 'technology', 'this') 1\n",
            "('technology', 'this', 'workbench') 1\n",
            "('this', 'workbench', 'includes') 1\n",
            "('workbench', 'includes', 'a') 1\n",
            "('includes', 'a', 'set') 1\n",
            "('a', 'set', 'of') 1\n",
            "('set', 'of', 'linguistic') 1\n",
            "('of', 'linguistic', 'resources') 1\n",
            "('linguistic', 'resources', 'and') 1\n",
            "('resources', 'and', 'software') 1\n",
            "('and', 'software', 'tools') 1\n",
            "('software', 'tools', 'that') 1\n",
            "('tools', 'that', 'have') 1\n",
            "('that', 'have', 'been') 1\n",
            "('have', 'been', 'applied') 1\n",
            "('been', 'applied', 'in') 1\n",
            "('applied', 'in', 'a') 1\n",
            "('in', 'a', 'considerable') 1\n",
            "('a', 'considerable', 'number') 1\n",
            "('considerable', 'number', 'of') 1\n",
            "('number', 'of', 'practical') 1\n",
            "('of', 'practical', 'purposes') 1\n",
            "('practical', 'purposes', 'covering') 1\n",
            "('purposes', 'covering', 'abstract—natural') 1\n",
            "('covering', 'abstract—natural', 'language') 1\n",
            "('nlp', 'is', 'an') 1\n",
            "('is', 'an', 'effective') 1\n",
            "('an', 'effective', 'approach') 1\n",
            "('effective', 'approach', 'for') 1\n",
            "('approach', 'for', 'bringing') 1\n",
            "('for', 'bringing', 'improvement') 1\n",
            "('bringing', 'improvement', 'in') 1\n",
            "('improvement', 'in', 'educational') 1\n",
            "('in', 'educational', 'setting') 1\n",
            "('educational', 'setting', 'implementing') 1\n",
            "('setting', 'implementing', 'nlp') 1\n",
            "('implementing', 'nlp', 'involves') 1\n",
            "('nlp', 'involves', 'initiating') 1\n",
            "('involves', 'initiating', 'the') 1\n",
            "('initiating', 'the', 'process') 1\n",
            "('process', 'of', 'learning') 1\n",
            "('of', 'learning', 'through') 1\n",
            "('learning', 'through', 'the') 1\n",
            "('through', 'the', 'natural') 1\n",
            "('the', 'natural', 'acquisition') 1\n",
            "('natural', 'acquisition', 'in') 1\n",
            "('acquisition', 'in', 'the') 1\n",
            "('in', 'the', 'educational') 1\n",
            "('the', 'educational', 'systems') 1\n",
            "('educational', 'systems', 'it') 1\n",
            "('systems', 'it', 'is') 1\n",
            "('it', 'is', 'based') 1\n",
            "('is', 'based', 'on') 1\n",
            "('based', 'on', 'effective') 1\n",
            "('on', 'effective', 'approaches') 1\n",
            "('effective', 'approaches', 'for') 1\n",
            "('approaches', 'for', 'providing') 1\n",
            "('for', 'providing', 'a') 1\n",
            "('providing', 'a', 'solution') 1\n",
            "('a', 'solution', 'abstract') 1\n",
            "('solution', 'abstract', 'after') 1\n",
            "('abstract', 'after', 'twenty') 1\n",
            "('after', 'twenty', 'years') 1\n",
            "('twenty', 'years', 'of') 1\n",
            "('years', 'of', 'disfavor') 1\n",
            "('of', 'disfavor', 'a') 1\n",
            "('disfavor', 'a', 'technology') 1\n",
            "('a', 'technology', 'has') 1\n",
            "('technology', 'has', 'returned') 1\n",
            "('has', 'returned', 'which') 1\n",
            "('returned', 'which', 'imitates') 1\n",
            "('which', 'imitates', 'the') 1\n",
            "('imitates', 'the', 'processes') 1\n",
            "('the', 'processes', 'of') 1\n",
            "('processes', 'of', 'the') 1\n",
            "('of', 'the', 'brain') 1\n",
            "('the', 'brain', 'natural') 1\n",
            "('brain', 'natural', 'language') 1\n",
            "('natural', 'language', 'experiments') 1\n",
            "('language', 'experiments', 'sejnowski') 1\n",
            "('experiments', 'sejnowski', 'rosenberg') 1\n",
            "('sejnowski', 'rosenberg', 'demonstrate') 1\n",
            "('rosenberg', 'demonstrate', 'that') 1\n",
            "('demonstrate', 'that', 'neural') 1\n",
            "('that', 'neural', 'network') 1\n",
            "('neural', 'network', 'computing') 1\n",
            "('network', 'computing', 'architecture') 1\n",
            "('computing', 'architecture', 'can') 1\n",
            "('architecture', 'can', 'learn') 1\n",
            "('can', 'learn', 'from') 1\n",
            "('learn', 'from', 'actual') 1\n",
            "('from', 'actual', 'spoken') 1\n",
            "('actual', 'spoken', 'language') 1\n",
            "('spoken', 'language', 'observe') 1\n",
            "('language', 'observe', 'rules') 1\n",
            "('observe', 'rules', 'of') 1\n",
            "('rules', 'of', 'pronunciation') 1\n",
            "('of', 'pronunciation', 'text') 1\n",
            "('pronunciation', 'text', 'statistics') 1\n",
            "('text', 'statistics', 'are') 1\n",
            "('statistics', 'are', 'frequently') 1\n",
            "('are', 'frequently', 'used') 1\n",
            "('frequently', 'used', 'in') 1\n",
            "('used', 'in', 'stylometry') 1\n",
            "('in', 'stylometry', 'and') 1\n",
            "('stylometry', 'and', 'cryptography') 1\n",
            "('and', 'cryptography', 'studies') 1\n",
            "('cryptography', 'studies', 'in') 1\n",
            "('studies', 'in', 'this') 1\n",
            "('this', 'paper', 'some') 1\n",
            "('paper', 'some', 'text') 1\n",
            "('some', 'text', 'statistics') 1\n",
            "('text', 'statistics', 'tools') 1\n",
            "('statistics', 'tools', 'are') 1\n",
            "('tools', 'are', 'developed') 1\n",
            "('are', 'developed', 'in') 1\n",
            "('developed', 'in', 'iso') 1\n",
            "('in', 'iso', 'prolog') 1\n",
            "('iso', 'prolog', 'for') 1\n",
            "('prolog', 'for', 'natural') 1\n",
            "('language', 'processing', 'details') 1\n",
            "('processing', 'details', 'are') 1\n",
            "('details', 'are', 'given') 1\n",
            "('are', 'given', 'on') 1\n",
            "('given', 'on', 'the') 1\n",
            "('on', 'the', 'usage') 1\n",
            "('the', 'usage', 'of') 1\n",
            "('usage', 'of', 'usercallable') 1\n",
            "('of', 'usercallable', 'predicates') 1\n",
            "('usercallable', 'predicates', 'logic') 1\n",
            "('predicates', 'logic', 'and') 1\n",
            "('logic', 'and', 'limitations') 1\n",
            "('and', 'limitations', 'of') 1\n",
            "('limitations', 'of', 'the') 1\n",
            "('of', 'the', 'program') 1\n",
            "('the', 'program', 'are') 1\n",
            "('program', 'are', 'also') 1\n",
            "('are', 'also', 'discussed') 1\n",
            "('also', 'discussed', 'we') 1\n",
            "('discussed', 'we', 'summarize') 1\n",
            "('we', 'summarize', 'our') 1\n",
            "('summarize', 'our', 'experience') 1\n",
            "('our', 'experience', 'using') 1\n",
            "('experience', 'using', 'framenet') 1\n",
            "('using', 'framenet', 'in') 1\n",
            "('framenet', 'in', 'two') 1\n",
            "('in', 'two', 'rather') 1\n",
            "('two', 'rather', 'different') 1\n",
            "('rather', 'different', 'projects') 1\n",
            "('different', 'projects', 'in') 1\n",
            "('projects', 'in', 'natural') 1\n",
            "('processing', 'nlp', 'we') 1\n",
            "('nlp', 'we', 'conclude') 1\n",
            "('we', 'conclude', 'that') 1\n",
            "('conclude', 'that', 'nlp') 1\n",
            "('that', 'nlp', 'can') 1\n",
            "('nlp', 'can', 'benefit') 1\n",
            "('can', 'benefit', 'from') 1\n",
            "('benefit', 'from', 'framenet') 1\n",
            "('from', 'framenet', 'in') 1\n",
            "('framenet', 'in', 'different') 1\n",
            "('in', 'different', 'ways') 1\n",
            "('different', 'ways', 'but') 1\n",
            "('ways', 'but', 'we') 1\n",
            "('but', 'we', 'sketch') 1\n",
            "('we', 'sketch', 'some') 1\n",
            "('sketch', 'some', 'problems') 1\n",
            "('some', 'problems', 'that') 1\n",
            "('problems', 'that', 'need') 1\n",
            "('that', 'need', 'to') 1\n",
            "('need', 'to', 'be') 1\n",
            "('to', 'be', 'overcome') 1\n",
            "('be', 'overcome', 'research') 1\n",
            "('overcome', 'research', 'in') 1\n",
            "('research', 'in', 'natural') 1\n",
            "('processing', 'nlp', 'has') 1\n",
            "('nlp', 'has', 'in') 1\n",
            "('has', 'in', 'recent') 1\n",
            "('recent', 'years', 'benefited') 1\n",
            "('years', 'benefited', 'from') 1\n",
            "('benefited', 'from', 'the') 1\n",
            "('from', 'the', 'enormous') 1\n",
            "('the', 'enormous', 'amount') 1\n",
            "('enormous', 'amount', 'of') 1\n",
            "('amount', 'of', 'raw') 1\n",
            "('of', 'raw', 'textual') 1\n",
            "('raw', 'textual', 'data') 1\n",
            "('textual', 'data', 'available') 1\n",
            "('data', 'available', 'on') 1\n",
            "('available', 'on', 'the') 1\n",
            "('on', 'the', 'world') 1\n",
            "('the', 'world', 'wide') 1\n",
            "('world', 'wide', 'web') 1\n",
            "('wide', 'web', 'the') 1\n",
            "('web', 'the', 'presence') 1\n",
            "('the', 'presence', 'of') 1\n",
            "('presence', 'of', 'standard') 1\n",
            "('of', 'standard', 'search') 1\n",
            "('standard', 'search', 'engines') 1\n",
            "('search', 'engines', 'has') 1\n",
            "('engines', 'has', 'made') 1\n",
            "('has', 'made', 'this') 1\n",
            "('made', 'this', 'data') 1\n",
            "('this', 'data', 'accessible') 1\n",
            "('data', 'accessible', 'to') 1\n",
            "('accessible', 'to', 'computational') 1\n",
            "('to', 'computational', 'linguists') 1\n",
            "('computational', 'linguists', 'as') 1\n",
            "('linguists', 'as', 'a') 1\n",
            "('as', 'a', 'corpus') 1\n",
            "('a', 'corpus', 'of') 1\n",
            "('corpus', 'of', 'a') 1\n",
            "('of', 'a', 'size') 1\n",
            "('a', 'size', 'that') 1\n",
            "('size', 'that', 'had') 1\n",
            "('that', 'had', 'never') 1\n",
            "('had', 'never', 'existed') 1\n",
            "('never', 'existed', 'natural') 1\n",
            "('existed', 'natural', 'language') 1\n",
            "('processing', 'nlp', 'programs') 1\n",
            "('nlp', 'programs', 'are') 1\n",
            "('programs', 'are', 'confronted') 1\n",
            "('are', 'confronted', 'with') 1\n",
            "('confronted', 'with', 'various') 1\n",
            "('with', 'various', 'diculties') 1\n",
            "('various', 'diculties', 'in') 1\n",
            "('diculties', 'in', 'processing') 1\n",
            "('in', 'processing', 'html') 1\n",
            "('processing', 'html', 'and') 1\n",
            "('html', 'and', 'xml') 1\n",
            "('and', 'xml', 'documents') 1\n",
            "('xml', 'documents', 'and') 1\n",
            "('documents', 'and', 'have') 1\n",
            "('and', 'have', 'the') 1\n",
            "('have', 'the', 'potential') 1\n",
            "('the', 'potential', 'to') 1\n",
            "('potential', 'to', 'produce') 1\n",
            "('to', 'produce', 'better') 1\n",
            "('produce', 'better', 'results') 1\n",
            "('better', 'results', 'if') 1\n",
            "('results', 'if', 'linguistic') 1\n",
            "('if', 'linguistic', 'information') 1\n",
            "('linguistic', 'information', 'is') 1\n",
            "('information', 'is', 'annotated') 1\n",
            "('is', 'annotated', 'in') 1\n",
            "('annotated', 'in', 'the') 1\n",
            "('in', 'the', 'source') 1\n",
            "('the', 'source', 'texts') 1\n",
            "('source', 'texts', 'wehave') 1\n",
            "('texts', 'wehave', 'therefore') 1\n",
            "('wehave', 'therefore', 'developed') 1\n",
            "('therefore', 'developed', 'the') 1\n",
            "('developed', 'the', 'linguistic') 1\n",
            "('the', 'linguistic', 'annotation') 1\n",
            "('linguistic', 'annotation', 'language') 1\n",
            "('annotation', 'language', 'or') 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "aYK5WSKzr3XU",
        "outputId": "c2cc95d2-31f0-49f5-a923-50e6ee4ca4b7"
      },
      "source": [
        "from nltk import bigrams\n",
        "def probability(bigrams, tokens):\n",
        "    return [t / tokens.count(b[0]) for b, t in bigrams.items()]\n",
        "count_probability = probability(bigrams, tokens)\n",
        "_ = [print(b, frequency) for b, frequency in zip(bigrams, probability(bigrams, tokens))] \n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-3fa4690e0630>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprobability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbigrams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbigrams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcount_probability\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbigrams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrequency\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrequency\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbigrams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbigrams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-3fa4690e0630>\u001b[0m in \u001b[0;36mprobability\u001b[0;34m(bigrams, tokens)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbigrams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprobability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbigrams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbigrams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mcount_probability\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbigrams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrequency\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrequency\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbigrams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbigrams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'items'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2KHnzfYr9ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "997cb272-bad7-4648-e24f-9bb9c167d551"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "for col in df_clean.Paper.values:\n",
        "    text1 = nlp(col)\n",
        "    for chunk in text1.noun_chunks:\n",
        "        freq = col.count(chunk.text)\n",
        "        freq_text = df1.count(chunk.text)\n",
        "        df_clean[chunk.text] = freq / freq_text\n",
        "\n",
        "\n",
        "df1 = df_clean.copy()\n",
        "df1.set_index('Paper')\n",
        "df1.to_csv(\"papers.csv\", index = False)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_axis_number\u001b[0;34m(cls, axis)\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_AXIS_TO_AXIS_NUMBER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'text'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-d32f7654e9d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoun_chunks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mfreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mfreq_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mdf_clean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfreq\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfreq_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mcount\u001b[0;34m(self, axis, level, numeric_only)\u001b[0m\n\u001b[1;32m   8457\u001b[0m         \u001b[0mMyla\u001b[0m      \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8458\u001b[0m         \"\"\"\n\u001b[0;32m-> 8459\u001b[0;31m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8460\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlevel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8461\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_axis_number\u001b[0;34m(cls, axis)\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_AXIS_TO_AXIS_NUMBER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"No axis named {axis} for object type {cls.__name__}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: No axis named text for object type DataFrame"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfpMRCrRwN6Z"
      },
      "source": [
        "# **Question 2: Undersand TF-IDF and Document representation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dCQEbDawWCw"
      },
      "source": [
        "(40 points). Starting from the documents (all the reviews, or abstracts, or tweets) collected for assignment two, write a python program: \n",
        "\n",
        "(1) To build the **documents-terms weights (tf*idf) matrix bold text**.\n",
        "\n",
        "(2) To rank the documents with respect to query (design a query by yourself, for example, \"An Outstanding movie with a haunting performance and best character development\") by using **cosine similarity**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vATjQNTY8buA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2ec91a5-891b-46a5-94a0-3b036c9946a0"
      },
      "source": [
        "# Write your code here\n",
        "\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vector = TfidfVectorizer()\n",
        "matrix= vector.fit_transform(list(df_clean.Paper.values))\n",
        "df_matrix = pd.DataFrame.sparse.from_spmatrix(matrix, columns=vector.get_feature_names())\n",
        "\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "tfidf = linear_kernel(matrix[0:1], matrix).flatten()\n",
        "tfidf\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.        , 0.0468433 , 0.08998481, 0.08726796, 0.1126589 ,\n",
              "       0.10233224, 0.08855167, 0.11719437, 0.07280293, 0.09736383,\n",
              "       0.05121015, 0.09651412, 0.06527775, 0.12564205, 0.11756968,\n",
              "       0.06317574, 0.13463875, 0.07578596, 0.11983939, 0.09810907,\n",
              "       0.05447036, 0.14871547, 0.11240544, 0.        , 0.09079781,\n",
              "       0.        , 0.05964402, 0.10505037, 0.10270881, 0.11567604,\n",
              "       0.05485572, 0.        , 0.11832352, 0.        , 0.        ,\n",
              "       0.        , 0.05193721, 0.12057716, 0.10151219, 0.13235691,\n",
              "       0.06892273, 0.05215826, 0.0826149 , 0.03728351, 0.11069124,\n",
              "       0.07594907, 0.1801941 , 0.04447667, 0.11317364, 0.15095509,\n",
              "       0.15095509, 0.13980333, 0.04463059, 0.12577786, 0.07764598,\n",
              "       0.08836441, 0.19381133, 0.09075348, 0.08065769, 0.06020886,\n",
              "       0.0649523 , 0.        , 0.03589961, 0.07830155, 0.03942137,\n",
              "       0.10333215, 0.        , 0.09741263, 0.04268247, 0.        ,\n",
              "       0.12860936, 0.0724356 , 0.08091416, 0.04251841, 0.19596402,\n",
              "       0.06946292, 0.11881095, 0.03590942, 0.10145841, 0.10531041,\n",
              "       0.03498716, 0.12923231, 0.12021869, 0.07847178, 0.10005043,\n",
              "       0.09227849, 0.04465957, 0.14771703, 0.04225748, 0.12065689,\n",
              "       0.10159162])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-VAcNXBsK4I",
        "outputId": "b1462141-f254-4408-ba47-b2c4f0012c37"
      },
      "source": [
        "index = tfidf.argsort()[::-1]\n",
        "index"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0, 74, 56, 46, 50, 49, 21, 87, 51, 16, 39, 81, 70, 53, 13, 89, 37,\n",
              "       82, 18, 76, 32, 14,  7, 29, 48,  4, 22, 44, 79, 27, 65, 28,  5, 90,\n",
              "       38, 78, 84, 19, 67,  9, 11, 85, 24, 57,  2,  6, 55,  3, 42, 72, 58,\n",
              "       83, 63, 54, 45, 17,  8, 71, 75, 40, 12, 60, 15, 59, 26, 30, 20, 41,\n",
              "       36, 10,  1, 86, 52, 47, 68, 73, 88, 64, 43, 77, 62, 80, 23, 61, 35,\n",
              "       31, 66, 34, 33, 69, 25])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzUoFSm6sPWI",
        "outputId": "1469a3cd-f079-42bb-a2ae-8e77fa6fe561"
      },
      "source": [
        "print('-'*80, end='\\n\\n')\n",
        "for similarity in df_clean.Paper.values[index[1:]]:\n",
        "    print(similarity, end='\\n\\n')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "\n",
            "this chapter examines the application of natural language processing to computerassisted language learning including the history of work in this field over the last thirtyfive years but with a focus on current developments and opportunities  introduction this chapter focuses on applications \n",
            "\n",
            "this chapter examines the application of natural language processing to computerassisted language learning including the history of work in this field over the last thirtyfive years but with a focus on current developments and opportunities  \n",
            "\n",
            "in this paper we describe a framework for developing probabilistic classifiers in natural language processing our focus is on formulating models that capture the most important interdependencies among features to avoid overfitting the data while also characterizing the data well the class \n",
            "\n",
            "in the state of the art plan recognition systems this paper will outline the relations between natural language processingnlp and plan recognitionpr argue that each of them can effectively inform the other and then focus on key recent research results in nlp and argue for their applicability to pr  \n",
            "\n",
            "in the state of the art plan recognition systems this paper will outline the relations between natural language processingnlp and plan recognitionpr argue that each of them can effectively inform the other and then focus on key recent research results in nlp and argue for their applicability to pr  \n",
            "\n",
            "the voice recognition for a natural language tamil by combining the digital and mathematical knowledge using mfcc and dtw to extract and match the features to improve the accuracy for better performance \n",
            "\n",
            "text statistics are frequently used in stylometry and cryptography studies in this paper some text statistics tools are developed in iso prolog for natural language processing details are given on the usage of  usercallable predicates logic and limitations of the program are also discussed \n",
            "\n",
            "information retrieval is the process of finding the documents in a document collection that satisfies the information need of the user the documents are natural language constructs and the motivation of this work is to investigate how natural language processing can be used to improve \n",
            "\n",
            " sounds text and motion the techniques developed from deep learning research have already been impacting the research of natural language process this paper reviews the recent research on deep learning its applications and recent development in natural language processing  \n",
            "\n",
            "in this chapter the basic uses of description logics for natural language processing will be analysed together with a little bit of history and the role of description logics in the current state of the art in computational linguistics will be pointed out  introduction since the early days \n",
            "\n",
            " a fundamental issue in natural language processing is the prerequisite of an enormous quantity of preprogrammed knowledge concerning both the language and the domain under examination manual acquisition of this knowledge is tedious and error prone development of an automated acquisition \n",
            "\n",
            "abstract natural language processing is the study of mathematical and computational modelling of various aspects of language and the improvement of a wide range of systems natural language is any language that arises as an innate facility for language possessed by the human intellect it may \n",
            "\n",
            "what is a statistical method and how can it be used in natural language processing nlp in this paper we start from a definition of nlp as concerned with the design and implementation of effective natural language input and output components for computational systems we distinguish three \n",
            "\n",
            "this paper reviews the processes involved in natural language processing nlp it then demonstrates the various kinds of choices that need be taken during the execution of the word morphology the syntactic text analysis or text generation components it compares the time complexity \n",
            "\n",
            "research in natural language processing nlp has in recent years benefited from the enormous amount of raw textual data available on the world wide web the presence of standard search engines has made this data accessible to computational linguists as a corpus of a size that had never existed \n",
            "\n",
            "this chapter considers the revolution that has taken place in natural language processing research over the last five years it begins by providing a brief guide to the structure of the field and then presents a caricature of two competing paradigms of  nlp research and indicates the reasons \n",
            "\n",
            " that supports sophisticated natural language processing while significantly simplifying the interface between domainspecific knowledge and general linguis tic resources this paper presents the results of our experiences in designing and using the upper model in a variety of applications over the past  years \n",
            "\n",
            "abstract—natural language processing nlp is the application of automated parsing and machine learning techniques to analyze standard text applications of nlp to requirements engineering include extraction of ontologies from a requirements specification and use of nlp to verify the consistency \n",
            "\n",
            "we classify and review current approaches to software infrastructure for research development and delivery of nlp systems the task \n",
            "\n",
            "proceedings of the workshop on \n",
            "\n",
            "this article focusses on the derivation of large lexicons for natural language processing we describe the development of a dictionary support environment linking a restructured version of the longman dictionary of contemporary english to natural language processing systems the process \n",
            "\n",
            "objectives to provide an overview and tutorial of natural language processing nlp and modern nlpsystem design target audience this tutorial targets the medical informatics generalist who has limited acquaintance with the principles behind nlp andor limited knowledge of the current state \n",
            "\n",
            "abstract many information retrievalir systems retrieve relevant documents based on exact matching of keywords between a query and documents this method degrades precision rate in order to solve the problem we collected semantically related words and assigned semantic relationships used in general thesaurus and a special relationship called keyfact termft manually in addition to the semantic knowledge we automatically constructed statistic knowledge based on the concept of mutual information keyfact is an extended concept of keyword represented by noun and compound noun keyfact can be a verb and an adjective including subject or object term we first retrieved relevant documents with original query using tf  idf weighting formula and then an expanded query including keyfacts is used in both second document ranking and word sense disambiguating so we made an improvement in precision rate using keyfact network  \n",
            "\n",
            "abstract this paper explains the information retrieval using natural language processing for malayalam language in these basic \n",
            "\n",
            "this paper focuses on connectionist models in natural language processing we briefly present and discuss several aspects of high level tasks which recently have been approached with connectionism either with localist or parallel distributed processing models several interesting architectures \n",
            "\n",
            "abstract testing against natural language requirements is the standard approach for system and acceptance testing this test is often performed by an independent test organization unfamiliar with the application area the only things the testers have to go by are the written requirements so \n",
            "\n",
            "of kernelized sorting to increase its robustness and performance on several natural language processing nlp tasks document matching from parallel and comparable corpora machine transliteration and even image processing empirically we show that on these tasks a semisupervised variant of kernelized \n",
            "\n",
            "we describe the design and use of the stanford corenlp toolkit an extensible pipeline that provides core natural language analysis this toolkit is quite widely used both in the research nlp community and also among commercial and government users of open source nlp technology we suggest \n",
            "\n",
            "we argue that manual and automatic thesauruses are alternative resources for the same nlp tasks this involves the radical step of interpreting manual thesauruses as classifications of words rather than word senses the case for this is made the range of roles for thesauruses within nlp is briefly presented and the wasps thesaurus is introduced thesaurus evaluation is now becoming urgent a range of evaluation strategies all embedded within nlp tasks is proposed \n",
            "\n",
            "we developed a prototype information retrieval system which uses advanced natural language processing techniques to enhance the effectiveness of traditional keyword based document retrieval the backbone of our system is a statistical retrieval engine which performs automated indexing \n",
            "\n",
            "introduction patterns in music have been the object of intensive studies in the past years one of the purposes of analyzing musical structure and form is to discover the patterns that are explicit or implicit in musical works simon  patterns comprise periodicity make use of alphabets can be compound made up of subpatterns and possess phrase structure with various forms of punctuation traditionally composers have employed pattern propagation intuitively but algorithmic composition techniques allow the pattern propagation to be formalized albeit a high level during composition all the musical patterns evolve according to the rules and constraints specied at the design stage in jazz improvisation the musician invents a solo guided by a progression of chords the changes one approach  to learn improvising is to memorize patterns short chunks of music that t subprogressions and to concatenate them to form a whole solo that ts a whole progression one \n",
            "\n",
            "process of language understanding this is a new approach in natural language processing based on the deterministic chaotic behavior of dynamical systems  \n",
            "\n",
            "natural language processing nlp programs are confronted with various diculties in processing html and xml documents and have the potential to produce better results if linguistic information is annotated in the source texts wehave therefore developed the linguistic annotation language or \n",
            "\n",
            "visual development environment to support the visual assembly execution and analysis of modular natural language processing systems the visual model is an executable data flow program graph automatically synthesised from data dependency declarations of language processing modules the graph \n",
            "\n",
            " lexsign senseid  senseid dictionary   ldoce  lexsign senseid  senseid ldbentryno     lexsign senseid  senseid senseno    when loaded into the lkb  will be expanded into a fullyfledged representation for the transitive use of experience by integrating wordspecific information provided by  with the information encoded by the lkb type stricttranssign thus although neither ldoce llce or the earlier subcategorised lexicon contain all the information about psychological verbs defined in sanfilippoaposs type system by using the conjunction of information available from all three it proved possible to effectively enrich this information at the same time as mapping it into a formal representation  towards a multilingual lkb a goal of acquilex is to demonstrate that an lkb can be produced that usefully exploits various mrd sources and integrates multilingual information the use of a common lrl with a common type system makes it possi \n",
            "\n",
            "this paper presents a workbench built by priberam informática for the development of the company’s natural language processing technology this workbench includes a set of linguistic resources and software tools that have been applied in a considerable number of practical purposes covering \n",
            "\n",
            "statistical baseline including the forgiving nature but broad coverage of the typical retrieval task the lack of good weighting schemes for compound index terms and the implicit linguistic processing inherent in the statistical methods natural language processing techniques may be more important \n",
            "\n",
            "in this paper we will discuss several issues and requirements for enabling natural language processing systems to become contextadaptive given the fact that emerging systems feature speaker independent continuous speech recognition restricted to individual domains and are equipped with syntactic \n",
            "\n",
            "based and literature resources we describe here a system for agent directed natural language processing to extract information from journal articles an interface was developed to permit curation of the nlp results and deposition of accepted results into a knowledge base motivation the advent of high \n",
            "\n",
            "similar to the way humans intuitively do in order to eliminate noisy content in this paper we describe a combination of html dom analysis and natural language processing nlp techniques for automated extractions of main article with associated images from web pages \n",
            "\n",
            "abstract—natural language processing nlp is an effective approach for bringing improvement in educational setting implementing nlp involves initiating the process of learning through the natural acquisition in the educational systems it is based on effective approaches for providing a solution \n",
            "\n",
            "conversational partners but it also provides us with information about being creative making associations storytelling and language use many more subtleties in facetoface and multiparty interaction can be added such as using humor to persuade and dominate to soften or avoid a face threatening act \n",
            "\n",
            "traditional approaches tointerpretation in natural language processing typically fall into one of three classes syntaxdriven semanticsdriven or frametask based syntaxdriven approaches use a domainindependent grammar to drive the interpretation process and produce a global parse \n",
            "\n",
            "we report experiments on the use of standard natural language processing nlp tools for the analysis of music lyrics a significant amount of music audio has lyrics lyrics encode an important part of the semantics of a song therefore their analysis complements that of acoustic and cultural \n",
            "\n",
            "this paper see  for a theoretical discussion and  and  for brief discussions of a program built around these principles the goal here is simply to point out how our interest in natural language processing has led us naturally and indeed inevitably \n",
            "\n",
            "abstract this thesis examines the use of machine learning techniques in various tasks of natural language processing mainly for the task of information extraction from texts the objectives are the improvement of adaptability of information extraction systems to new thematic domains or even \n",
            "\n",
            "this paper we will describe a simple rulebased approach to automated learning of linguistic knowledge this approach has been shown for a number of tasks to capture information in a clearer and more direct fashion without a compromise in performance we present a detailed case study of this learning method applied to part of speech tagging \n",
            "\n",
            "over the last few years a number of areas of natural language processing have begun applying graphbased techniques these include among others text summarization syntactic parsing word sense disambiguation ontology construction sentiment and subjectivity analysis text clustering \n",
            "\n",
            "an evaluation of lolita and related natural language processing systems paul callaghan submitted to the university of durham for the degree of phd august   this research addresses the question how do we evaluate systems like lolita lolita is the natural \n",
            "\n",
            "natural language processing nlp is a very large and diverse subtopic of artificial intelligence as a result nlp itself has many subtopics including optical character recognition text to speech translators foreign language reading and writing aids machine translation and speech recognition \n",
            "\n",
            "into the same or neighboring map nodes nodes may thus be viewed as word categories although no a priori information about classes is given during the selforganizing process a model of the word classes emerges the central topic of the thesis is the use of the som in natural language processing the approach \n",
            "\n",
            "facts forms a link between ie a recent development in natural language processing and logic programming with prolog  \n",
            "\n",
            "in this report some collaborative work between the fields of machine learning ml and natural language processing nlp is presented the document is structured in two parts the first part includes a superficial but comprehensive survey covering the stateoftheart of machine learning \n",
            "\n",
            "will be structured in the words of statistical natural language processing we need a sophisticated statistical model of the basic elements such as words or phrases to be combined with the structural modeling such as syntactic parsing or dependency analysis since the basic property of these elements \n",
            "\n",
            "this is an authorproduced version of a paper published in the \n",
            "\n",
            "this paper briefly describes the current implementation status of an intelligent information retrieval system marie that employs natural language processing techniques descriptive captions are used to iden tify photographic images concerning various military projects the captions are parsed \n",
            "\n",
            "natural language processing nlp which is a branch of artificial intelligence includes speech synthesis speech recognition and machine translation natural language processing has a wide range of applications in the indian context most of the rural indian community is unable to make use \n",
            "\n",
            "this paper describes a natural language system which improves its own performance through learning the system processes short english narratives and is able to acquire from a single narrative a new schema for a stereotypical set of actions during the understanding process the system attempts \n",
            "\n",
            "we applied a structure learning model maxmargin structure mms to natural language processing nlp tasks where the aim is to capture the latent relationships within the output language domain we formulate this model as an extension of multi–class support vector machine svm and present a \n",
            "\n",
            "abstract natural language processing is a theoretically motivated range of computational techniques for analysing and representing naturally occurring texts at one or more levels of linguistic analysis for the purpose of achieving humanlike language processing for a range of tasks \n",
            "\n",
            "abstract in this special issue of tal we look at the fundamental principles underlying evaluation in natural language processing we adopt a global point of view that goes beyond the horizon of a single evaluation campaign or a particular protocol after a brief review of history and terminology \n",
            "\n",
            "we introduce a method for analyzing the complexity of natural language processing tasks and for predicting the difficulty new nlp tasks our complexity measures are derived from the kolmogorov complexity of a class of automata — meaning automata whose purpose is to extract relevant pieces \n",
            "\n",
            "probabilistic finitestate string transducers fsts are extremely popular in natural language processing due to powerful generic methods for applying composing and learning them unfortunately fsts are not a good fit for much of the current work on probabilistic modeling for machine \n",
            "\n",
            "in recent years machine learning ml has been used more and more to solve complex tasks in different disciplines ranging from data mining to information \n",
            "\n",
            "this paper we argue that questionanswering qa over technical domains is distinctly different from trecbased qa or webbased qa and it cannot benefit lom dataintensive approaches \n",
            "\n",
            "work in computational linguistics began very soon after the development of the first computers booth brandwood and cleave  yet in the intervening four decades there has been a pervasive feeling that progress in computer understanding of natural language has not been commensurate \n",
            "\n",
            "mation infrastructure digital libraries networked services digital convergence or intelligent agents this attention is moving natural language processing along the critical path for all kinds of novel applications this article will mention a number of successful applications of natural language processing nlp \n",
            "\n",
            "sri has developed a new architecture for integrating speech and naturallanguage processing that applies linguistic constraints during recognition by incrementally expanding the statetransition network embodied in a unification grammar we compare this dynamicgralnlnarnetwork dgn approach \n",
            "\n",
            "to evaluation in speech processing part  surveys significant evaluation work done so far for instance in machine translation and discusses the particular problems of generic system evaluation the conclusion is that evaluation strategies and techniques for nlp need much more development in particular \n",
            "\n",
            "abstract language is way of communicating your words language helps in understanding the worldwe get a better insight of the world language helps speakers to be as vague or as precise as they like nlp stands for natural language processing natural languages are those languages that are spoken \n",
            "\n",
            "abstract after twenty years of disfavor a technology has returned which imitates the processes of the brain natural language experiments sejnowski  rosenberg  demonstrate that neural network computing architecture can learn from actual spoken language observe rules of pronunciation \n",
            "\n",
            "of logic programming within both natural language research and machine learning we point out opportunities for induction of linguistic knowledge within logic programming keywords inductive logic programming natural language processing logic programming machine learning  introduction there is a \n",
            "\n",
            "many natural language processing nlp techniques have been used in information retrieval the results are not encouraging simple methods stopwording porterstyle stemming etc usually yield significant improvements while higherlevel processing chunking parsing word sense disambiguation \n",
            "\n",
            "in fall  i introduced a new course called applied natural language processing in which students acquire an understanding of which text analysis techniques are currently feasible for practical applications \n",
            "\n",
            "previous work demonstrated that web counts can be used to approximate bigram counts suggesting that webbased frequencies should be useful for a wide variety of natural language processing nlp tasks however only a limited number of tasks have so far been tested using webscale data sets \n",
            "\n",
            "we summarize our experience using framenet in two rather different projects in natural language processing nlp we conclude that nlp can benefit from framenet in different ways but we sketch some problems that need to be overcome  \n",
            "\n",
            "we describe a single convolutional neural network architecture that given a sentence outputs a host of language processing predictions partofspeech tags chunks named entity tags semantic roles semantically similar words and the likelihood that the sentence makes sense grammatically \n",
            "\n",
            "in natural language processing nlp research results from software engineering and software technology have often been neglected \n",
            "\n",
            "confidence measures are a practical solution for improving the usefulness of natural language processing applications confidence estimation is a generic machine learning approach for deriving confidence measures we give an overview of the application of confidence estimation in various fields \n",
            "\n",
            "natural language processing systems nlp that extract clinical information from textual reports were shown to be effective for limited domains and for particular applications because an nlp system typically requires substantial resources to develop it is beneficial if it is designed to be easily \n",
            "\n",
            "gaussian processes gps are a powerful modelling framework incorporating kernels and bayesian inference and are recognised as stateoftheart for many machine learning tasks \n",
            "\n",
            "abstract not found \n",
            "\n",
            "abstract not found \n",
            "\n",
            "abstract not found \n",
            "\n",
            "universitquotat des saarlandes \n",
            "\n",
            "abstract not found \n",
            "\n",
            "abstract not found \n",
            "\n",
            "unihamburgde \n",
            "\n",
            "abstract not found \n",
            "\n",
            "abstract not found \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5mmYIfN8eYV"
      },
      "source": [
        "# **Question 3: Create your own training and evaluation data for sentiment analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsi2y4z88ngX"
      },
      "source": [
        "(15 points). **You dodn't need to write program for this question!** Read each review (abstract or tweet) you collected in detail, and annotate each review with a sentiment (positive, negative, or neutral). Save the annotated dataset into a csv file with three columns (first column: document_id, clean_text, sentiment), upload the csv file to GitHub and submit the file link blew. This datset will be used for assignment four: sentiment analysis and text classification. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfvMKJjIXS5G"
      },
      "source": [
        "# The GitHub link of your final csv file\n",
        "\n",
        "# Link: https://github.com/prudhvijiddigam/Computational-Methods/blob/main/sentimental_analysis.csv"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}