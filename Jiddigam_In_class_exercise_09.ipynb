{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Jiddigam_In_class_exercise_09.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prudhvijiddigam/Computational-Methods/blob/main/Jiddigam_In_class_exercise_09.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQ3ZNp7hO_QI"
      },
      "source": [
        "# **The ninth in-class-exercise (20 points in total, 4/16/2021)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KH2CB856O_QK"
      },
      "source": [
        "The purpose of the exercise is to practice different machine learning algorithms for text classification as well as the performance evaluation. In addition, you are requried to conduct *10 fold cross validation (https://scikit-learn.org/stable/modules/cross_validation.html)* in the training. \n",
        "\n",
        "The dataset can be download from here: https://github.com/unt-iialab/info5731_spring2021/blob/main/class_exercises/exercise09_datacollection.zip. The dataset contains two files train data and test data for sentiment analysis in IMDB review, it has two categories: 1 represents positive and 0 represents negative. You need to split the training data into training and validate data (80% for training and 20% for validation, https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6) and perform 10 fold cross validation while training the classifier. The final trained model was final evaluated on the test data. \n",
        "\n",
        "Algorithms:\n",
        "\n",
        "(1) MultinominalNB\n",
        "\n",
        "(2) SVM \n",
        "\n",
        "(3) KNN \n",
        "\n",
        "(4) Decision tree\n",
        "\n",
        "(5) Random Forest\n",
        "\n",
        "(6) XGBoost\n",
        "\n",
        "Evaluation measurement:\n",
        "\n",
        "(1) Accuracy\n",
        "\n",
        "(2) Recall\n",
        "\n",
        "(3) Precison \n",
        "\n",
        "(4) F-1 score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HodwSb5yO_QM"
      },
      "source": [
        "# Write your code here\n",
        "\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3T04-K7Q3JI"
      },
      "source": [
        "try:\n",
        "    from xgboost import XGBClassifier\n",
        "except ImportError ('Installing XGBoost...'):\n",
        "    !pip install xgboost"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXUA7cJ-Q-sR",
        "outputId": "9eb0baf5-7eca-4c4a-9dff-51a11ddc2eb8"
      },
      "source": [
        "data_train = pd.read_csv(r'/content/stsa-train.txt',sep = 'delimiter=',header= None,names=['review'])\n",
        "data_test = pd.read_csv(r'/content/stsa-test.txt',sep = 'delimiter=',header= None,names=['review'])\n",
        "\n",
        "data_train[['sentiment','review']] = data_train[\"review\"].str.split(\" \", 1, expand=True)\n",
        "data_test[['sentiment','review']] = data_test[\"review\"].str.split(\" \", 1, expand=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "G0sM8QdXQ8vk",
        "outputId": "05609a14-1ca1-4aec-e38a-f8ba30949269"
      },
      "source": [
        "data_train.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a stirring , funny and finally transporting re...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>apparently reassembled from the cutting-room f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>they presume their audience wo n't sit still f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>this is a visually stunning rumination on love...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>jonathan parker 's bartleby should have been t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  a stirring , funny and finally transporting re...         1\n",
              "1  apparently reassembled from the cutting-room f...         0\n",
              "2  they presume their audience wo n't sit still f...         0\n",
              "3  this is a visually stunning rumination on love...         1\n",
              "4  jonathan parker 's bartleby should have been t...         1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "2vC6oGyTSHux",
        "outputId": "a2233460-73dd-48b3-9698-6285c73ab91c"
      },
      "source": [
        "data_test.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>no movement , no yuks , not much of anything .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a gob of drivel so sickly sweet , even the eag...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gangs of new york is an unapologetic mess , wh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>we never really feel involved with the story ,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>this is one of polanski 's best films .</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0     no movement , no yuks , not much of anything .         0\n",
              "1  a gob of drivel so sickly sweet , even the eag...         0\n",
              "2  gangs of new york is an unapologetic mess , wh...         0\n",
              "3  we never really feel involved with the story ,...         0\n",
              "4            this is one of polanski 's best films .         1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2E5r327FVPXo"
      },
      "source": [
        "with open('/content/stsa-train.txt') as fin:\n",
        "    data = fin.readlines()\n",
        "with open('/content/stsa-test.txt') as fin:\n",
        "    data.extend(fin.readlines())\n",
        "sentiment = [x[0] for x in data]\n",
        "review = [x.strip()[2:] for x in data]\n",
        "df = pd.DataFrame({'review' : review, 'sentiment': sentiment})\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQe-0vyeVlfx"
      },
      "source": [
        "#TEXT PROCESSING"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1HBWMtuSgVq",
        "outputId": "574d78aa-85ff-4cb0-e984-79f664965aaf"
      },
      "source": [
        "import nltk\n",
        "import re\n",
        "import string\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "stopword=nltk.corpus.stopwords.words('english')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wl= WordNetLemmatizer()\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nd71iZqFSwBu"
      },
      "source": [
        "def data_cleaning(data):\n",
        "  data=\"\".join([word.lower() for word in data if word not in string.punctuation])\n",
        "  data = re.sub(\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\", \" \", data)\n",
        "  tokens = re.split('\\W+',data)\n",
        "  data = [wl.lemmatize(word) for word in tokens if word not in stopword]\n",
        "  return data"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWhCWD8uSwJV",
        "outputId": "dc75cbfa-a527-4014-f84c-9908dffe7866"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer(analyzer = data_cleaning)\n",
        "X_tfidf = tfidf.fit_transform(data_train['review'])\n",
        "print(X_tfidf.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6920, 13343)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "g8llRZNuUhw0",
        "outputId": "9ee3449f-e841-4f33-ce9a-fde4a319cc9b"
      },
      "source": [
        "X_tfidf=pd.DataFrame(X_tfidf.toarray())\n",
        "X_tfidf.columns=tfidf.get_feature_names()\n",
        "X_tfidf.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>100minute</th>\n",
              "      <th>103minute</th>\n",
              "      <th>10course</th>\n",
              "      <th>10th</th>\n",
              "      <th>10thgrade</th>\n",
              "      <th>10year</th>\n",
              "      <th>10yearold</th>\n",
              "      <th>112minute</th>\n",
              "      <th>12</th>\n",
              "      <th>129minute</th>\n",
              "      <th>12th</th>\n",
              "      <th>12yearold</th>\n",
              "      <th>13th</th>\n",
              "      <th>14yearold</th>\n",
              "      <th>15th</th>\n",
              "      <th>15year</th>\n",
              "      <th>168minute</th>\n",
              "      <th>18yearold</th>\n",
              "      <th>1930s</th>\n",
              "      <th>1940s</th>\n",
              "      <th>1950s</th>\n",
              "      <th>1960s</th>\n",
              "      <th>1970s</th>\n",
              "      <th>1980s</th>\n",
              "      <th>19th</th>\n",
              "      <th>19thcentury</th>\n",
              "      <th>20car</th>\n",
              "      <th>20th</th>\n",
              "      <th>21st</th>\n",
              "      <th>22yearold</th>\n",
              "      <th>24andunders</th>\n",
              "      <th>26yearold</th>\n",
              "      <th>2day</th>\n",
              "      <th>30</th>\n",
              "      <th>34th</th>\n",
              "      <th>37minute</th>\n",
              "      <th>3d</th>\n",
              "      <th>3yearolds</th>\n",
              "      <th>40</th>\n",
              "      <th>...</th>\n",
              "      <th>yuen</th>\n",
              "      <th>yung</th>\n",
              "      <th>yvan</th>\n",
              "      <th>zaidan</th>\n",
              "      <th>zany</th>\n",
              "      <th>zap</th>\n",
              "      <th>zaza</th>\n",
              "      <th>zboys</th>\n",
              "      <th>zeal</th>\n",
              "      <th>zealand</th>\n",
              "      <th>zealously</th>\n",
              "      <th>zeitgeist</th>\n",
              "      <th>zelda</th>\n",
              "      <th>zellweger</th>\n",
              "      <th>zemeckis</th>\n",
              "      <th>zen</th>\n",
              "      <th>zero</th>\n",
              "      <th>zerodimensional</th>\n",
              "      <th>zeus</th>\n",
              "      <th>zhang</th>\n",
              "      <th>zhao</th>\n",
              "      <th>zhuangzhuang</th>\n",
              "      <th>zigzag</th>\n",
              "      <th>zing</th>\n",
              "      <th>zinger</th>\n",
              "      <th>zingerfilled</th>\n",
              "      <th>zip</th>\n",
              "      <th>zipper</th>\n",
              "      <th>zippy</th>\n",
              "      <th>zishe</th>\n",
              "      <th>ziyi</th>\n",
              "      <th>zoe</th>\n",
              "      <th>zombie</th>\n",
              "      <th>zombieland</th>\n",
              "      <th>zone</th>\n",
              "      <th>zoning</th>\n",
              "      <th>zoom</th>\n",
              "      <th>zwick</th>\n",
              "      <th>zzzzzzzzz</th>\n",
              "      <th>élan</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.400584</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.048154</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.029784</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.049596</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.048782</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 13343 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             100minute  103minute  10course  ...  zoom  zwick  zzzzzzzzz  élan\n",
              "0  0.000000        0.0        0.0       0.0  ...   0.0    0.0        0.0   0.0\n",
              "1  0.048154        0.0        0.0       0.0  ...   0.0    0.0        0.0   0.0\n",
              "2  0.029784        0.0        0.0       0.0  ...   0.0    0.0        0.0   0.0\n",
              "3  0.049596        0.0        0.0       0.0  ...   0.0    0.0        0.0   0.0\n",
              "4  0.048782        0.0        0.0       0.0  ...   0.0    0.0        0.0   0.0\n",
              "\n",
              "[5 rows x 13343 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRwFR44HXZMH",
        "outputId": "e7b340f1-6892-4077-cd5c-95ea9cb61c77"
      },
      "source": [
        "test_tfidf = tfidf.transform(data_test['review'])\n",
        "print(test_tfidf.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1821, 13343)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2MoZd6tY8WD"
      },
      "source": [
        "#splittind data into test and train data\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_tfidf, data_train['sentiment'].values,\n",
        "                                                test_size=0.2, random_state=1)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKUFaCeZcSA1"
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLF8k8lIZLhQ"
      },
      "source": [
        "naive_bayes = MultinomialNB()\n",
        "svc = SVC()\n",
        "knn = KNeighborsClassifier()\n",
        "dt = DecisionTreeClassifier()\n",
        "rf = RandomForestClassifier()\n",
        "xgb = XGBClassifier()\n",
        "algos = [naive_bayes, svc, knn, dt, rf, xgb]\n",
        "cut = ['nb', 'svc', 'knn', 'dt', 'rf', 'xgb']\n",
        "estimators = []\n",
        "for name, model in zip(cut, algos):\n",
        "    cv = Pipeline([('vect', CountVectorizer()), (name,model)])\n",
        "    estimators.append(cv)\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4zd5c0OcfOQ"
      },
      "source": [
        "model = naive_bayes.fit(x_train,y_train)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEfSEQ2gatHE"
      },
      "source": [
        "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8BFnaDIbfqD",
        "outputId": "c501296d-7acc-47f8-ef35-f4a359b5970c"
      },
      "source": [
        "# Accuracy using Multinomial algorithm\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import cross_val_score\n",
        "accuracy = cross_val_score(naive_bayes, x_test, y_test, cv=18)\n",
        "y_pred_naive_bayes = model.predict(x_test)\n",
        "print(\"The accuracy for Multinomial\",accuracy.mean())\n",
        "print('accuracy %s' % accuracy_score(y_pred_naive_bayes,y_test))\n",
        "print(classification_report(y_test,y_pred_naive_bayes))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy for Multinomial 0.7210735171261488\n",
            "accuracy 0.7695086705202312\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.69      0.74       675\n",
            "           1       0.74      0.85      0.79       709\n",
            "\n",
            "    accuracy                           0.77      1384\n",
            "   macro avg       0.78      0.77      0.77      1384\n",
            "weighted avg       0.77      0.77      0.77      1384\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qG19CUNbqBF"
      },
      "source": [
        "#Accuracy using decision tree\n",
        "model1= dt.fit(x_train,y_train)\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_EFlNtpe75T",
        "outputId": "30bd3d23-f260-4e38-ebf6-6bb602485a81"
      },
      "source": [
        "y_pred_decision_tree = model1.predict(x_test)\n",
        "accuracy = cross_val_score(dt, x_test, y_test, cv=10)\n",
        "print('accuracy' % accuracy_score(y_pred_decision_tree,y_test))\n",
        "print(classification_report(y_test,y_pred_decision_tree))\n",
        "print(\"The accuracy for decision trees\",accuracy.mean())"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.55      0.58       675\n",
            "           1       0.61      0.66      0.64       709\n",
            "\n",
            "    accuracy                           0.61      1384\n",
            "   macro avg       0.61      0.61      0.61      1384\n",
            "weighted avg       0.61      0.61      0.61      1384\n",
            "\n",
            "The accuracy for decision trees 0.5983317693671151\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMTBhFXUfi6S",
        "outputId": "1a6670c9-5645-4612-d3c6-a7f590eda74f"
      },
      "source": [
        "#accuracy using KNeighbours\n",
        "from sklearn.model_selection import cross_val_score\n",
        "accuracy = cross_val_score(knn, x_test, y_test, cv=10)\n",
        "model2 = knn.fit(x_train,y_train)\n",
        "y_pred_knn= model2.predict(x_test)\n",
        "print('accuracy' % accuracy_score(y_pred_knn,y_test))\n",
        "print(classification_report(y_test,y_pred_knn))\n",
        "print(\"The accuracy using knn\",accuracy.mean())"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.67      0.69       675\n",
            "           1       0.70      0.74      0.72       709\n",
            "\n",
            "    accuracy                           0.71      1384\n",
            "   macro avg       0.71      0.71      0.71      1384\n",
            "weighted avg       0.71      0.71      0.71      1384\n",
            "\n",
            "The accuracy using knn 0.6633041392972578\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aozeA3bOnn2y",
        "outputId": "a0dc6558-5392-4422-fc19-ef1e18a1d19f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "accuracy = cross_val_score(svc, x_test, y_test, cv=10)\n",
        "print(\"using svm\",accuracy.mean())\n",
        "model3 = svc.fit(x_train,y_train)\n",
        "y_pred_svc = model3.predict(x_test)\n",
        "print(' The accuracy using svc %s' % accuracy_score(y_pred_svc,y_test))\n",
        "print(classification_report(y_test,y_pred_svc))\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using svm 0.7066416432071734\n",
            " The accuracy using svc 0.7673410404624278\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.74      0.76       675\n",
            "           1       0.76      0.80      0.78       709\n",
            "\n",
            "    accuracy                           0.77      1384\n",
            "   macro avg       0.77      0.77      0.77      1384\n",
            "weighted avg       0.77      0.77      0.77      1384\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gno6YFDXoZib",
        "outputId": "1f70b79b-9dde-4f27-c1de-33a967ce3a1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#accuracy using random forest\n",
        "model4 = rf.fit(x_train,y_train)\n",
        "y_pred_rf = model4.predict(x_test)\n",
        "accuracy = cross_val_score(rf, x_test, y_test, cv=10)\n",
        "print('The accuracy using random forest' % accuracy_score(y_pred_rf,y_test))\n",
        "print(classification_report(y_test,y_pred_rf))\n",
        "print(\"using random forest\",accuracy.mean())"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy using random forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.61      0.67       675\n",
            "           1       0.68      0.78      0.73       709\n",
            "\n",
            "    accuracy                           0.70      1384\n",
            "   macro avg       0.70      0.70      0.70      1384\n",
            "weighted avg       0.70      0.70      0.70      1384\n",
            "\n",
            "using random forest 0.6755656344489627\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkgDTEhQo9Zl",
        "outputId": "0404d823-d520-41ae-a0e8-1ec558261da2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#accuracy using XG boost\n",
        "model_xgb = xgb.fit(x_train,y_train)\n",
        "y_pred_xgb = model_xgb.predict(x_test)\n",
        "accuracy = cross_val_score(xgb, x_test, y_test, cv=10)\n",
        "print('Accuracy %s' % accuracy_score(y_pred_xgb,y_test))\n",
        "print(classification_report(y_test,y_pred_xgb))\n",
        "print(\"The accuracy using XG boost\",accuracy.mean())"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy 0.6213872832369942\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.37      0.49       675\n",
            "           1       0.59      0.86      0.70       709\n",
            "\n",
            "    accuracy                           0.62      1384\n",
            "   macro avg       0.65      0.62      0.59      1384\n",
            "weighted avg       0.65      0.62      0.60      1384\n",
            "\n",
            "The accuracy using XG boost 0.6206808466270461\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4K0sjcIqILl"
      },
      "source": [
        "From the above results we can see that Multinomial algoritham has best best accuracy and precision results."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPYBe84kvzGb",
        "outputId": "439677f2-4640-4ee5-c0d1-bb5b3bec2afd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Evaluating test data\n",
        "\n",
        "test_data_naive_bayes = model.predict(X_tfidf)\n",
        "print('The accuracy on test data using Multinonial %s' % accuracy_score(test_data_naive_bayes,data_train['sentiment']))\n",
        "print(classification_report(test_data_naive_bayes,data_train['sentiment']))\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy on test data using Multinonial 0.9119942196531792\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.94      0.90      3091\n",
            "           1       0.95      0.89      0.92      3829\n",
            "\n",
            "    accuracy                           0.91      6920\n",
            "   macro avg       0.91      0.91      0.91      6920\n",
            "weighted avg       0.91      0.91      0.91      6920\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEQElqv2wQJv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}